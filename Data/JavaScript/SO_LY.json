[
  "Title: How do I resolve system-managed environment restrictions every time I use npm?.\nBody: <p>Error message:</p>\n<blockquote>\n<pre class=\"lang-none prettyprint-override\"><code>npm ERR! code EACCES\nnpm ERR! syscall access\nnpm ERR! path /usr/lib/node_modules\nnpm ERR! errno -13\nnpm ERR! EACCES: permission denied, access '/usr/lib/node_modules'\n</code></pre>\n</blockquote>\n<p>I use apt upgrade and update.</p>",
  "Title: Error \"DataFrame object has no method 'append'\"\nBody: <p>I am trying to append an object to a DataFrame, but I get the following error:</p>\n<blockquote>\n<p>TypeError: df.append is not a function</p>\n</blockquote>\n<p>As far as I know, DataFrame should let me add a row.</p>\n<p>Code snippet:</p>\n<pre class=\"lang-js prettyprint-override\"><code>df = new DataFrame(df).append(newRow, { ignoreIndex: true })\n</code></pre>\n<p>I was expecting the object <code>newRow</code> to be added as a new row.</p>\n<p>How can I fix it?</p>",
  "Title: Why did Express start failing with \"Cannot find module 'encodeUrl' from 'serve-static'\"?\n\nBody: <p>Environment:</p>\n<pre class=\"lang-none prettyprint-override\"><code>Node.js 18.19.0\nexpress@4.18.2\n</code></pre>\n<p>I run my Express backend code in a Docker container, with base image:\n<code>FROM node:18-bullseye-slim</code></p>\n<p>But when I run the tests with <code>jest 29.7.0</code>,</p>\n<pre class=\"lang-none prettyprint-override\"><code>npm install jest\nnpx jest\n</code></pre>\n<p>it raises an error with logs:</p>\n<pre class=\"lang-none prettyprint-override\"><code>==================================== ERRORS ====================================\nCannot find module 'encodeUrl' from 'serve-static'\nRequire stack:\n- /app/node_modules/express/lib/response.js\n- /app/node_modules/express/lib/express.js\n- /app/node_modules/express/index.js\n- /app/src/app.js\n- /app/tests/utils.test.js\n</code></pre>\n<p>My code works fine when I run it directly with <code>node server.js</code></p>\n<p><code>server.js</code> shown below</p>\n<pre><code>const app = require('./app');\n\napp.listen(3000, '0.0.0.0');\n</code></pre>\n<p>I guess it should be a Jest version issue, because it used to work without changing any related code, and I use <code>npm install jest</code> without specifying a version.</p>\n<p>And my backend runs fine without Jest.</p>",
  "Title: OpenAI ChatGPT (GPT-3.5) API error 429: \"You exceeded your current quota, please check your plan and billing details\".\nBody: <p>I'm making a JavaScript script to use OpenAI via its API. However, I'm getting this error:</p>\n<blockquote>\n<p>RateLimitError: You exceeded your current quota, please check your plan and billing details</p>\n</blockquote>\n<p>My script is the following:</p>\n<pre class=\"lang-js prettyprint-override\"><code>#!/usr/bin/env node\n// -*- coding: utf-8 -*-\n\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({ apiKey: \"&lt;My API Key&gt;\" });\n\nconst completion = await client.chat.completions.create({\n  model: \"gpt-3.5-turbo\",\n  messages: [\n    { role: \"user\", content: \"Tell the world about the ChatGPT API in the style of a pirate.\" }\n  ]\n});\n\nconsole.log(completion.choices[0].message.content);\n</code></pre>\n<p>I'm using the Node.js shebang because I'm managing versions with nvm. I think it should work, since I did 0 API requests, so I'm assuming there's an error in my code.</p>",
  "Title: ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3.\nBody: <p>After <code>npm install openai</code>, when I try to <code>import OpenAI from \"openai\"</code>, it shows this error:</p>\n<blockquote>\n<p>the 'ssl' module of urllib3 is compile with LibreSSL not OpenSSL</p>\n</blockquote>\n<p>I just followed a tutorial on a project about using the OpenAI API. But when I get to the first step, which is installing and importing OpenAI, I got stuck. And I tried to find the solution for this error but I found nothing.</p>\n<p>Here is the message after I try to import OpenAI:</p>\n<pre class=\"lang-none prettyprint-override\"><code>Node.js v18.17.0\ndarwin x64\n\n&gt;&gt;&gt; import OpenAI from \"openai\"\n\nError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3.\n</code></pre>\n<p>I tried to <code>npm update</code> the dependencies, but it is still not working. The result is:</p>\n<pre class=\"lang-none prettyprint-override\"><code>npm update\nup to date, audited 1 package in 1s\n</code></pre>",
  "Title: Error Updating npm: OpenSSL_add_all_algorithms Missing\n\nBody: <p>I'm getting an error when installing or updating any npm package with Node.js. Purging and reinstalling <code>npm</code> and other packages hasn't helped. Here's what I see when I run <code>npm install -g npm</code> (the error is the same for installing or updating any package):</p>\n<pre><code>...stack trace...\nThe stack trace ends with a message about OpenSSL_add_all_algorithms being missing.\n</code></pre>\n<p>I'm running Ubuntu 20.04 in WSL. OpenSSL is already installed:</p>\n<pre><code>sudo apt install openssl\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nopenssl is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n</code></pre>\n<p>My assumption is that I need to reinstall something, but I'm not sure what. I've tried the obvious stuff like <code>openssl</code>, <code>libssl-dev</code>, <code>libffi-dev</code>, <code>nodejs</code>, and <code>npm</code> itself.</p>",
  "Title: Error: Unable to extract uploader id - YouTube, discord.js\n\nBody: <p>I have a very powerful bot in Discord (discord.js, JavaScript) and it can play music in voice channels. It gets the music from YouTube (ytdl-core). It <strong>worked perfectly before</strong> but now it doesn't want to work with any video. I tried updating ytdl-core but it still doesn't work. I searched everywhere but I still can't find an answer that might help me.</p>\n<p>This is the Error: <code>Error: Unable to extract uploader id</code></p>\n<p>After and before the error log there is no more information. Can anyone help?</p>\n<p>I will leave some of the code that I use for my bot... The YouTube setup/settings:</p>\n<pre><code>const ytdl = require('ytdl-core');\nconst { createAudioResource, StreamType } = require('@discordjs/voice');\n\nconst ytdlFormatOptions = {\n  quality: 'highestaudio',\n  filter: 'audioonly',\n  highWaterMark: 1 &lt;&lt; 25\n};\n\nclass YTDLSource {\n  constructor(resource, data) {\n    this.resource = resource;\n    this.data = data;\n    this.title = data.videoDetails.title;\n    this.url = data.videoDetails.video_url;\n    this.duration = data.videoDetails.lengthSeconds;\n    this.image = data.videoDetails.thumbnails[0].url;\n  }\n\n  static async fromUrl(url, { stream = true } = {}) {\n    const info = await ytdl.getInfo(url);\n    const data = info;\n\n    const audio = ytdl(url, { ...ytdlFormatOptions, requestOptions: { family: 4 } });\n    const resource = createAudioResource(audio, { inputType: StreamType.Arbitrary });\n\n    return new YTDLSource(resource, data);\n  }\n}\n</code></pre>\n<p>Approximately the command to run the audio (from my bot):</p>\n<pre><code>const { joinVoiceChannel, createAudioPlayer, AudioPlayerStatus } = require('@discordjs/voice');\n\nconst sessionChannel = message.member.voice.channel;\nconst connection = joinVoiceChannel({\n  channelId: sessionChannel.id,\n  guildId: sessionChannel.guild.id,\n  adapterCreator: sessionChannel.guild.voiceAdapterCreator\n});\n\nconst url = matched[1];\nconst player = createAudioPlayer();\n\nconst source = await YTDLSource.fromUrl(url, { stream: true });\nplayer.play(source.resource);\nconnection.subscribe(player);\n\nplayer.on('error', e =&gt; console.error(`Player error: ${e}`));\n</code></pre>",
  "Title: pre-commit fails to install isort 5.11.4 with error \"RuntimeError: The Poetry configuration is invalid\".\nBody: <p><a href=\"https://pre-commit.com/\" rel=\"noreferrer\">pre-commit</a> suddenly started to fail installing the <a href=\"https://github.com/pycqa/isort\" rel=\"noreferrer\">isort</a> hook in our builds today with the following error</p>\n<pre><code>[INFO] Installing environment for https://github.com/pycqa/isort.\n[INFO] Once installed this environment will be reused.\n[INFO] This may take a few minutes...\nAn unexpected error has occurred: CalledProcessError: command: ('/builds/.../.cache/pre-commit/repo0_h0f938/py_env-python3.8/bin/python', '-mpip', 'install', '.')\nreturn code: 1\nexpected return code: 0\n[...]\nstderr:\n      ERROR: Command errored out with exit status 1:\n[...]\n        File &quot;/tmp/pip-build-env-_3j1398p/overlay/lib/python3.8/site-packages/poetry/core/masonry/api.py&quot;, line 40, in prepare_metadata_for_build_wheel\n          poetry = Factory().create_poetry(Path(&quot;.&quot;).resolve(), with_groups=False)\n        File &quot;/tmp/pip-build-env-_3j1398p/overlay/lib/python3.8/site-packages/poetry/core/factory.py&quot;, line 57, in create_poetry\n          raise RuntimeError(&quot;The Poetry configuration is invalid:\\n&quot; + message)\n      RuntimeError: The Poetry configuration is invalid:\n        - [extras.pipfile_deprecated_finder.2] 'pip-shims&lt;=0.3.4' does not match '^[a-zA-Z-_.0-9]+$'\n</code></pre>\n<p>It seems to be related with poetry configuration..</p>",
  "Title: npm install on an existing project Error \"does not contain any element\".\nBody: <p>I am using npm for the first time.\nI have a very simple project. Basically</p>\n<pre><code>a_project\n|\n|--test\n|    |---test_something.js\n|\n|-script_to_test.js\n</code></pre>\n<p>From a project I do <code>npm init</code> and then <code>npm install</code></p>\n<p>I get the following</p>\n<pre><code> npm install\nadded 7 packages, and audited 7 packages in 1s\n\nfound 0 vulnerabilities\n\n/home/me/MyStudy/2023/node_practice/dos/a_project/a_project does not contain any element\n</code></pre>\n<p>after this I can run <code>npx jest</code> without problem but what does that error message mean?</p>",
  "Title: npm install is failing: \"EACCES: permission denied\"\nBody: <p>Command:</p>\n<pre class=\"lang-none prettyprint-override\"><code>npm install\n</code></pre>\n<p>Output:</p>\n<pre class=\"lang-none prettyprint-override\"><code>npm ERR! code EACCES\nnpm ERR! syscall access\nnpm ERR! path /usr/lib/node_modules\nnpm ERR! errno -13\nnpm ERR! Error: EACCES: permission denied, access '/usr/lib/node_modules'\n</code></pre>\n<p>I wish someone would explain to me what to do and how to solve it.</p>",
  "Title: Why is b.shift() over 200 times slower than deleting b[0] for a Uint8Array?\nBody: <p>Letting them compete three times (a million shifts/deletes each time):</p>\n<pre><code>const { performance } = require('perf_hooks');\n\nfunction timeit(fn) {\n  const t0 = performance.now();\n  fn();\n  const t1 = performance.now();\n  return (t1 - t0) / 1000;\n}\n\nfor (let i = 0; i &lt; 3; i++) {\n  let t1 = timeit(() =&gt; {\n    let b = new Uint8Array(1_000_000);\n    for (let j = 0; j &lt; 1_000_000; j++) {\n      // remove first element\n      // convert to Array to allow shift\n      const arr = Array.from(b);\n      arr.shift();\n      b = Uint8Array.from(arr);\n    }\n  });\n\n  let t2 = timeit(() =&gt; {\n    let b = new Uint8Array(1_000_000);\n    for (let j = 0; j &lt; 1_000_000; j++) {\n      // delete first element by slicing\n      b = b.slice(1);\n    }\n  });\n\n  console.log(t1 / t2);\n}\n</code></pre>\n<p>Time ratios:</p>\n<pre><code>274.6037053753368\n219.38099365582403\n252.08691226683823\n</code></pre>\n<p>Why is <code>shift</code> that much slower at doing the same thing?</p>",
  "Title: Why is the simpler loop slower?\nBody: <p>Called with <code>n = 1e8</code>, the simple loop is consistently significantly slower for me than the complex one in Node.js, and I don't see why:</p>\n<pre><code>function simple(n) {\n    while (n) {\n        n -= 1;\n    }\n}\n\nfunction complex(n) {\n    while (true) {\n        if (!n) break;\n        n -= 1;\n    }\n}\n</code></pre>\n<p>Some times in seconds:</p>\n<pre class=\"lang-none prettyprint-override\"><code>simple 4.34\ncomplex 3.65\nsimple 4.37\ncomplex 3.64\nsimple 4.33\ncomplex 3.62\nNode.js: v20.x\n</code></pre>\n<p>I also looked at the V8 bytecode with <code>node --print-bytecode</code>, and it looks like the complex one does more work per iteration (two jumps instead of one). Then why is it faster?</p>\n<p>Seems to be a Node/V8 phenomenon, see the comments.</p>\n<p>Benchmark script:</p>\n<pre class=\"lang-js prettyprint-override\"><code>import { performance } from \"node:perf_hooks\";\n\nfunction simple(n) {\n    while (n) {\n        n -= 1;\n    }\n}\n\nfunction complex(n) {\n    while (true) {\n        if (!n) break;\n        n -= 1;\n    }\n}\n\nfor (const f of [simple, complex, simple, complex, simple, complex]) {\n    const t = performance.now();\n    f(1e8);\n    console.log(f.name, (performance.now() - t) / 1000);\n}\n\nconsole.log(\"Node.js:\", process.version);\n</code></pre>",
  "Title: TypeError: Cannot read properties of undefined (reading 'ANTIALIAS') in sharp\nBody: <ul>\n<li>Trying to show images in my Electron app, so I'm using <code>sharp</code>.</li>\n<li><code>sharp.ANTIALIAS</code> doesn’t work, but resizing with a built-in kernel like <code>sharp.kernel.lanczos3</code> does.</li>\n</ul>\n<p>Here's some sample code:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const { app, BrowserWindow } = require('electron');\nconst sharp = require('sharp');\nconst fs = require('fs');\n\napp.whenReady().then(async () => {\n  const image = sharp('VC.png');\n  const resized = await image.resize(20, 20, { kernel: sharp.ANTIALIAS }).toBuffer();\n\n  fs.writeFileSync('out.png', resized);\n\n  const win = new BrowserWindow();\n  win.loadFile('index.html');\n});\n</code></pre>\n<p>Here's the error:</p>\n<pre class=\"lang-none prettyprint-override\"><code>TypeError: Cannot read properties of undefined (reading 'ANTIALIAS')\n</code></pre>\n<ul>\n<li>Tried reinstalling npm packages. Didn’t work.</li>\n<li>Someone told me to upgrade to the latest sharp version. I’m on the latest version.</li>\n</ul>",
  "Title: \"Unable to import module from a Lambda layer in Node.js while scraping and writing to S3\"\nBody: <h1>What I want to achieve</h1>\n<p>Scrape a website with AWS Lambda (Node.js) and save the data to S3.</p>\n<h1>The issues I'm having</h1>\n<p>When I execute the Lambda, I get an import error.</p>\n<blockquote>\n<p>{ \"errorMessage\": \"Unable to import module 'index': Cannot find module 'axios' from /opt/nodejs/node_modules/axios/index.js\", \"errorType\": \"Runtime.ImportModuleError\", \"requestId\": \"fb66bea9-cbad-4bd3-bd4d-6125454e21be\", \"stackTrace\": [] }</p>\n</blockquote>\n<h1>Code</h1>\n<p>Minimum Lambda code:</p>\n<pre><code>const AWS = require('aws-sdk');\n\nexports.handler = async (event) =&gt; {\n  const s3 = new AWS.S3();\n  await s3.putObject({\n    Bucket: 'horserace-dx',\n    Key: 'raw/a.html',\n    Body: 'testtext'\n  }).promise();\n\n  return event;\n};\n</code></pre>\n<p>A Lambda layer was added. I installed dependencies into a <code>nodejs</code> folder, zipped it, and uploaded as a layer.</p>\n<pre><code>npm install axios -t ./nodejs\nnpm install cheerio -t ./nodejs\n</code></pre>\n<ul>\n<li>The bucket <code>horserace-dx</code> exists</li>\n<li>The folder <code>raw</code> exists</li>\n<li>The Lambda role can read/write S3</li>\n<li>The Lambda runtime is Node.js 18</li>\n</ul>\n<h1>What I did so far</h1>\n<p>I searched for this error and tried pinning versions when building the layer, but it still fails.</p>\n<pre><code>npm install axios@1.6.8 -t ./nodejs\nnpm install cheerio@1.0.0-rc.12 -t ./nodejs\n</code></pre>\n<p>What should I do to fix the import error and get this working?</p>",
  "Title: Why is dot so much faster than sum in Node.js?\nBody: <p>Why is dot so much faster than sum in Node.js? I’m seeing that a dot product over two arrays can be faster than summing one array, even though dot does a multiply and a sum.</p>\n<p>For example:</p>\n<pre><code>const { Suite } = require('benchmark');\n\nconst A = new Float64Array(1000).map(() =&gt; Math.random());\nconst B = new Float64Array(1000).map(() =&gt; Math.random());\n\nfunction sum(arr) {\n  let s = 0;\n  for (let i = 0; i &lt; arr.length; i++) s += arr[i];\n  return s;\n}\n\nfunction dot(a, b) {\n  let s = 0;\n  for (let i = 0; i &lt; a.length; i++) s += a[i] * b[i];\n  return s;\n}\n\nconst suite = new Suite();\nsuite\n  .add('sum(A)', () =&gt; sum(A))\n  .add('dot(A,B)', () =&gt; dot(A, B))\n  .on('cycle', (event) =&gt; console.log(String(event.target)))\n  .run();\n</code></pre>\n<p>Given that dot is both multiplying two arrays elementwise and then summing them, how can this be faster than just summing one array? If B were set to the all-ones array then dot would simply be summing A.</p>\n<p>So it seems the fastest option to sum A is:</p>\n<pre><code>const O = new Float64Array(1000).fill(1);\ndot(A, O);\n</code></pre>\n<p>This can't be right, can it?</p>\n<p>This is on Ubuntu with Node.js 20.x (V8). The arrays are Float64Array.</p>\n<p><strong>Update</strong></p>\n<p>The order of the timings reverses if the array is much longer. That is:</p>\n<pre><code>const A = new Float64Array(1_000_000).map(() =&gt; Math.random());\nconst O = new Float64Array(1_000_000).fill(1);\n\n// dot(A, O) becomes slower than sum(A)\n</code></pre>\n<p>This implies to me that there is some fixed sized overhead when calling sum(A) that doesn't exist when calling dot(), but the part of the code that does the summation is in fact faster for long arrays.</p>\n<p>——————————-</p>\n<p>Any speed ups using native addons, WebAssembly, or other JS techniques would be great to see.</p>",
  "Title: Why does V8 create a separate function for an array comprehension-style expression?\n\nBody: <p>This is the V8 bytecode output for a simple array-comprehension-style expression in Node.js:</p>\n<pre><code>$ node --print-bytecode -e \"Array.from([], _ =&gt; true)\"\n[generated bytecode for &lt;eval&gt;]\n...\nSharedFunctionInfo &lt;anonymous&gt;\nCreateClosure\nCallRuntime\n</code></pre>\n<p>From what I can tell, V8 creates a separate function object for the mapping callback and immediately calls it to build the array. I get that the callback is anonymous, but why does the engine need a separate function object here instead of inlining the loop? Is this for scoping, or an optimization detail of V8’s bytecode generation?</p>",
  "Title: Unexpected BigUint64Array behavior 0xFFFF'FFFF'FFFF'FFFF - 1 = 0?\nBody: Consider the following brief JavaScript session showcasing `BigUint64Array`:\n\n```js\nconst a = new BigUint64Array(1);\n\na;\n// BigUint64Array(1) [0n]\n\na[0] -= 1n;\na;\n// BigUint64Array(1) [18446744073709551615n]\n// this is 0xffff ffff ffff ffff, as expected\n\na[0] -= 1n;\na;\n// BigUint64Array(1) [0n]\n// what the heck?\n```\n\nI'm utterly confused by this last output.\n\nI would expect `0xFFFF'FFFF'FFFF'FFFE`.\n\nWhat exactly is going on here?\n\nMy setup:\n\n```text\nNode.js v20.x\n```",
  "Title: read_sql_query() throws \"'OptionEngine' object has no attribute 'execute'\" with SQLAlchemy 2.0.0.\nBody: <p>First of all, I'm a totally new guys in the dev world\nI'm currently taking courses in AI / Data Science and one of my work is to use a SQL Database to make prediction using Prophet, then use these predition to make a PowerBI\nBut currently, I'm stuck with the JavaScript code, I'm not a developer initially, so I have no clue where the problem is:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const { createPool } = require('mysql2/promise');\nconst { Parser } = require('json2csv');\nconst { Prophet } = require('prophet-js'); // if using a JS Prophet wrapper\nconst fs = require('fs');\n\n(async () =&gt; {\n  const pool = createPool({\n    host: 'localhost',\n    user: 'root',\n    password: 'Password',\n    database: 'data',\n    port: 3306,\n  });\n\n  const query = `SELECT Cle_Produit, Date_Facturation, SUM(Quantite) AS Total_Quantite\n                 FROM ventes\n                 GROUP BY Cle_Produit, Date_Facturation`;\n\n  const [rows] = await pool.query(query);\n\n  // TODO: pivot rows so Date_Facturation becomes ds and Total_Quantite becomes y\n  // Then fit Prophet, make future dataframe, predict, and export to CSV\n\n  await pool.end();\n})();\n</code></pre>\n<p>It returns me this message:</p>\n<blockquote>\n<p>Importing plotly failed. Interactive plots will not work.\nTraceback (most recent call last):\nFile \"f:\\Backup\\Cours\\Cours\\Explo Data\\app3.js\", line 9, in \ndf = pd.read_sql_query(query, engine)\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 397, in    read_sql_query\nreturn pandas_sql.read_query(\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 1560, in read_query\nresult = self.execute(*args)\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 1405, in execute\nreturn self.connectable.execution_options().execute(*args, **kwargs)\nAttributeError: 'OptionEngine' object has no attribute 'execute'</p>\n</blockquote>\n<p>Please, can somebody help me?</p>\n<p>I want this JavaScript script to create a csv file with the prediction from prophet.\nI want Prophet to use the table ventes from the DB data, and it should use the column <code>Cle_Produit</code>, <code>Quantite</code> and <code>Date_Facturation</code></p>",
  "Title: CUDA 12 + tfjs-node-gpu: “Could not find cuda drivers on your machine, GPU will not be used” while every check is fine and in PyTorch it works\n\nBody: <ul>\n<li><strong>@tensorflow/tfjs-node-gpu version</strong> = 4.8.0</li>\n<li><strong>Node.js version</strong> = 18.16.0</li>\n<li><strong>CUDA drivers version</strong> = 525.85.12</li>\n<li><strong>CUDA version</strong> = 12.0</li>\n<li><strong>cuDNN version</strong> = 8.5.0</li>\n<li>I am using <strong>Linux</strong> (x86_64, Ubuntu 22.04)</li>\n<li>I am coding in <strong>Visual Studio Code</strong> on a <strong>node_modules</strong> project</li>\n</ul>\n<p>I am trying to run some models on the GPU (NVIDIA GeForce RTX 3050) using TensorFlow.js GPU. The problem that I have is that apparently every checking that I am making seems to be correct, but in the end the script is not able to detect or use the GPU. I’ve dedicated a lot of time trying to see what is happening and nothing seems to work, so any advice or solution will be more than welcomed. The GPU seems to be working for PyTorch in a separate Python environment.</p>\n<p>I will show some of the most common checkings regarding CUDA that I did (Visual Studio Code terminal), I hope you find them useful:</p>\n<ol>\n<li><p><strong>Check CUDA version:</strong></p>\n<p><code>$ nvcc --version</code></p>\n<pre><code>nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Fri_Jan__6_16:45:21_PST_2023\nCuda compilation tools, release 12.0, V12.0.140\nBuild cuda_12.0.r12.0/compiler.32267302_0\n</code></pre>\n</li>\n<li><p><strong>Check if the connection with the CUDA libraries is correct:</strong></p>\n<p><code>$ echo $LD_LIBRARY_PATH</code></p>\n<pre><code>/usr/cuda/lib\n</code></pre>\n</li>\n<li><p><strong>Check NVIDIA drivers for the GPU:</strong></p>\n<p><code>$ nvidia-smi</code></p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n| N/A   40C    P5     6W /  20W |     46MiB /  4096MiB |     22%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A      1356      G   /usr/lib/xorg/Xorg                 45MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n</li>\n<li><p><strong>Add cuda/bin PATH and check it:</strong></p>\n<p><code>$ export PATH=\"/usr/local/cuda/bin:$PATH\"</code></p>\n<p><code>$ echo $PATH</code></p>\n<pre><code>/usr/local/cuda-12.0/bin:/home/victus-linux/Escritorio/MasterThesis_CODE/to_share/node_modules/.bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin\n</code></pre>\n</li>\n<li><p><strong>Custom function to check if CUDA is correctly installed: [<a href=\"https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation\">function by Sherlock</a>]</strong></p>\n<pre class=\"lang-bash prettyprint-override\"><code>function lib_installed() { /sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep $1; }\nfunction check() { lib_installed $1 &amp;&amp; echo \"$1 is installed\" || echo \"ERROR: $1 is NOT installed\"; }\ncheck libcuda\ncheck libcudart\n</code></pre>\n<pre><code>libcudart.so.12 -&gt; libcudart.so.12.0.146\n        libcuda.so.1 -&gt; libcuda.so.525.85.12\n        libcuda.so.1 -&gt; libcuda.so.525.85.12\n        libcudadebugger.so.1 -&gt; libcudadebugger.so.525.85.12\nlibcuda is installed\n        libcudart.so.12 -&gt; libcudart.so.12.0.146\nlibcudart is installed\n</code></pre>\n</li>\n<li><p><strong>Custom function to check if cuDNN is correctly installed: [<a href=\"https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation\">function by Sherlock</a>]</strong></p>\n<pre class=\"lang-bash prettyprint-override\"><code>function lib_installed() { /sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep $1; }\nfunction check() { lib_installed $1 &amp;&amp; echo \"$1 is installed\" || echo \"ERROR: $1 is NOT installed\"; }\ncheck libcudnn \n</code></pre>\n<pre><code>        libcudnn_cnn_train.so.8 -&gt; libcudnn_cnn_train.so.8.8.0\n        libcudnn_cnn_infer.so.8 -&gt; libcudnn_cnn_infer.so.8.8.0\n        libcudnn_adv_train.so.8 -&gt; libcudnn_adv_train.so.8.8.0\n        libcudnn.so.8 -&gt; libcudnn.so.8.8.0\n        libcudnn_ops_train.so.8 -&gt; libcudnn_ops_train.so.8.8.0\n        libcudnn_adv_infer.so.8 -&gt; libcudnn_adv_infer.so.8.8.0\n        libcudnn_ops_infer.so.8 -&gt; libcudnn_ops_infer.so.8.8.0\nlibcudnn is installed\n</code></pre>\n</li>\n</ol>\n<p>So, once I did these previous checkings I used a script to evaluate if everything was finally ok and then the following error appeared:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const tf = require('@tensorflow/tfjs-node-gpu');\n\n(async () =&gt; {\n  console.log(`\\nTensorFlow.js version = ${tf.version.tfjs}\\n`);\n  await tf.ready();\n\n  console.log(`\\nBackend = ${tf.getBackend()}\\n`);\n\n  const a = tf.tensor([1, 2, 3]);\n  const b = tf.tensor([4, 5, 6]);\n  a.add(b).print();\n})();\n</code></pre>\n<pre><code>2023-03-02 12:05:09.463343: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-03-02 12:05:09.489911: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-03-02 12:05:09.490522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-03-02 12:05:10.066759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\nTensorFlow.js version = 4.8.0\n\n2023-03-02 12:05:10.748675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2023-03-02 12:05:10.771263: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n</code></pre>\n<p><strong>Extra check:</strong> I tried to run a checking script on PyTorch in a separate Python environment and in there it worked, so I guess the problem is related with TensorFlow.js / tfjs-node-gpu.</p>\n<p>Please, if you know something that might help solve this issue, don't hesitate on telling me.</p>",
  "Title: Theoretically can the Ackermann function be optimized?.\nBody: <p>I am wondering if there can be a version of Ackermann function with better time complexity than the standard variation.</p>\n<p>This is not a homework and I am just curious. I know the Ackermann function doesn't have any practical use besides as a performance benchmark, because of the deep recursion. I know the numbers grow very large very quickly, and I am not interested in computing it.</p>\n<p>Even though I use Node.js and the numbers won’t overflow for small values, I do have finite time, but I have implemented a version of it myself according to the definition found on <a href=\"https://en.wikipedia.org/wiki/Ackermann_function\" rel=\"noreferrer\">Wikipedia</a>, and computed the output for extremely small values, just to make sure the output is correct.</p>\n<p><a href=\"https://i.stack.imgur.com/vsPES.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/vsPES.jpg\" alt=\"enter image description here\" /></a></p>\n<pre><code>function A(m, n) {\n  if (!m) return n + 1;\n  return n ? A(m - 1, A(m, n - 1)) : A(m - 1, 1);\n}\n</code></pre>\n<p>The above code is a direct translation of the image, and is extremely slow, I don't know how it can be optimized, is it impossible to optimize it?</p>\n<p>One thing I can think of is to memoize it, but the recursion runs backwards, each time the function is recursively called the arguments were not encountered before, each successive function call the arguments decrease rather than increase, therefore each return value of the function needs to be calculated, memoization doesn't help when you call the function with different arguments the first time.</p>\n<p>Memoization can only help if you call it with the same arguments again, it won't compute the results and will retrieve cached result instead, but if you call the function with any input with (m, n) &gt;= (4, 2) it will crash the interpreter regardless.</p>\n<p>I also implemented another version according to this <a href=\"https://stackoverflow.com/a/20411205/16383578\">answer</a>:</p>\n<pre><code>function ack(x, y) {\n  for (let i = x; i &gt; 0; i--) {\n    y = y ? ack(i, y - 1) : 1;\n  }\n  return y + 1;\n}\n</code></pre>\n<p>But it is actually slower:</p>\n<pre><code>console.time(\"A(3,4)\");\nA(3, 4);\nconsole.timeEnd(\"A(3,4)\");\n// ~1.3 ms\n\nconsole.time(\"ack(3,4)\");\nack(3, 4);\nconsole.timeEnd(\"ack(3,4)\");\n// ~2 ms\n</code></pre>\n<p>Theoretically can Ackermann function be optimized? If not, can it be definitely proven that its time complexity cannot decrease?</p>\n<hr />\n<p>I have just tested <code>A(3, 9)</code> and <code>A(4, 1)</code> will crash the interpreter, and the performance of the two functions for <code>A(3, 8)</code>:</p>\n<pre><code>console.time(\"A(3,8)\");\nA(3, 8);\nconsole.timeEnd(\"A(3,8)\");\n// ~432 ms\n\nconsole.time(\"ack(3,8)\");\nack(3, 8);\nconsole.timeEnd(\"ack(3,8)\");\n// ~588 ms\n</code></pre>\n<hr />\n<p>I did some more experiments:</p>\n<pre><code>const counts = new Map();\n\nfunction A1(m, n) {\n  const key = `${m},${n}`;\n  counts.set(key, (counts.get(key) || 0) + 1);\n  if (!m) return n + 1;\n  return n ? A1(m - 1, A1(m, n - 1)) : A1(m - 1, 1);\n}\n\nfunction test(m, n) {\n  counts.clear();\n  A1(m, n);\n  return counts;\n}\n</code></pre>\n<p>The arguments indeed repeat.</p>\n<p>But surprisingly caching doesn't help at all:</p>\n<pre><code>const memo = new Map();\nfunction Ackermann(m, n) {\n  const key = `${m},${n}`;\n  if (memo.has(key)) return memo.get(key);\n  const val = !m ? n + 1 : (n ? Ackermann(m - 1, Ackermann(m, n - 1)) : Ackermann(m - 1, 1));\n  memo.set(key, val);\n  return val;\n}\n\nconsole.time(\"Ackermann(3,4)\");\nAckermann(3, 4);\nconsole.timeEnd(\"Ackermann(3,4)\");\n// ~1.3 ms\n</code></pre>\n<p>Caching only helps when the function is called with the same arguments again, as explained:</p>\n<pre><code>console.time(\"Ackermann(3,2)\");\nAckermann(3, 2);\nconsole.timeEnd(\"Ackermann(3,2)\");\n// ~0.1 ms\n</code></pre>\n<p>I have tested it with different arguments numerous times, and it always gives the same efficiency boost (which is none).</p>",
  "Title: Why is b.shift() over 200 times slower than b.splice(0, 1) for an array of bytes?\nBody: <p>Letting them compete three times (a million shifts/splices each time):</p>\n<pre><code>const { performance } = require('perf_hooks');\n\nfunction timeit(fn) {\n  const start = performance.now();\n  fn();\n  return (performance.now() - start) / 1000;\n}\n\nfor (let i = 0; i &lt; 3; i++) {\n  const t1 = timeit(() =&gt; {\n    let b = new Array(1_000_000).fill(0);\n    b.shift();\n  });\n\n  const t2 = timeit(() =&gt; {\n    let b = new Array(1_000_000).fill(0);\n    b.splice(0, 1);\n  });\n\n  console.log(t1 / t2);\n}\n</code></pre>\n<p>Time ratios:</p>\n<pre><code>274.6037053753368\n219.38099365582403\n252.08691226683823\n</code></pre>\n<p>Why is <code>shift</code> that much slower at doing the same thing?</p>",
  "Title: Why isn’t the derived class destructor called when deleting an array through a base class reference in JavaScript?\n\nBody: <p>I have an <code>Animal</code> class with a destructor, and a derived class <code>Cat</code>.</p>\n<pre><code>class Animal {\n  constructor() {\n    console.log(\"Animal constructor\");\n  }\n  destroy() {\n    console.log(\"Animal destructor\");\n  }\n}\n\nclass Cat extends Animal {\n  constructor() {\n    super();\n    console.log(\"Cat constructor\");\n  }\n  destroy() {\n    console.log(\"Cat destructor\");\n    super.destroy();\n  }\n}\n\nconst j = [new Cat()];\nj.forEach(a =&gt; a.destroy());\n</code></pre>\n<p>This gives the output:</p>\n<blockquote>\n<p>Animal constructor<br />\nCat constructor<br />\nCat destructor<br />\nAnimal destructor</p>\n</blockquote>\n<p>I’m trying to understand how destructor-like cleanup works with inheritance in JavaScript and how to ensure the derived cleanup runs before the base cleanup when dealing with arrays of base references.</p>",
  "Title: Convenient way to declare 2D (or higher-dimension) arrays in JavaScript?\nBody: <p>I’m converting a lot of old code to modern JavaScript.</p>\n<p>There are many raw 2D arrays in that code like:</p>\n<pre><code>const bar = new Array(XSIZE).fill(null).map(() =&gt; new Array(YSIZE));\n</code></pre>\n<p>And I’m about to replace these declarations with something like:</p>\n<pre><code>const bar = Array.from({ length: XSIZE }, () =&gt; Array.from({ length: YSIZE }));\n</code></pre>\n<p>This is convenient because the usage stays the same and the code behaves like raw arrays, with the benefit of being able to add bounds checks in debug builds.</p>\n<p>But IMO the nested <code>Array.from</code> is somewhat cumbersome and not easy to read, and with 3D arrays it would be even worse.</p>\n<p>Right now I’m using this helper to make the declaration more readable:</p>\n<pre><code>const declare2DArray = (x, y) =&gt; Array.from({ length: x }, () =&gt; new Array(y));\n...\nconst bar = declare2DArray(XSIZE, YSIZE);\n</code></pre>\n<p>But I feel this is a bit hacky, and I’m wondering if there is a cleaner, more idiomatic JavaScript way to do something similar.</p>",
  "Title: V8 removes a bounds check in the right operand of &&, but not in the left operand — why?\n\nBody: I have the following JavaScript code:\n\n```js\nconst ARRAY_LENGTH = 666;\n\nlet g_sum = 0;\nconst g_ptrArray = new Int32Array(ARRAY_LENGTH);\n\nfunction test() {\n  let idx = 0;\n\n  // either enable or disable the check \"idx < ARRAY_LENGTH\" in the while loop\n  while (g_ptrArray[idx] !== 0 /* && idx < ARRAY_LENGTH */) {\n    g_sum += g_ptrArray[idx];\n    ++idx;\n  }\n}\n```\n\nWhen I run this in Node.js and inspect V8’s optimized machine code, I see the same optimized output for both cases:\n\n1) `g_ptrArray[idx] !== 0`  \n2) `g_ptrArray[idx] !== 0 && idx < ARRAY_LENGTH`\n\nThe optimized code seems to omit the bounds check for `idx < ARRAY_LENGTH` entirely when it’s on the right side of `&&`.\n\nHowever, if I swap the order to:\n\n```js\nwhile (idx < ARRAY_LENGTH && g_ptrArray[idx] !== 0) {\n  g_sum += g_ptrArray[idx];\n  ++idx;\n}\n```\n\nthen the optimized code does include the bounds check.\n\n**My question:**  \nHow is that possible? Why can V8 generate the same optimized code and drop the `idx < ARRAY_LENGTH` condition when it appears on the right side of `&&`? What rule or optimization allows it to remove that check?",
  "Title: Are multidimensional array accesses sequenced in JavaScript?\nBody: <p>Take the following:</p>\n<pre><code>function a() {\n    console.log(\"a\");\n    return 0;\n}\n\nfunction b() {\n    console.log(\"b\");\n    return 1;\n}\n\nfunction c() {\n    console.log(\"c\");\n    return 2;\n}\n\nfunction d() {\n    console.log(\"d\");\n    return 3;\n}\n</code></pre>\n<p>Will the following have predictable behavior?</p>\n<pre><code>const arr = Array.from({ length: 4 }, () =>\n  Array.from({ length: 4 }, () =>\n    Array.from({ length: 4 }, () =>\n      Array(4).fill(0)\n    )\n  )\n);\n\narr[a()][b()][c()][d()] = 1;\n</code></pre>\n<p>Is it guaranteed to print in this order?</p>\n<pre class=\"lang-none prettyprint-override\"><code>a\nb\nc\nd\n</code></pre>\n<p>I am aware that constructs such as the following are problematic in some languages because of sequencing:</p>\n<pre><code>let i = 0;\ni = i++;\n</code></pre>\n<p>Put another way, is the following valid in JavaScript?</p>\n<pre><code>let i = 0;\nconst arr = Array.from({ length: 4 }, () =>\n  Array.from({ length: 4 }, () =>\n    Array.from({ length: 4 }, () =>\n      Array(4).fill(0)\n    )\n  )\n);\n\narr[i++][i++][i++][i++] = 1;\n</code></pre>\n<p>Or does it depend on evaluation order and lead to unpredictable results due to unsequenced modification and access to <code>i</code>?</p>\n<p>According to the JavaScript specification, is there a defined evaluation order between each successive <code>[]</code> when indexing a multidimensional array?</p>\n<p>To be clear, this isn’t about precedence or implicit parentheses. The question is about sequencing: the order in which the <em>operands themselves</em> are evaluated.</p>",
  "Title: How to use array input for a custom GitHub Actions.\n\nBody: <p>I'm working on a GitHub Action <a href=\"https://github.com/MathieuSoysal/Javadoc-publisher.yml/blob/4ea2062374784e3de840530c99365039f5fa76bb/action.yml#L47-L50\" rel=\"noreferrer\">workflow</a> that uses an array for input.</p>\n<p>I used this solution to simulate an array:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>      - uses: actions/my-custom-ci\n        with:\n          subdirectories: src/main/java src/test/java\n</code></pre>\n<p>But I want to use a solution like this:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>      - uses: actions/my-custom-ci\n        with:\n          subdirectories: \n                - src/main/java \n                - src/test/java\n</code></pre>\n<p>Is it possible to use an array input for custom GitHub Actions? If yes, how can we use an array input for custom GitHub Actions?</p>",
  "Title: Merging users with multiple refs and count their collective assets.\nBody: <p>There is a set of users. A person can have multiple users, but <code>ref1</code> and <code>ref2</code> might be alike and can therefore link users together. <code>ref1</code> and <code>ref2</code> does not overlap, one value in <code>ref1</code> does not exist in <code>ref2</code>.</p>\n<p>A user can own multiple assets. I want to &quot;merge&quot; users that has one or more refs alike and then count how many assets they own together. There could be missing entries in the user table, in that case I just want to propagate the owner into ref2 and set the asset_count and asset_ids. I want to do this in JavaScript (Node.js), ideally in the DB layer or with SQL plus JavaScript if needed.</p>\n<p>Here is an example schema to illustrate:</p>\n<p><strong>Example assets</strong></p>\n<pre><code>SELECT * FROM assets;\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id</th>\n<th>name</th>\n<th>owner</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>#1</td>\n<td>a</td>\n</tr>\n<tr>\n<td>2</td>\n<td>#2</td>\n<td>b</td>\n</tr>\n<tr>\n<td>3</td>\n<td>#3</td>\n<td>c</td>\n</tr>\n<tr>\n<td>4</td>\n<td>#4</td>\n<td>a</td>\n</tr>\n<tr>\n<td>5</td>\n<td>#5</td>\n<td>c</td>\n</tr>\n<tr>\n<td>6</td>\n<td>#6</td>\n<td>d</td>\n</tr>\n<tr>\n<td>7</td>\n<td>#7</td>\n<td>e</td>\n</tr>\n<tr>\n<td>8</td>\n<td>#8</td>\n<td>d</td>\n</tr>\n<tr>\n<td>9</td>\n<td>#9</td>\n<td>a</td>\n</tr>\n<tr>\n<td>10</td>\n<td>#10</td>\n<td>a</td>\n</tr>\n<tr>\n<td>11</td>\n<td>#11</td>\n<td>z</td>\n</tr>\n</tbody>\n</table>\n</div><hr />\n<p><strong>Example users</strong></p>\n<pre><code>SELECT * FROM users;\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id</th>\n<th>username</th>\n<th>ref1</th>\n<th>ref2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>bobo</td>\n<td>a</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>toto</td>\n<td>b</td>\n<td>e</td>\n</tr>\n<tr>\n<td>3</td>\n<td>momo</td>\n<td>c</td>\n<td>d</td>\n</tr>\n<tr>\n<td>4</td>\n<td>lolo</td>\n<td>a</td>\n<td>f</td>\n</tr>\n<tr>\n<td>5</td>\n<td>popo</td>\n<td>c</td>\n<td>f</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>What I want to get in the end</strong></p>\n<pre><code>SELECT * FROM results;\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ids</th>\n<th>usernames</th>\n<th>refs1</th>\n<th>refs2</th>\n<th>asset_ids</th>\n<th>asset_count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1,3,4,5</td>\n<td>bobo,momo,lolo,popo</td>\n<td>a,c</td>\n<td>d,f</td>\n<td>1,3,4,5,6,8,9,10</td>\n<td>8</td>\n</tr>\n<tr>\n<td>2</td>\n<td>toto</td>\n<td>b</td>\n<td>e</td>\n<td>2,7</td>\n<td>2</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td>z</td>\n<td>11</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>I've tried different approaches, but this is what I currently have:</p>\n<p><strong>Closest I have got</strong></p>\n<pre><code>SELECT\n  ARRAY_AGG(DISTINCT u.id) AS ids,\n  ARRAY_AGG(DISTINCT u.username) AS usernames,\n  ARRAY_AGG(DISTINCT u.ref1) AS refs1,\n  ARRAY_AGG(DISTINCT u.ref2) AS refs2,\n  COUNT(DISTINCT a.id) AS asset_count\nFROM assets a\nJOIN users u ON a.owner = u.ref1 OR a.owner = u.ref2\nGROUP BY a.owner\nORDER BY MIN(a.id);\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ids</th>\n<th>usernames</th>\n<th>refs1</th>\n<th>refs2</th>\n<th>asset_count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1,4</td>\n<td>bobo,lolo</td>\n<td>a</td>\n<td>d,f</td>\n<td>4</td>\n</tr>\n<tr>\n<td>2</td>\n<td>toto</td>\n<td>b</td>\n<td>e</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3,5</td>\n<td>momo,popo</td>\n<td>c</td>\n<td>d,f</td>\n<td>2</td>\n</tr>\n<tr>\n<td>1,3</td>\n<td>bobo,momo</td>\n<td>a,c</td>\n<td>d</td>\n<td>2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>toto</td>\n<td>b</td>\n<td>e</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>If I merge the above table on ids, I almost get the result I want (without the missing entries in the user table). The merging can easily be done in code, but then I cannot paginate etc. I want to to this in DB layer if possible.</p>\n<p>I want either a solution to the problem or a good explanation of why it is not possible to do (with examples). Please provide a JavaScript (Node.js) solution, and if SQL is required, include how to execute it from JavaScript.</p>\n<p>Please check out my <a href=\"https://www.db-fiddle.com/f/4jyoMCicNSZpjMt4jFYoz5/8836\" rel=\"noreferrer\">DB Fiddle</a>.</p>",
  "Title: Array.prototype.sort causes “Cannot read properties of undefined” even though w <= arr1.length\nBody: <p>The code below throws an error like “Cannot read properties of undefined (reading '0')”.  \nI don’t understand why, <code>w</code> is guaranteed to be &lt;= <code>arr1.length</code>.</p>\n<pre><code>function testFunc() {\n  return Math.random() &gt; 0.5;\n}\n\nfunction tempFunc() {\n  const arr1 = new Array(5);\n  let w = 0;\n\n  for (let i = 0; i &lt; 5; i++) {\n    if (testFunc()) {\n      arr1[w] = [3, 4];\n      w++;\n    }\n  }\n\n  arr1.sort((a, b) =&gt; a[0] - b[0]);\n\n  return 0;\n}\n</code></pre>",
  "Title: Why is this JavaScript program producing an Array of Arrays rather than a simple Array?\nBody: <pre><code>const f = new Map();\nfor (const file of fs.readdirSync(os.homedir(), { withFileTypes: true })) {\n  const filename = file.name;\n  if (!f.has(filename)) f.set(filename, []);\n  f.get(filename).push([file, Math.random()]);\n}\nconst p = Array.from(f.entries())[Math.floor(Math.random() * f.size)];\nconsole.log(Array.isArray(p));\nconsole.log(`${Array.isArray(p[1])} has ${p[1].length} elements`);\nconsole.log(`${Array.isArray(p[1][0])} has ${p[1][0].length} elements`);\n\nconsole.log('');\nconsole.log(process.version);\nconsole.log(os.platform());\nconsole.log(os.release());\nconsole.log(process.versions.v8);\n</code></pre>\n<p>Output:</p>\n<pre><code>true\ntrue has 1 elements\ntrue has 2 elements\n\nv20.x.x\ndarwin\n22.x.x\n10.x.x\n</code></pre>\n<p>Why is the value of <code>p</code> an array containing another array, rather than a simple array?</p>",
  "Title: Insert one array into another at a specific index?\nBody: <p>In JavaScript I can concatenate arrays with <code>concat()</code> or spread, but that adds the second array to the end of the first.</p>\n<pre><code>const arr1 = [1, 4, 5];\nconst arr2 = [2, 3];\n\nconst result = arr1.concat(arr2);\n\nOutput:\n[1, 4, 5, 2, 3]\n</code></pre>\n<p>How would I add the second array so it becomes part of the first element, resulting in:</p>\n<pre><code>[1, 2, 3, 4, 5]\n</code></pre>\n<p>I tried using <code>arr1.splice(1, 0, arr2)</code> and got:</p>\n<pre><code>[1, [2, 3], 4, 5]\n</code></pre>\n<p>How do I insert the elements of <code>arr2</code> into <code>arr1</code> at index 1 without nesting?</p>",
  "Title: Can you initialize a \"const char array\" with a string literal in JavaScript?\nBody: <p>In JavaScript, I want a fixed array of character bytes and I’m using a typed array. It’s not clear whether a string literal can directly initialize a typed array, or whether I need an explicit conversion step.</p>\n<p>This matters in the following situation:</p>\n<pre><code>const str = new Uint8Array(\"test\"); // is this valid?\n</code></pre>\n<p>I’m 99% sure you need a conversion like <code>new TextEncoder().encode(\"test\")</code>, but is there a definitive rule in ECMAScript or the typed array APIs that allows or disallows direct initialization from a string literal?</p>",
  "Title: Is V8 wrong to allow initializing a const array property with another array reference?\nBody: <p>While (re)implementing a simple constexpr-like map, I wrote this:</p>\n<pre class=\"lang-js prettyprint-override\"><code>class FlatMap {\n  #elements;\n  constructor(arr) {\n    this.#elements = arr; // works in V8?!\n  }\n\n  get(key) {\n    for (const elem of this.#elements) {\n      if (elem.key === key) return elem.value;\n    }\n    throw new Error(\"Key not found\");\n  }\n}\n\nconst m = new FlatMap([\n  { key: 4, value: \"a\" },\n  { key: -1, value: \"b\" },\n  { key: 42, value: \"c\" }\n]);\n\nconsole.assert(m.get(4) === \"a\");\nconsole.assert(m.get(-1) === \"b\");\nconsole.assert(m.get(42) === \"c\");\n\nfunction main() {\n  return m.get(4); // \"a\"\n}\n</code></pre>\n<p>I naively thought to set the private array <code>#elements</code> as <code>const</code> and initialize it in the constructor; I was using V8 as the engine, and all was seemingly working well. When I decided to try it with other runtimes, I had errors complaining about the array initialization requiring a different shape.</p>\n<p>In hindsight the other runtimes aren't particularly wrong, are they? Am I inadvertently using some V8-specific behavior here?</p>\n<p>By the way, what would you do to avoid copying the array elements by hand?</p>",
  "Title: why `number[6]` arrays can’t be used in a tuple type in TypeScript?\nBody: <p>Why can’t the TypeScript code below compile?</p>\n<pre><code>const x: number[] = new Array(6);\nconst y: number[] = new Array(6);\n\nconst a: [number[6], number[6]] = [x, y];\n</code></pre>\n<p>TypeScript reports that <code>number[6]</code> is not a valid type. I know there are alternative ways to represent fixed-length arrays, but I want to understand the reason this form isn’t allowed.</p>",
  "Title: toSpliced() method throwing TypeError in VS Code Debug Console.\nBody: <p>I am getting the following error on VS Code Debug Console;</p>\n<p>&quot;Uncaught TypeError TypeError: months.toSpliced is not a function&quot;</p>\n<p>when I run this code;</p>\n<pre><code>const months = [&quot;Jan&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;];\n\n// Inserting an element at index 1\nconst months2 = months.toSpliced(1, 0, &quot;Feb&quot;);\nconsole.log(months2); // [&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;]\n</code></pre>\n<p>It is not even my code, I copy-pasted it from here; <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/toSpliced\" rel=\"noreferrer\">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/toSpliced</a></p>\n<p>I came across this error while trying to learn toSpliced() method.</p>\n<p>Any help would be highly appreciated. Thank you.</p>",
  "Title: Is a two-dimensional array implemented as a continuous one-dimensional array?\nBody: <p>I have a question about the memory layout of a two-dimensional array in JavaScript.\nWhen we define one, like <code>const a = [[1,2,3,4],[5,6,7,8],[9,10,11,12]]</code>, is the memory allocated for this array continuous?</p>\n<p>Or in other words, is a two-dimensional array implemented as a continuous one-dimensional array?</p>\n<p>If the answer is yes, is accessing <code>a[0][6]</code> equivalent to accessing <code>a[1][2]</code>?</p>\n<p>I wrote the following program.</p>\n<pre><code>const a = [\n  [1, 2, 3, 4],\n  [5, 6, 7, 8],\n  [9, 10, 11, 12]\n];\n\nconsole.log(a[0][6], a[1][2]);\n</code></pre>\n<p>I find that the output is <code>undefined 7</code>.</p>\n<p><code>a[0][6]</code> seems illegal, but I want to know why and whether such an operation is legal in JavaScript.</p>",
  "Title: How to shuffle array of items but allow weights to influence the order.\nBody: <p>I'm trying to write a TypeScript function to shuffle an array.</p>\n<p>By default, I want the shuffle order to be random (but subject to a seed).\n(I already have access to this function: <code>function random(seed: number): number</code>)</p>\n<p>However, I want to also allow influencing the order via weights per item.</p>\n<p>In other words, I want the the default item weight to be 1, and if an item has a weight of 10, it should be 10 times more likely to appear sooner in the shuffled order.</p>\n<p>Am I even thinking about this correctly? Is this a reasonable goal?</p>\n<p>I was thinking that I'd need to use the Fisher-Yates algorithm but adapted to honor a weights array of the same length as the main array, and the main array will be shuffled such that higher weighted items are more likely to appear first.</p>\n<pre><code>function removeDuplicates&lt;T&gt;(array: T[]): T[] {\n  const uniqueValues = new Set&lt;T&gt;();\n  return array.filter((item) =&gt; {\n    if (!uniqueValues.has(item)) {\n      uniqueValues.add(item);\n      return true;\n    }\n\n    return false;\n  });\n}\n\nfunction duplicateItemsBasedOnWeights&lt;T&gt;(array: T[], weights: number[]): T[] {\n  const result = [];\n  for (const [index, element] of array.entries()) {\n    for (let position = 0; position &lt; weights[index]; position++) {\n      result.push(element);\n    }\n  }\n\n  return result;\n}\n\nexport function shuffleWithWeights&lt;T&gt;(array: T[], weights: number[], seed: number): T[] {\n  const arrayWithDuplicateValuesBasedOnWeights: T[] = duplicateItemsBasedOnWeights(array, weights);\n\n  const shuffledArrayWithDuplicateValuesBasedOnWeights = shuffleArrayUsingFisherYates(arrayWithDuplicateValuesBasedOnWeights, seed);\n\n  return removeDuplicates(shuffledArrayWithDuplicateValuesBasedOnWeights);\n}\n</code></pre>\n<p>I've looked at empirical results by calling it a bunch of different times with these values (and a different seed each time), and the results don't seem distributed how I'd hoped, so I must have been approaching this problem incorrectly.</p>\n<pre><code>const items = [1, 2, 3, 4, 5];\nconst weights = [1, 1, 1, 200, 1_000];\n</code></pre>\n<p>In my real-world cases, I'll be shuffling 70,000 objects (which would explore to <em>many</em> more than that if I use my current approach of creating duplicate items based on item weight).</p>",
  "Title: Why does a nested array object prevent providing storage?\nBody: <p>At <a href=\"https://en.cppreference.com/w/cpp/language/lifetime\" rel=\"noreferrer\">Lifetime</a> under <strong>Providing storage</strong>, it says:</p>\n<blockquote>\n<p>As a special case, objects can be created in arrays of unsigned char or std::byte (since C++17) (in which case it is said that the array provides storage for the object) if</p>\n<ul>\n<li>the lifetime of the array has begun and not ended</li>\n<li>the storage for the new object fits entirely within the array</li>\n<li>there is no array object that satisfies these constraints nested within the array.</li>\n</ul>\n</blockquote>\n<p>Why is the third condition there?</p>\n<p>Even if there's a nested array (I believe it means an array which starts at some index of the outer array and ends at an index that's no farther, not an array which is an item of the outer array, as the term nested would probably be understood in most languages), what difficulty does it pose to the standard authors or implementations to enable a segment of the outer array disjoint with the nested array to provide storage?</p>\n<p>And, if the nested array doesn't have any array nested in it, do I understand correctly that it can provide storage? If so, why can't the outer array provide storage in the same place, i.e. with the segment providing storage not straddling the start or end of any nested (perhaps indirectly) array?</p>\n<p>And, even with straddling, what problems could arise that the standard included this requirement to avoid?</p>\n<p>Additionally, can a nested array not satisfy the second condition, i.e. overlap it partially? Can such arrays even exist? In what sense and under what conditions is then one nested in another? Can both ever be nested in each other?</p>",
  "Title: Why can I declare an array with a constant size in some cases and not others?\n\nBody: <p>I’m trying to create a class that includes a 2D array along with some member functions.</p>\n<p>When I write:</p>\n<pre><code>class Board {\n  const BOARDSIZE = 8;\n\n  data = Array(BOARDSIZE).fill(false).map(() =&gt; Array(BOARDSIZE).fill(false));\n}\n</code></pre>\n<p>I get an error about accessing a class field before initialization. However, when I write:</p>\n<pre><code>const BOARDSIZE = 8;\n\nclass Board {\n  data = Array(BOARDSIZE).fill(false).map(() =&gt; Array(BOARDSIZE).fill(false));\n}\n</code></pre>\n<p>or:</p>\n<pre><code>class Board {\n  data = Array(8).fill(false).map(() =&gt; Array(8).fill(false));\n}\n</code></pre>\n<p>there is no error. I’ve searched around and can’t figure out why it won’t accept one and not the other. I’d rather not declare BOARDSIZE as a global variable because I don’t want it just floating around in a large project but I also don’t want to have to write 8 every time a member function of the class needs the board size for flexibility’s sake down the line.</p>\n<p>Is there a way to have a local variable that represents the size of the board?</p>",
  "Title: Obtain palindromic array by performing these operations.\nBody: <p>An array is called palindromic if it remains the same after reversing the order of its elements.</p>\n<p>You have an array of strings arr. For each i, <code>arr[i]</code> consists of at least two characters. For each pair of consecutive elements <code>arr[i]</code> and <code>arr[i + 1]</code>, you can:</p>\n<ol>\n<li>Move the rightmost character of <code>arr[i]</code> to the leftmost position in <code>arr[i + 1]</code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;ab&quot; and &quot;cdef&quot;. This operation can be applied only once to any pair of consecutive elements.</li>\n<li>Move the leftmost character of <code>arr[i + 1]</code> to the rightmost position in <code>arr[i]</code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;abcd&quot; and &quot;ef&quot;. Again, this operation can be applied only once to any pair of consecutive elements.</li>\n<li>Do nothing to the pair of consecutive elements.</li>\n</ol>\n<p>Is it possible to obtain a palindromic array from arr by performing these operations?</p>\n<p>Consider the case when arr = <code>{&quot;aa&quot;, &quot;bab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}</code>. Here the output should be true and here is why:</p>\n<p>Move first char from 1st index to the last position of 0th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}</code>\nMove last char from 3rd index to the first position of 4th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;ab&quot;, &quot;aab&quot;}</code>, which is a palindromic array.</p>\n<p>I tried solutions such as two pointer, etc. but doesn't seem to work.</p>",
  "Title: sorting an array of objects JS.\nBody: <p>Hello everyone I still can't sort the array correctly. We need to sort the following array:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const arr = [\n     {id: 3123124, parentId: 0o0000, title: 'title', type: 'block'},\n     {id: 3542132, parentId: 3123124, title: 'title', type: 'child'},\n     {id: 12345, parentId: 88888, title: 'title', type: 'block'},\n     {id: 24124, parentId: 12345, title: 'title', type: 'child'},\n     {id: 99999, parentId: 45324, title: 'title', type: 'child'},\n     {id: 986648, parentId: 3123124, title: 'title', type: 'block'},\n     {id: 77777, parentId: 88888, title: 'title', type: 'child'},\n     {id: 54232, parentId: 3123124, title: 'title', type: 'child'},\n     {id: 54308, parentId: 15075, title: 'title', type: 'child'},\n     {id: 66666, parentId: 88888, title: 'title', type: 'block'},\n     {id: 56445, parentId: 12345, title: 'title', type: 'child'},\n     {id: 88888, parentId: 45324, title: 'title', type: 'block'},\n     {id: 15075, parentId: 12345, title: 'title', type: 'block'},\n     {id: 84356, parentId: 66666, title: 'title', type: 'child'},\n     {id: 45324, parentId: 0o0000, title: 'title', type: 'block'},\n]\n\nconst newArr = [\n    {id: 3123124, parentId: 0o0000, title: 'title', type: 'block'},\n    {id: 3542132, parentId: 3123124, title: 'title', type: 'child'},\n    {id: 54232, parentId: 3123124, title: 'title', type: 'child'},\n    {id: 986648, parentId: 3123124, title: 'title', type: 'block'},\n    {id: 45324, parentId: 0o0000, title: 'title', type: 'block'},\n    {id: 99999, parentId: 45324, title: 'title', type: 'child'},\n    {id: 88888, parentId: 45324, title: 'title', type: 'block'},\n    {id: 77777, parentId: 88888, title: 'title', type: 'child'},\n    {id: 12345, parentId: 88888, title: 'title', type: 'block'},\n    {id: 56445, parentId: 12345, title: 'title', type: 'child'},\n    {id: 24124, parentId: 12345, title: 'title', type: 'child'},\n    {id: 15075, parentId: 12345, title: 'title', type: 'block'},\n    {id: 54308, parentId: 15075, title: 'title', type: 'child'},\n    {id: 66666, parentId: 88888, title: 'title', type: 'block'},\n    {id: 84356, parentId: 66666, title: 'title', type: 'child'},\n]\n</code></pre>\n<ul>\n<li>arr - array to sort</li>\n<li>newArr - is an array that should turn out to be</li>\n</ul>\n<p>So that the topmost elements have <code>parentId: 0o000</code>, and their lowest children, who have the same <code>parentId</code> <code>id</code>, and so on, there can be as many elements as you like.\nIf the <code>parentId</code> is the same for several elements, then <code>child</code> comes first, the most recent <code>block</code> and its children below, if there are any.</p>\n<p>I tried to add to a new array by the <code>parentId</code> property, but in the end the order of the elements was lost</p>",
  "Title: Error: libcublas.so.*[0-9] not found in the system path.\nBody: <p>I'm trying to import and use a CUDA-enabled library in my Node.js (Express) project. I use npm as my dependency manager, installed it with <code>npm install &lt;package-name&gt;</code>, and when I try to import it in my code I get this error</p>\n<pre><code>Error: libcublas.so.*[0-9] not found in the system path [my project and node_modules paths]\n</code></pre>\n<p>How can I solve that?</p>",
  "Title: Express returns \"Failed to lookup view 'bootstrap4/uni_form'\" when using Handlebars form helpers.\nBody: <p>Using Handlebars form helpers with Express, I only get a <code>Failed to lookup view</code> error when I use any helper related to rendering forms.</p>\n<p>I’m new to the form helper library (which seems to be universally recommended for <em>quickly</em> making forms look better), and I followed the installation instructions from its docs. As far as I can tell, the installation is correct (installed with <code>npm</code> and the view engine config is set). I’m running this in a local project on Windows.</p>\n<p>I even created a brand-new project with minimal content, and the same problem persists. The project is called <code>stuff</code> and the single router in it is <code>other</code>.</p>\n<p><strong>app.js</strong></p>\n<pre><code>const path = require('path');\nconst express = require('express');\nconst exphbs = require('express-handlebars');\nconst helpers = require('handlebars-helpers')();\n\nconst app = express();\n\napp.engine('hbs', exphbs({\n  extname: '.hbs',\n  layoutsDir: path.join(__dirname, 'views', 'layouts'),\n  partialsDir: path.join(__dirname, 'views', 'partials'),\n  helpers\n}));\napp.set('view engine', 'hbs');\napp.set('views', path.join(__dirname, 'views'));\n\napp.use(express.urlencoded({ extended: true }));\n\napp.get('/', (req, res) =&gt; {\n  res.render('test', { aform: { name: '', email: '' } });\n});\n\nmodule.exports = app;\n</code></pre>\n<p><strong>models/Mine.js</strong></p>\n<pre><code>const mongoose = require('mongoose');\n\nconst MineSchema = new mongoose.Schema({\n  name: { type: String, maxlength: 100 },\n  email: { type: String }\n});\n\nmodule.exports = mongoose.model('Mine', MineSchema);\n</code></pre>\n<p><strong>views/test.hbs</strong></p>\n<pre><code>{{! load bootstrap4 helpers }}\n{{! load form helpers }}\n&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n  &lt;meta charset=&quot;UTF-8&quot;&gt;\n  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;\n  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n  &lt;title&gt;TestThing&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;form action=&quot;/&quot;&gt;\n    {{{form aform}}}\n  &lt;/form&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p><strong>npm ls --depth=0</strong></p>\n<pre><code>express@4.18.2\nexpress-handlebars@7.1.2\nhandlebars-helpers@0.10.0\nmongoose@7.0.3\nbootstrap@4.6.2\n</code></pre>\n<p><strong>error reported in the console</strong></p>\n<pre><code>Error: Failed to lookup view \"bootstrap4/uni_form\" in views directory \"C:\\ProjectDir\\stuff\\views\"\n</code></pre>\n<p><em><strong>View lookup</strong></em></p>\n<pre><code>Express looked for these templates, in this order:\n\nC:\\ProjectDir\\stuff\\views\\bootstrap4\\uni_form.hbs (not found)\nC:\\ProjectDir\\stuff\\views\\partials\\bootstrap4\\uni_form.hbs (not found)\nC:\\ProjectDir\\stuff\\node_modules\\bootstrap\\templates\\bootstrap4\\uni_form.hbs (not found)\n</code></pre>\n<p>It looks to me like the helper library can’t see templates that should have been installed. Or is there something else I’m supposed to download or create?</p>\n<p>I wanted to quickly tidy a form in my Express app before moving on, and hours later I still can’t get the form helper to render at all. It’s clear I’m missing something, but what?</p>\n<p><strong>Other weird things I tried</strong></p>\n<ul>\n<li>Setting the template pack string to a wrong value — this results in a different error suggesting <code>bootstrap3</code>, <code>bootstrap4</code>, or <code>uni_form</code>. But repeating keeps the error above (even with the misspelling).</li>\n<li>Removing <code>bootstrap</code> and loading it from CDN (no difference).</li>\n<li>Creating a blank file at the path shown for the missing template, which just fails to render the form.</li>\n<li>Using <code>{{{crispy aform}}}</code> — same result.</li>\n</ul>",
  "Title: How to fetch data server-side in the latest Next.js? Tried getStaticProps but it&#39;s not running and getting undefined.\nBody: <p>I am working on a Django Rest Framework with Next.js, and I am getting stuck with fetching data from the API. I have data in this url <code>http://127.0.0.1:8000/api/campaigns</code> and when I visit the url I see the data.</p>\n<p>The problem is when I fetch and console the data with Next.js, I get <code>undefined</code>. Also when I try mapping the data, I get the error:</p>\n<blockquote>\n<p>Unhandled Runtime Error</p>\n<p>Error: Cannot read properties of undefined (reading 'map')</p>\n</blockquote>\n<p>Here is my <code>Index.js</code> file where the data fetching is done:</p>\n<pre><code>import React from 'react'\n\nexport default function Index ({data}) {\n  console.log(data)\n  return (\n    &lt;div&gt;\n      &lt;main&gt;\n        &lt;h1&gt;Available Campaigns&lt;/h1&gt;\n        {data.map((element) =&gt; &lt;div key={element.slug}&gt;\n          &lt;div&gt;\n            &lt;div&gt;\n              &lt;img src={element.logo} height={120} width={100} alt=&quot;image&quot; /&gt;\n            &lt;/div&gt;\n            &lt;div&gt;&lt;/div&gt;\n          &lt;/div&gt;\n\n        &lt;/div&gt;)}\n      &lt;/main&gt;\n    &lt;/div&gt;\n  );\n}\n\nexport async function getStaticProps() {\n  const response = await fetch(&quot;http://127.0.0.1:8000/api/campaigns&quot;);\n  const data = await response.json();\n  return {\n    props: {\n      data: data\n    },\n  }\n}\n</code></pre>\n<p>Here is a screenshot of the data I am getting when I visit the URL:</p>\n<p><a href=\"https://i.stack.imgur.com/4vU7y.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/4vU7y.png\" alt=\"Image\" /></a></p>\n<p>Here is the file structure for the Next.js app inside the front end:</p>\n<p><a href=\"https://i.stack.imgur.com/MnfjC.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/MnfjC.png\" alt=\"File Structure\" /></a></p>\n<p>Also, note that I am using the latest version of Next.js. Any help will be highly appreciated. Thanks.</p>",
  "Title: Express admin showing a white box instead of toggle theme icon.\nBody: <p>As I open the Express admin page, a wide white box appears instead of the theme icon (using Express 4.18.2).</p>\n<p><a href=\"https://i.stack.imgur.com/dXqnL.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/dXqnL.png\" alt=\"admin page as appears on production\" /></a></p>\n<p>While testing on Docker container, everything seems ok.</p>\n<p><a href=\"https://i.stack.imgur.com/zoDtk.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/zoDtk.png\" alt=\"admin page while testing on Docker container\" /></a></p>\n<p>I have been looking at the <a href=\"https://docs.djangoproject.com/en/4.1/ref/contrib/admin/#theming-support\" rel=\"noreferrer\">documentation</a> on overriding admin/base.html, but I'm not sure this is the issue.</p>\n<p>Checking the log after deployment (on EC cloud), nothing comes to my attention.</p>\n<p>I am letting serve the static content by nginx (1.23).</p>\n<pre><code>node app.js build --noinput\n</code></pre>\n<p>Overall, all static files are working properly on the rest of the site.</p>\n<p>I tried inspecting the element <code>&lt;button class=&quot;theme-toggle&quot;&gt;</code>. Nothing anomalous.</p>\n<p>Everything looks <em>normal</em> to me. Apart from this, production looks identical to the Docker container.</p>",
  "Title: How to safely and atomically decrement a counter with Node.js and PostgreSQL?\nBody: <p>I've been reading up on PostgreSQL transaction isolation and how that relates to Sequelize transactions (e.g. <a href=\"https://charemza.name/blog/posts/django/postgres/transactions/not-as-atomic-as-you-may-think/\" rel=\"noreferrer\">this article</a>, <a href=\"https://www.postgresql.org/docs/15/transaction-iso.html\" rel=\"noreferrer\">PostgreSQL docs</a>), but I'm far from fluent in this topic and I'm not sure I understand what I've read.</p>\n<p>We've got a PostgreSQL-backed Node.js app using Sequelize that involves quota objects. Simplified, it's just this:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const Quota = sequelize.define('Quota', {\n  objId: {\n    type: DataTypes.INTEGER,\n    unique: true,\n    allowNull: false\n  },\n  count: {\n    type: DataTypes.INTEGER,\n    allowNull: false\n  }\n});\n</code></pre>\n<p>An instance of this controls how many times a certain operation can be performed against the <code>obj</code> instance. <code>count</code> is initialized to a certain number, and will only ever decrement until it hits zero.</p>\n<p>Any number of processes/threads can concurrently perform these operations. Basically, we need to atomically decrement (with UPDATE) the <code>count</code> of a single database row without deadlocking and without two processes/threads ever e.g. starting with a <code>count</code> of 100 and both trying to decrement it to 99.</p>\n<p>My naive approach would be this:</p>\n<pre class=\"lang-js prettyprint-override\"><code>await sequelize.transaction(\n  { isolationLevel: Transaction.ISOLATION_LEVELS.SERIALIZABLE },\n  async (t) =&gt; {\n    await Quota.update(\n      { count: sequelize.literal('count - 1') },\n      { where: { objId: instanceId }, transaction: t }\n    );\n  }\n);\n</code></pre>\n<p>However, I'm not sure if this is subject to this issue, from the linked article:</p>\n<blockquote>\n<p>if at COMMIT the database cannot determine that the transaction could have been performed serially with respect to the read/writes of other transactions, then it will fail with a django.db.DatabaseError. This can happen even if they updated different rows.</p>\n</blockquote>\n<p>All the processes/threads performing operations against the same <code>obj</code> would be decrementing the same column of the same row, so... maybe? I don't actually know what's involved in PostgreSQL &quot;determin[ing] that the transaction could have been performed serially&quot;.</p>\n<p>An alternate approach could be:</p>\n<pre class=\"lang-js prettyprint-override\"><code>await sequelize.transaction(async (t) =&gt; {\n  const row = await Quota.findOne({\n    where: { objId: instanceId },\n    lock: t.LOCK.UPDATE,\n    transaction: t\n  });\n\n  await row.update(\n    { count: sequelize.literal('count - 1') },\n    { transaction: t }\n  );\n});\n</code></pre>\n<p>This seems to do row-level locking, and my understanding is that the isolation level change isn't needed, but I don't know if this is sufficient for correct handling of concurrent operations.</p>\n<p>Is one of these approaches preferrable here, and are some modifications still necessary to guarantee atomicity and deadlock avoidance? We could use something like <code>redlock</code> to also prevent concurrent DB operations at the application level, but this feels like a more natural fit to do at the DB level.</p>",
  "Title: how to resolve Node.js: SyntaxError: The requested module does not provide an export named 'parseHeader'.\nBody: <p>My application was running fine till few days back, but now all of a sudden i'm seeing this error and not sure what it means, please help.</p>\n<p>Error:</p>\n<pre><code>File \"/myproj/myapp/routes.js\", line 8, in &lt;module&gt;\nimport { routers } from \"my-rest-framework\";\nFile \"/usr/local/lib/node_modules/my-rest-framework/routers.js\", line 22, in &lt;module&gt;\nimport { views } from \"my-rest-framework\";\nFile \"/usr/local/lib/node_modules/my-rest-framework/views.js\", line 15, in &lt;module&gt;\nimport { Request } from \"my-rest-framework/request\";\nFile \"/usr/local/lib/node_modules/my-rest-framework/request.js\", line 17, in &lt;module&gt;\nimport { parseHeader } from \"multipartparser\";\nSyntaxError: The requested module 'multipartparser' does not provide an export named 'parseHeader'\n</code></pre>\n<p>my line 8 of routes.js is:</p>\n<pre><code>import { routers } from \"my-rest-framework\";\n</code></pre>\n<p>and i could see the parseHeader function in the multipartparser.js file PFA</p>\n<p><a href=\"https://i.stack.imgur.com/c70Wy.png\" rel=\"noreferrer\">multipartparser file</a></p>",
  "Title: Mongoose embedded schema throws validation error because of renamed field\nBody: <p>I have a Node.js app using <code>mongoose</code>. My schemas are:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const mongoose = require('mongoose');\n\nconst BlogSchema = new mongoose.Schema({\n  _id: mongoose.Schema.Types.ObjectId,\n  name: { type: String, maxlength: 100, alias: 'Name' },\n  tagline: String\n});\n\nconst EntrySchema = new mongoose.Schema({\n  _id: mongoose.Schema.Types.ObjectId,\n  blog: BlogSchema\n});\n</code></pre>\n<p>When I run this app, I get a validation error complaining that the field name in the embedded schema doesn’t match the database field name.</p>\n<p>I want to keep the property name <code>name</code> in my code and the database field <code>Name</code> because the database already exists and I can’t change it. The database uses camelCase, while the app uses snake_case.</p>\n<p>How do I avoid this error?</p>",
  "Title: MySQL 8 or later is required (found 5.7.33) when running migrations in Sequelize\nBody: <p>I get this error when running migrations from my command line.</p>\n<p>I tried this command:</p>\n<pre><code>npx sequelize-cli db:migrate\n</code></pre>\n<p><strong>but the error persists</strong></p>\n<pre><code>MySQL 8 or later is required (found 5.7.33).\n</code></pre>\n<p>Is there any way to perform the migration, or should I downgrade my Node version to v9?</p>\n<p><strong>node version</strong></p>\n<pre><code>node v18\n</code></pre>",
  "Title: Microservices architecture with Node.js.\nBody: <p>I have some questions about creating microservices with Node.js.</p>\n<p>Let's say we have an online shop or a larger system with many database requests and users. I want to practice and simulate a simple microservice to learn something new.</p>\n<p>We want to create a microservices-based system with the following components:</p>\n<ol>\n<li>A Node.js-based microservice with its admin panel and full functionality (excluding GraphQL).</li>\n<li>One or more microservices with a React/Angular frontend.</li>\n<li>Several additional microservices to separate functionalities.\nI'm unsure about the architecture. Let's assume we want to manage data using the admin panel.</li>\n</ol>\n<p>The simplest solution would be to add a REST API to the first microservice and extend its functionality - instead of creating different services (3.).</p>\n<ol>\n<li>But what if we want to separate functionality into different microservices?</li>\n<li>Should the microservices in point 3 be connected to the same database and treated as different Node.js projects?</li>\n<li>Can we use Go, FastAPI, or Java Spring for the third microservice? If yes, should all models be duplicated and registered in the first microservice?</li>\n<li>Alternatively, is there a better way to approach this?</li>\n</ol>\n<p>It would be great to hear your perspective and methods on how to proceed with this.</p>\n<p>Have a wonderful day!</p>",
  "Title: Node.js “Detected change in …, restarting” Message in Docker\n\nBody: <p>I’m having a problem I don’t understand and can’t resolve.</p>\n<p>I have a Dockerised Node.js project, which I created using a Cookiecutter-style template months ago. Today my development environment started showing the following message on every request:</p>\n<p><a href=\"https://i.stack.imgur.com/jq1A9.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/jq1A9.png\" alt=\"code of error\" /></a></p>\n<p>I’m not seeing this in production. I tried rolling back to commits that worked before (for example, commits from one week ago), and I’m still getting this message.</p>\n<p>The restarting is closing database connections, so the app is unusable.</p>\n<p>Does anyone know what causes this and how to fix it? It feels like a Docker setup issue, but the Docker configuration hasn’t changed in months, so I don’t understand why it would start now.</p>\n<p>Many thanks for any help!</p>",
  "Title: libsodium/sodium-native errors while building arm64 Node images for Node/Express\n\nBody: <p>Summary:\nI am trying to build an ARM64 image for my project to be able to run it faster locally on my MacBook M1 (Pro), instead of using normal x64 images which run extremely slow (long startup time, long response time for local dev HTTP server, long test running times).</p>\n<p>I have the following Dockerfile:</p>\n<pre><code>FROM arm64v8/node:16-bullseye\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    curl \\\n    build-essential \\\n    python3 \\\n    pkg-config \\\n    libssl-dev \\\n    libsodium-dev\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package*.json ./\n\n# Install Node dependencies\nRUN npm ci\n\n# Copy the project files to the container\nCOPY . .\n\n# Expose the development server port\nEXPOSE 3000\n\n# Start the dev server\nCMD [\"npm\", \"run\", \"dev\"]\n</code></pre>\n<p><code>package.json</code>:</p>\n<pre><code>{\n  \"name\": \"my-app\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"node server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"4.18.2\",\n    \"cors\": \"2.8.5\",\n    \"dotenv\": \"16.0.3\",\n    \"pg\": \"8.10.0\",\n    \"redis\": \"4.5.1\",\n    \"bull\": \"4.10.1\",\n    \"axios\": \"1.3.4\",\n    \"jsonwebtoken\": \"9.0.0\",\n    \"passport\": \"0.6.0\",\n    \"passport-jwt\": \"4.0.1\",\n    \"sequelize\": \"6.29.3\",\n    \"sequelize-cli\": \"6.6.0\",\n    \"knex\": \"2.4.2\",\n    \"winston\": \"3.8.2\",\n    \"pino\": \"8.10.0\",\n    \"multer\": \"1.4.5-lts.1\",\n    \"nodemailer\": \"6.9.1\",\n    \"yup\": \"1.0.2\",\n    \"date-fns\": \"2.29.3\",\n    \"uuid\": \"9.0.0\",\n    \"sodium-native\": \"3.4.0\"\n  }\n}\n</code></pre>\n<p>Traceback:\n<code>https://pastebin.com/1xtwdfXY</code> (too long to paste here)</p>\n<p>I have already tried everything you can find online, including:</p>\n<ul>\n<li>Installing libsodium via apt instead of via npm</li>\n<li>Installing a specific version of <code>sodium-native</code> (<code>3.4.0</code>)</li>\n<li>Installing libsodium locally on the host machine (macOS) via <code>brew install libsodium</code></li>\n</ul>\n<p>But sadly nothing helps. Sources:</p>\n<ul>\n<li><code>https://github.com/holepunchto/sodium-native/issues</code></li>\n<li><code>https://github.com/jedisct1/libsodium/issues</code></li>\n<li><code>https://github.com/sodium-friends/sodium-native</code></li>\n<li><code>https://github.com/jedisct1/libsodium</code></li>\n<li><code>https://stackoverflow.com/search?q=sodium-native+arm64</code></li>\n</ul>",
  "Title: NextAuth - Cannot find module 'next-auth/middleware' even when next-auth is properly installed.\n\nBody: <p>\"Cannot find module 'next-auth/middleware'\"</p>\n<p>I keep getting this error in my Next.js app even when next-auth is installed and set up???</p>\n<p>I tried reinstalling and switching Node versions but nothing changed. I can import other modules fine, but the middleware import keeps failing…</p>\n<p>Help pls?</p>\n<p>next.config.js:</p>\n<pre><code>/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  reactStrictMode: true,\n};\n\nmodule.exports = nextConfig;\n</code></pre>\n<p>middleware.js:</p>\n<pre><code>import { withAuth } from \"next-auth/middleware\";\n\nexport default withAuth({\n  pages: {\n    signIn: \"/login\",\n  },\n});\n\nexport const config = {\n  matcher: [\"/dashboard/:path*\"],\n};\n</code></pre>\n<p>package.json (deps):</p>\n<pre><code>{\n  \"dependencies\": {\n    \"next\": \"13.5.6\",\n    \"react\": \"18.2.0\",\n    \"react-dom\": \"18.2.0\",\n    \"next-auth\": \"^4.24.7\"\n  }\n}\n</code></pre>\n<p>Tried reinstalling next-auth through npm, clearing node_modules, other StackOverflow solutions, and the docs. Nothing worked so far.</p>\n<p>Error location:</p>\n<pre><code>import { withAuth } from \"next-auth/middleware\";\n</code></pre>",
  "Title: Express + Mongoose, \"Cannot read properties of null (reading 'path')\" when adding a child page\nBody: <p>I’m trying to integrate a page tree into an existing Express app, but I’m getting the above error when I add a child page.</p>\n<p>In my app setup I have the following:</p>\n<pre><code>const express = require('express');\nconst path = require('path');\nconst session = require('express-session');\nconst cors = require('cors');\nconst helmet = require('helmet');\n\nconst app = express();\n\napp.use(helmet());\napp.use(cors());\napp.use(express.urlencoded({ extended: true }));\napp.use(express.json());\napp.use(session({ secret: 'secret', resave: false, saveUninitialized: false }));\n\napp.use(express.static(path.join(__dirname, 'public')));\n\napp.use('/', require('./routes/home'));\napp.use('/news', require('./routes/news'));\napp.use('/cms', require('./routes/cms'));\n</code></pre>\n<p>my project routes:</p>\n<pre><code>const express = require('express');\nconst router = express.Router();\n\nrouter.use('/', require('./home'));\nrouter.use('/news', require('./news'));\nrouter.use('/cms', require('./cms'));\n\nmodule.exports = router;\n</code></pre>\n<p>my news routes:</p>\n<pre><code>const express = require('express');\nconst router = express.Router();\nconst { newsArticleDetail } = require('../controllers/news');\n\nrouter.get('/news/:id', newsArticleDetail);\n\nmodule.exports = router;\n</code></pre>\n<p>in my news controller:</p>\n<pre><code>const NewsArticle = require('../models/NewsArticle');\n\nasync function newsArticleDetail(req, res, next) {\n  try {\n    const newsArticle = await NewsArticle.findById(req.params.id);\n    res.render('news/news_page', { newsArticle });\n  } catch (err) {\n    next(err);\n  }\n}\n\nmodule.exports = { newsArticleDetail };\n</code></pre>\n<p>and my model:</p>\n<pre><code>const mongoose = require('mongoose');\n\nconst NewsArticleSchema = new mongoose.Schema({\n  title: { type: String, required: true },\n  articleBody: { type: String },\n  parent: { type: mongoose.Schema.Types.ObjectId, ref: 'Page' },\n  path: { type: String }\n});\n\nmodule.exports = mongoose.model('NewsArticle', NewsArticleSchema);\n</code></pre>\n<p>and in my template:</p>\n<pre><code>&lt;% extends('base') %&gt;\n\n&lt;% block('content') %&gt;\n  &lt;h1&gt;&lt;%= newsArticle.title %&gt;&lt;/h1&gt;\n  &lt;%- newsArticle.articleBody %&gt;\n&lt;% endblock %&gt;\n</code></pre>\n<p>I’ve also added the root page, made sure the routes are pointing to the correct place, ran migrations for my schema, but I still get the same error. When I go to localhost:7000/cms in the admin, I have a page set up. When I try to add a child page I get the error. Here is the stack trace:</p>\n<p>Environment:</p>\n<p>Request Method: POST<br>\nRequest URL: http://127.0.0.1:7000/cms/pages/add/news/article/2/</p>\n<pre><code>TypeError: Cannot read properties of null (reading 'path')\n    at addChild (C:\\project\\node_modules\\your-cms-lib\\lib\\tree.js:210:22)\n    at processAdd (C:\\project\\node_modules\\your-cms-lib\\lib\\create.js:95:10)\n    at Layer.handle [as handle_request] (C:\\project\\node_modules\\express\\lib\\router\\layer.js:95:5)\n    at next (C:\\project\\node_modules\\express\\lib\\router\\route.js:144:13)\n    at Route.dispatch (C:\\project\\node_modules\\express\\lib\\router\\route.js:114:3)\n    at Layer.handle [as handle_request] (C:\\project\\node_modules\\express\\lib\\router\\layer.js:95:5)\n    at C:\\project\\node_modules\\express\\lib\\router\\index.js:284:15\n    at Function.process_params (C:\\project\\node_modules\\express\\lib\\router\\index.js:346:12)\n</code></pre>",
  "Title: JWT refresh token is empty on login in Node.js (Express)\nBody: <p>I’m having trouble with a JWT auth setup in Node.js. When I sign up a new account, the response includes both access and refresh tokens, but when I log in with credentials I only get the access token and the refresh token is an empty string. I configured everything per the docs/tutorial I’m following. Any idea why this happens?</p>\n<p>UPDATE: I found the refresh token is correctly set in the response header as a cookie, but it’s not in the response body and shows as empty.</p>\n<p>Server setup</p>\n<pre><code>const express = require('express');\nconst cookieParser = require('cookie-parser');\n\nconst app = express();\napp.use(express.json());\napp.use(cookieParser());\n\nconst jwtConfig = {\n  accessCookie: 'access',\n  refreshCookie: 'refresh',\n};\n</code></pre>\n<p>Response:</p>\n<pre><code>{\n  \"accessToken\": \"eyJhbGciOiJ.....\",\n  \"refreshToken\": \"\",\n  \"user\": {\n    \"id\": 2,\n    \"username\": \"test_user_0\",\n    \"email\": \"test0@mysite.co\",\n    \"firstName\": \"\",\n    \"lastName\": \"\"\n  }\n}\n</code></pre>",
  "Title: \"error: --plat-name must be one of ('win32', 'win-amd64', 'win-arm32', 'win-arm64')\" when installing node-postgres on Windows 11 in a Node.js project\n\nBody: <p>npm version: 10.2.0</p>\n<p>Node.js version: 18.18.2</p>\n<p>OS: Windows 11</p>\n<p>My Node.js project uses a local environment. Installing the PostgreSQL driver fails. The log shows a native build failure and mentions that a metadata field is deprecated.</p>\n<p>I haven’t found any solutions for my platform even though solutions exist for other platforms. Both node-gyp and npm are latest.</p>\n<p><code>npm install pg --prefer-online</code> also does not work.</p>\n<p>The full error is below:</p>\n<pre><code>\nPS C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods&gt; npm install pg\nnpm ERR! code 1\nnpm ERR! path C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\\\node_modules\\\\pg\nnpm ERR! command failed\nnpm ERR! command C:\\\\Windows\\\\system32\\\\cmd.exe /d /s /c node-gyp rebuild\ngyp info it worked if it ends with ok\ngyp info using node-gyp@10.0.1\ngyp info using node@18.18.2 | win32 | x64\ngyp info find Python using Python version 3.11.5 found at \"C:\\\\Python311\\\\python.exe\"\ngyp info spawn C:\\\\Python311\\\\python.exe\ngyp info spawn args [\ngyp info spawn args   'C:\\\\Users\\\\Aavash\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\node-gyp\\\\gyp\\\\gyp_main.py',\ngyp info spawn args   'binding.gyp',\ngyp info spawn args   '-f',\ngyp info spawn args   'msvs',\ngyp info spawn args   '-I',\ngyp info spawn args   'C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\\\node_modules\\\\pg\\\\build\\\\config.gypi',\ngyp info spawn args   '-I',\ngyp info spawn args   'C:\\\\Users\\\\Aavash\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\node-gyp\\\\addon.gypi',\ngyp info spawn args   '-I',\ngyp info spawn args   'C:\\\\Users\\\\Aavash\\\\AppData\\\\Local\\\\node-gyp\\\\Cache\\\\18.18.2\\\\include\\\\node\\\\common.gypi',\ngyp info spawn args   '-Dlibrary=shared_library',\ngyp info spawn args   '-Dvisibility=default',\ngyp info spawn args   '-Dnode_root_dir=C:\\\\Users\\\\Aavash\\\\AppData\\\\Local\\\\node-gyp\\\\Cache\\\\18.18.2',\ngyp info spawn args   '-Dnode_gyp_dir=C:\\\\Users\\\\Aavash\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\node-gyp',\ngyp info spawn args   '-Dnode_lib_file=C:\\\\Users\\\\Aavash\\\\AppData\\\\Local\\\\node-gyp\\\\Cache\\\\18.18.2\\\\&lt;(target_arch)\\\\node.lib',\ngyp info spawn args   '-Dmodule_root_dir=C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\\\node_modules\\\\pg',\ngyp info spawn args   '-Dnode_engine=v8',\ngyp info spawn args   '--depth=.',\ngyp info spawn args   '--no-parallel',\ngyp info spawn args   '--generator-output',\ngyp info spawn args   'build',\ngyp info spawn args   '-Goutput_dir=.'\ngyp info spawn args ]\ngyp ERR! build error\ngyp ERR! stack Error: `--target_arch` must be one of ('ia32', 'x64', 'arm', 'arm64')\ngyp ERR! stack     at verifyArchitecture (C:\\\\Users\\\\Aavash\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\node-gyp\\\\lib\\\\configure.js:210:11)\ngyp ERR! System Windows_NT 10.0.22631\ngyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\Aavash\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\node-gyp\\\\bin\\\\node-gyp.js\" \"rebuild\"\ngyp ERR! cwd C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\\\node_modules\\\\pg\ngyp ERR! node -v v18.18.2\ngyp ERR! node-gyp -v v10.0.1\ngyp ERR! not ok\n</code></pre>\n<pre><code></code></pre>\n<p>I tried updating npm, node-gyp, and build tools but that didn’t work. It installs fine globally but shows errors in my project. I’ve tried everything but nothing seems to work.</p>",
  "Title: How does a BullMQ worker run the code defined elsewhere in a job?\nBody: <p>I tried reading official documentation as well as other SO threads, but it is still not clear how BullMQ works.</p>\n<p>From what I understand:</p>\n<ol>\n<li><strong>Node.js app</strong>: BullMQ is installed in the app where the job processor function defines the work to be performed.</li>\n<li><strong>Message broker</strong>: Redis gets this job from 1. and queues it.</li>\n<li><strong>BullMQ Worker</strong>: A completely separate BullMQ worker picks up the job and runs it. This worker can be in a completely different machine even, so long as it has access to Redis.</li>\n</ol>\n<p>So, then the burning question is:</p>\n<p><strong>How does the BullMQ worker get the code defined in the processor function to run the job?</strong></p>\n<p>Basically, how does 3. get what's defined in 1. if they are only connected using Redis? Is the JavaScript code stored in Redis as a string? What is the data structure of the Redis item/record?</p>",
  "Title: Dokku: how to change heroku stack to heroku-20 or heroku-22 (from heroku-18).\nBody: <p>I have been working on an Express (JavaScript) project using Dokku (thus Heroku) for deployments. Up until today, all deployments worked just fine, but since this morning, I get this error message:</p>\n<p><em>Requested runtime 'node-18.18.0' is not available for this stack (heroku-18).</em></p>\n<p>I know that node-18.18.0 is available on heroku-18 so I assume I (finally) have to change stack since heroku-18 is deprecated.</p>\n<p>I have tried using this command on Dokku:</p>\n<p>dokku buildpacks:add --index 1 {APP-NAME} <a href=\"https://github.com/heroku/heroku-buildpack-nodejs.git\" rel=\"nofollow noreferrer\">https://github.com/heroku/heroku-buildpack-nodejs.git</a>,</p>\n<p>but it doesn't solve my problem (heroku-18 is still being used).</p>\n<p>Any help would be greatly appreciated</p>",
  "Title: How to use the OpenAI `stream: true` option in an Express response and still save the streamed content?\n\nBody: <p>I’m trying to use <code>stream: true</code> like this:</p>\n<pre><code>const completion = await openai.completions.create({\n  model: \"text-davinci-003\",\n  prompt: \"Write me a story about dogs.\",\n  temperature: 0.7,\n  max_tokens: MAX_TOKENS,\n  frequency_penalty: 1.0,\n  presence_penalty: 1.0,\n  stream: true,\n});\n</code></pre>\n<p>Unfortunately, I don’t know what to do from here to return it to my React frontend. Usually I send a normal JSON response with a status code. From what I’ve read, I need to stream the response (like with <code>res.write</code> / <code>res.end</code> in Express), but I’m not sure how to integrate that with the <code>completion</code> iterator and also save the final output once streaming finishes, since the handler ends after returning the stream. Any help?</p>",
  "Title: Too many db connections (Node.js / Express)\nBody: <p>I have deployed a Node.js app (running Express) and I’m getting a lot of <code>FATAL: sorry, too many clients already</code> from PostgreSQL.</p>\n<p>It seems like this might be related to how connections are managed in async Node servers, but I can’t find anything beyond people acknowledging it so far.</p>\n<p>Is there some way around this, or should I change how the app is served (or downgrade dependencies)?</p>\n<p>This feels like a blocking issue for using async servers with PostgreSQL. Shouldn’t it be better documented? (unless I missed it)</p>",
  "Title: How can a child validation schema access a parent field when the parent schema validates an array?\nBody: <p>If I validate the parent schema as an array, how can the child schema access the corresponding parent field value?</p>\n<pre><code>const Joi = require('joi');\n\nconst ChildSchema = Joi.object({\n  field1: Joi.string().required()\n}).custom((value, helpers) =&gt; {\n  // How do I get the parent batch_key value here?\n  // if (value.field1 !== value.batch_key) {\n  //   return helpers.error('any.invalid');\n  // }\n  return value;\n});\n\nconst ParentSchema = Joi.object({\n  child: Joi.array().items(ChildSchema).required(),\n  batch_key: Joi.string().required()\n});\n\nconst RootSchema = Joi.array().items(ParentSchema);\n\nasync function handler(req) {\n  const data = req.body;\n  const result = RootSchema.validate(data, { abortEarly: false });\n  if (result.error) throw result.error;\n}\n</code></pre>\n<p>Request data:</p>\n<pre><code>[\n  {\n    \"batch_key\": \"batch_key_value_1\",\n    \"child\": [\n      { \"field1\": \"value1\" },\n      { \"field1\": \"value2\" },\n      { \"field1\": \"value3\" }\n    ]\n  },\n  {\n    \"batch_key\": \"batch_key_value_2\",\n    \"child\": [\n      { \"field1\": \"value4\" },\n      { \"field1\": \"value5\" },\n      { \"field1\": \"value6\" }\n    ]\n  }\n]\n</code></pre>",
  "Title: Error \"TypeError: df.append is not a function\".\nBody: <p>I am trying to append an object to a DataFrame object in JavaScript, but I get the following error:</p>\n<blockquote>\n<p>TypeError: df.append is not a function</p>\n</blockquote>\n<p>As far as I know, DataFrame should allow adding rows.</p>\n<p>Code snippet:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const dfd = require(\"danfojs-node\");\n\nconst df = new dfd.DataFrame(df).append(newRow);\n</code></pre>\n<p>I was expecting the object <code>newRow</code> to be added as a new row.</p>\n<p>How can I fix it?</p>",
  "Title: read_sql_query() throws \"'OptionEngine' object has no attribute 'execute'\" with SQLAlchemy 2.0.0.\nBody: <p>First of all, I'm a totally new guys in the dev world\nI'm currently taking courses in AI / Data Science and one of my work is to use a SQL Database to make prediction using Prophet, then use these predition to make a PowerBI\nBut currently, I'm stuck with the JavaScript code, I'm not a developer initially, so I have no clue where the problem is:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const mysql = require('mysql2/promise');\n\nasync function main() {\n  const connection = await mysql.createConnection({\n    host: 'localhost',\n    user: 'root',\n    password: 'Password',\n    database: 'data',\n    port: 3306\n  });\n\n  const query =\n    \"SELECT Cle_Produit, Date_Facturation, SUM(Quantite) AS Total_Quantite FROM ventes GROUP BY Cle_Produit, Date_Facturation\";\n  const [rows] = await connection.execute(query);\n\n  // TODO: pivot rows by Date_Facturation and Cle_Produit\n  // TODO: rename columns to ds and y\n  // TODO: run Prophet forecasting in JavaScript\n  // TODO: save forecast to forecast.csv\n\n  await connection.end();\n}\n\nmain().catch(console.error);\n</code></pre>\n<p>It returns me this message:</p>\n<blockquote>\n<p>Importing plotly failed. Interactive plots will not work.\nTraceback (most recent call last):\nFile \"f:\\Backup\\Cours\\Cours\\Explo Data\\app3.py\", line 9, in\ndf = pd.read_sql_query(query, engine)\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 397, in read_sql_query\nreturn pandas_sql.read_query(\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 1560, in read_query\nresult = self.execute(*args)\nFile \"F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py\",\nline 1405, in execute\nreturn self.connectable.execution_options().execute(*args, **kwargs)\nAttributeError: 'OptionEngine' object has no attribute 'execute'</p>\n</blockquote>\n<p>Please, can somebody help me?</p>\n<p>I want this JavaScript script to create a csv file with the prediction from prophet.\nI want Prophet to use the table ventes from the DB data, and it should use the column <code>Cle_Produit</code>, <code>Quantite</code> and <code>Date_Facturation</code></p>",
  "Title: Error: Cannot find module 'danfojs-node/lib/indexes/numeric' when loading a DataFrame in Metaflow\nBody: <p>I used Metaflow in a Node.js step to load a DataFrame with <code>danfojs-node</code>. It deserialized successfully from the artifact store, but when I try to view its index using <code>df.index</code>, I get <code>Error: Cannot find module 'danfojs-node/lib/indexes/numeric'</code>. Why?</p>\n<p>I’ve looked at other answers with similar errors <a href=\"https://stackoverflow.com/questions/51285798\">here</a> and <a href=\"https://stackoverflow.com/questions/37371451\">here</a>, which say this can happen when deserializing data created with a different library version. However, my error is slightly different, and it isn’t fixed by updating the package (<code>npm install danfojs-node@latest</code>).</p>",
  "Title: `'Workbook' object has no method 'save'`\nBody: <p>I was trying the following code that I found.</p>\n<pre><code>const XLSX = require('xlsx');\n\nconst data = [\n  { Name: 'John', Age: 25, Gender: 'M' },\n  { Name: 'Jane', Age: 30, Gender: 'F' },\n  { Name: 'Adam', Age: 35, Gender: 'M' }\n];\n\nconst workbook = XLSX.utils.book_new();\nconst worksheet = XLSX.utils.json_to_sheet(data);\nXLSX.utils.book_append_sheet(workbook, worksheet, 'Sheet1');\n\n// Trying to save the workbook\nworkbook.save('output.xlsx');\n</code></pre>\n<p>But I get the following error:</p>\n<pre><code>TypeError: workbook.save is not a function\n</code></pre>\n<p>Does anyone know how to solve it?\nThanks in advance!\nGiuseppe</p>\n<p>Trying to save data from an array of objects to an Excel file using a JavaScript library</p>",
  "Title: TypeError: \"OptionEngine\" object has no method \"execute\".\nBody: <p>Sequelize v6 works in a different way — they have changed some of the API.</p>\n<p>Following investigation I found a solution.\nMy code was simply:</p>\n<pre><code>const sSettingsDf = await engineCloud.execute(query);\n</code></pre>\n<p>The error like the title, \"TypeError: 'OptionEngine' object has no method 'execute'\"</p>\n<p>I will answer my own post below.</p>\n<p>I tried using various versions but did not like the idea of getting locked with historic components.</p>",
  "Title: Databricks: Issue while creating a Spark DataFrame from a Danfo.js DataFrame.\nBody: <p>I have a Danfo.js data frame which I want to convert into a Spark data frame. Usually, I use the code below to create a Spark data frame from a Danfo.js DataFrame, but all of a sudden I started getting the error below. I know iteritems() was removed in pandas, but I’m using a modern version of Danfo.js and even tried older versions and still see the same error. The error is raised inside the Spark function. What is the solution? Which version should I install to create a Spark DataFrame? I also changed the Databricks runtime and reran but still get the same error.</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nconst df = new dfd.DataFrame({ i: [1, 2, 3], j: [1, 2, 3] });\nspark.createDataFrame(df);\n\nerror:-\nUserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  'DataFrame' object has no attribute 'iteritems'\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\nAttributeError: 'DataFrame' object has no attribute 'iteritems'\n</code></pre>",
  "Title: TypeError: query string is not executable in alasql\nBody: <p>I have a problem with the following code:</p>\n<pre><code>const alasql = require('alasql');\n\nconst df = [\n  { column1: 1, column2: 4 },\n  { column1: 2, column2: 5 },\n  { column1: 3, column2: 6 }\n];\n\nconst query = 'SELECT * FROM ? WHERE column1 &gt; 1';\n\nconst newDataframe = alasql(query, [df]);\n\nconsole.log(newDataframe);\n</code></pre>\n<p>When I run it, I get an error saying the query string isn’t executable. I installed the latest versions of Node.js and alasql. Could someone help me please?</p>",
  "Title: DataFrame to SQL table throws TypeError about schema being provided twice  \nBody: <p>I have a DataFrame in danfojs-node called <code>purchaseDf</code>. I want to load it into a SQL table so I can run SQL queries with Sequelize. I tried this:</p>\n<pre><code>const rows = purchaseDf.toJSON();\nawait sequelize.getQueryInterface().bulkInsert(\n  'purchase_df',\n  rows,\n  { schema: 'public' }\n);\n</code></pre>\n<p>But it throws a TypeError about the schema being provided multiple times.</p>\n<p>I have a DataFrame named <code>purchaseDf</code> and I need to run a query like:</p>\n<pre><code>await sequelize.query(\"select * from purchase_df where condition\");\n</code></pre>\n<p>I need the DataFrame stored as a SQL table first. On the server I only have Sequelize installed.</p>\n<p>The same code works locally in my Node.js app, but in a Databricks notebook it now fails. A week ago it was working fine in Databricks too. How can I fix this?</p>\n<p>note:- danfojs-node version '1.1.2'\nName: Sequelize\nVersion: 6.x</p>",
  "Title: Different behavior of Series.astype('string') and Series.apply(String) for date columns in danfo.js\nBody: <p>I'm working with date information in danfo.js and wanted to convert a column of dates to strings. I noticed different behavior from two approaches I expected to yield the same result.</p>\n<p>Here's a <a href=\"https://stackoverflow.com/help/minimal-reproducible-example\">MCVE</a>.</p>\n<pre class=\"lang-js prettyprint-override\"><code>const dfd = require(\"danfojs-node\");\n\n// Create a dataframe with dates according to ISO8601\nconst df = new dfd.DataFrame({ dt_column: [\"2023-01-01\", \"2023-01-02\", \"2023-01-02\"] });\n\n// Convert the strings to Date objects\n// (I expect the time portion to be 00:00:00)\ndf.addColumn(\n  \"dt_column\",\n  df[\"dt_column\"].apply((x) => new Date(x)),\n  { inplace: true }\n);\n\ndf.addColumn(\"str_from_astype\", df[\"dt_column\"].astype(\"string\"), { inplace: true });\ndf.addColumn(\"str_from_apply\", df[\"dt_column\"].apply(String), { inplace: true });\n\ndf.print();\nconsole.log();\nconsole.log(\"Datatypes of the dataframe\");\ndf.ctypes.print();\n</code></pre>\n<p><strong>Output</strong></p>\n<pre><code>   dt_column str_from_astype       str_from_apply\n0 2023-01-01      2023-01-01  2023-01-01T00:00:00.000Z\n1 2023-01-02      2023-01-02  2023-01-02T00:00:00.000Z\n2 2023-01-02      2023-01-02  2023-01-02T00:00:00.000Z\n\nDatatypes of the dataframe\ndt_column          datetime\nstr_from_astype    string\nstr_from_apply     string\n</code></pre>\n<p>If I use <code>.astype(\"string\")</code> the time information is lost and when I use <code>.apply(String)</code> the time information is retained.</p>\n<p>Why is that?</p>\n<p>(danfojs-node)</p>",
  "Title: Improving performance for a nested for loop iterating over dates in JavaScript\nBody: <p>I am looking to improve the performance of code over a large dataframe (10 million rows). My solution loops over multiple dates <code>(2023-01-10, 2023-01-20, 2023-01-30)</code> for different combinations of <code>category_a</code> and <code>category_b</code>.</p>\n<p>The working approach is shown below, which iterates over the dates for different pairings of the two-category data by first locating a subset of a particular pair. I want to refactor it to see if there is an approach that is more efficient in JavaScript.</p>\n<p>My input (<code>df</code>) looks like:</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: right;\"></th>\n<th style=\"text-align: left;\">date</th>\n<th style=\"text-align: right;\">category_a</th>\n<th style=\"text-align: right;\">category_b</th>\n<th style=\"text-align: right;\">outflow</th>\n<th style=\"text-align: right;\">open</th>\n<th style=\"text-align: right;\">inflow</th>\n<th style=\"text-align: right;\">max</th>\n<th style=\"text-align: right;\">close</th>\n<th style=\"text-align: right;\">buy</th>\n<th style=\"text-align: left;\">random_str</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: left;\">2023-01-10</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: left;\">2023-01-20</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: left;\">2023-01-30</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">3</td>\n<td style=\"text-align: left;\">2023-01-10</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: left;\">2023-01-20</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">5</td>\n<td style=\"text-align: left;\">2023-01-30</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>With 2 pairs <code>(4, 1)</code> and <code>(4,2)</code> over the days and my expected output (<code>results</code>) looks like this:</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: right;\"></th>\n<th style=\"text-align: left;\">date</th>\n<th style=\"text-align: right;\">category_a</th>\n<th style=\"text-align: right;\">category_b</th>\n<th style=\"text-align: right;\">outflow</th>\n<th style=\"text-align: right;\">open</th>\n<th style=\"text-align: right;\">inflow</th>\n<th style=\"text-align: right;\">max</th>\n<th style=\"text-align: right;\">close</th>\n<th style=\"text-align: right;\">buy</th>\n<th style=\"text-align: left;\">random_str</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: left;\">2023-01-10</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">-1</td>\n<td style=\"text-align: right;\">23</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: left;\">2023-01-20</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">-1</td>\n<td style=\"text-align: right;\">23</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: left;\">2023-01-30</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">1</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">a</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">3</td>\n<td style=\"text-align: left;\">2023-01-10</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">10</td>\n<td style=\"text-align: right;\">-2</td>\n<td style=\"text-align: right;\">24</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: left;\">2023-01-20</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">-2</td>\n<td style=\"text-align: right;\">24</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n<tr>\n<td style=\"text-align: right;\">5</td>\n<td style=\"text-align: left;\">2023-01-30</td>\n<td style=\"text-align: right;\">4</td>\n<td style=\"text-align: right;\">2</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">0</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">20</td>\n<td style=\"text-align: right;\">nan</td>\n<td style=\"text-align: left;\">b</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>I have a working solution using dataframes to take a subset then loop over it to get a solution, but I want to improve performance in JavaScript using something like <code>danfojs-node</code>, <code>numjs</code>, worker threads, or another high-performance approach. Another idea is to rewrite it in BigQuery SQL.</p>\n<p><em><strong>Minimum working example</strong></em></p>\n<p>The code below generates the input dataframe.</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\n// prepare the input df\nconst df = new dfd.DataFrame({\n  date: [\"2023-01-10\", \"2023-01-20\", \"2023-01-30\", \"2023-01-10\", \"2023-01-20\", \"2023-01-30\"],\n  category_a: [4, 4, 4, 4, 4, 4],\n  category_b: [1, 1, 1, 2, 2, 2],\n  outflow: [1.0, 2.0, 10.0, 2.0, 2.0, 0.0],\n  open: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n  inflow: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n  max: [10.0, 20.0, 20.0, 10.0, 20.0, 20.0],\n  close: [0.0, NaN, NaN, 0.0, NaN, NaN],\n  buy: [0.0, NaN, NaN, 0.0, NaN, NaN],\n  random_str: [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"]\n});\n\n// parse dates\ndf.addColumn(\"date\", df[\"date\"].map(v => new Date(v)), { inplace: true });\n\n// get unique pairs of category_a and category_b\nconst uniquePairs = df.groupby([\"category_a\", \"category_b\"]).size().resetIndex().loc({ columns: [\"category_a\", \"category_b\"] }).toJSON();\n\n// get unique dates\nconst uniqueDates = Array.from(new Set(df[\"date\"].values)).sort((a, b) => a - b);\n</code></pre>\n<p>Using this input dataframe, the code below is what I am trying to optimize.</p>\n<pre><code>df.setIndex({ index: \"date\", inplace: true });\nconst day0 = uniqueDates[0]; // first date\n\nconst listOfNumbers = [...Array(uniquePairs.length).keys()];\nconst myset = Object.fromEntries(listOfNumbers.map(k => [k, null]));\n\nfor (const [countPair, value] of uniquePairs.entries()) {\n  const categoryA = value.category_a;\n  const categoryB = value.category_b;\n\n  // subset the dataframe for the pair\n  const dfSubset = df.loc({\n    rows: df[\"category_a\"].eq(categoryA).and(df[\"category_b\"].eq(categoryB))\n  });\n\n  // day 0\n  dfSubset.loc({ rows: [day0], columns: [\"close\"] }).data[0][0] =\n    dfSubset.loc({ rows: [day0], columns: [\"open\"] }).data[0][0] +\n    dfSubset.loc({ rows: [day0], columns: [\"inflow\"] }).data[0][0] -\n    dfSubset.loc({ rows: [day0], columns: [\"outflow\"] }).data[0][0];\n\n  // loop over single pair using date\n  for (let i = 1; i &lt; uniqueDates.length; i++) {\n    const date = uniqueDates[i];\n    const previousDate = uniqueDates[i - 1];\n\n    dfSubset.loc({ rows: [date], columns: [\"open\"] }).data[0][0] =\n      dfSubset.loc({ rows: [previousDate], columns: [\"close\"] }).data[0][0];\n\n    dfSubset.loc({ rows: [date], columns: [\"close\"] }).data[0][0] =\n      dfSubset.loc({ rows: [date], columns: [\"open\"] }).data[0][0] +\n      dfSubset.loc({ rows: [date], columns: [\"inflow\"] }).data[0][0] -\n      dfSubset.loc({ rows: [date], columns: [\"outflow\"] }).data[0][0];\n\n    const closeVal = dfSubset.loc({ rows: [date], columns: [\"close\"] }).data[0][0];\n    const maxVal = dfSubset.loc({ rows: [date], columns: [\"max\"] }).data[0][0];\n    const inflowVal = dfSubset.loc({ rows: [date], columns: [\"inflow\"] }).data[0][0];\n\n    if (closeVal &lt; maxVal) {\n      dfSubset.loc({ rows: [previousDate], columns: [\"buy\"] }).data[0][0] =\n        maxVal - closeVal + inflowVal;\n    } else if (closeVal &gt; maxVal) {\n      dfSubset.loc({ rows: [previousDate], columns: [\"buy\"] }).data[0][0] = 0;\n    } else {\n      dfSubset.loc({ rows: [previousDate], columns: [\"buy\"] }).data[0][0] = inflowVal;\n    }\n\n    dfSubset.loc({ rows: [date], columns: [\"inflow\"] }).data[0][0] =\n      dfSubset.loc({ rows: [previousDate], columns: [\"buy\"] }).data[0][0];\n\n    dfSubset.loc({ rows: [date], columns: [\"close\"] }).data[0][0] =\n      dfSubset.loc({ rows: [date], columns: [\"open\"] }).data[0][0] +\n      dfSubset.loc({ rows: [date], columns: [\"inflow\"] }).data[0][0] -\n      dfSubset.loc({ rows: [date], columns: [\"outflow\"] }).data[0][0];\n  }\n\n  myset[countPair] = dfSubset;\n}\n\n// make myset into a dataframe\nconst result = dfd.concat(Object.values(myset)).resetIndex({ drop: false });\n</code></pre>\n<p>After which we can check that the solution is the same as expected.</p>\n<pre><code>const expected = new dfd.DataFrame({\n  date: [\n    new Date(\"2023-01-10\"), new Date(\"2023-01-20\"), new Date(\"2023-01-30\"),\n    new Date(\"2023-01-10\"), new Date(\"2023-01-20\"), new Date(\"2023-01-30\")\n  ],\n  category_a: [4, 4, 4, 4, 4, 4],\n  category_b: [1, 1, 1, 2, 2, 2],\n  outflow: [1, 2, 10, 2, 2, 0],\n  open: [0.0, -1.0, 20.0, 0.0, -2.0, 20.0],\n  inflow: [0.0, 23.0, 10.0, 0.0, 24.0, 0.0],\n  max: [10, 20, 20, 10, 20, 20],\n  close: [-1.0, 20.0, 20.0, -2.0, 20.0, 20.0],\n  buy: [23.0, 10.0, NaN, 24.0, 0.0, NaN],\n  random_str: [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"]\n});\n\n// check that the result is the same as expected\n// How do I do a dataframe equality assertion in Danfo.js?\n</code></pre>\n<p><em><strong>SQL to create first table</strong></em></p>\n<p>The solution can also be in SQL. If so, you can use the following code to create the initial table.</p>\n<p>I am busy trying to implement a solution in BigQuery SQL using a user defined function to keep the logic going too.</p>\n<pre><code>WITH data AS (\n  SELECT \n    DATE '2023-01-10' as date, 4 as category_a, 1 as category_b, 1 as outflow, 0 as open, 0 as inflow, 10 as max, 0 as close, 0 as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-20' as date, 4 as category_a, 1 as category_b, 2 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-30' as date, 4 as category_a, 1 as category_b, 10 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-10' as date, 4 as category_a, 2 as category_b, 2 as outflow, 0 as open, 0 as inflow, 10 as max, 0 as close, 0 as buy, 'b' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-20' as date, 4 as category_a, 2 as category_b, 2 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'b' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-30' as date, 4 as category_a, 2 as category_b, 0 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'b' as random_str\n)\n\nSELECT \n  ROW_NUMBER() OVER (ORDER BY date) as \" \",\n  date,\n  category_a,\n  category_b,\n  outflow,\n  open,\n  inflow,\n  max,\n  close,\n  buy,\n  random_str\nFROM data\n</code></pre>",
  "Title: Why does exceljs readFile fail with a worksheet defined names error?\n\nBody: <p>This bug suddenly came up literally today after readFile previously was working fine. Fails no matter which version of Node.js I use — either 18 or 20.</p>\n<p>Do folks know the fix?</p>\n<pre><code>TypeError: Cannot read properties of undefined (reading 'definedNames')\n  at assignNames (/Users/aizenman/My Drive/code/daily_new_clients/code/node_modules/exceljs/lib/xlsx/xlsx.js:303:18)\n  at read (/Users/aizenman/My Drive/code/daily_new_clients/code/node_modules/exceljs/lib/xlsx/xlsx.js:271:10)\n  at XLSX.readFile (/Users/aizenman/My Drive/code/daily_new_clients/code/node_modules/exceljs/lib/xlsx/xlsx.js:66:12)\n  at loadSuperbillsBirths (/Users/aizenman/My Drive/code/daily_new_clients/code/diana/superbills.js:148:21)\n  at main (/Users/aizenman/My Drive/code/daily_new_clients/code/run_daily_housekeeping.js:25:5)\n  at Object.&lt;anonymous&gt; (/Users/aizenman/My Drive/code/daily_new_clients/code/run_daily_housekeeping.js:38:1)\n</code></pre>",
  "Title: Error while iterating over dataframe column entries: “TypeError: column.iteritems is not a function”\nBody: <p>Using danfojs, I get an error when calling <code>iteritems</code> on a column.</p>\n<pre class=\"lang-js prettyprint-override\"><code>for (const [eventId, region] of column.iteritems()) {\n  // ...\n}\n</code></pre>\n<p>The following error message appears:</p>\n<pre><code>TypeError: column.iteritems is not a function\n</code></pre>",
  "Title: TypeError: connection.connect is not a function when inserting a DataFrame into MySQL in Node.js\nBody: <p>I am trying to store data retrieved from a website into a MySQL database via a DataFrame in Node.js. However, when I call <code>connection.connect()</code> before inserting, I get: <code>TypeError: connection.connect is not a function</code>. I tested it a couple times and I am sure there is neither a connection issue nor a table existence issue involved. Is there anything wrong with the code itself? The code I am using is the following:</p>\n<pre><code>const mysql = require('mysql2/promise');\nconst dfd = require('danfojs-node');\nconst fs = require('fs');\nconst ini = require('ini');\n\nconst config = ini.parse(fs.readFileSync('db_init.ini', 'utf-8'));\nconst password = config.section_a.Password;\nconst host = config.section_a.Host;\nconst database = config.section_a.Database;\n\nasync function insertToDb(df) {\n  const pool = mysql.createPool({\n    host,\n    user: 'root',\n    password,\n    database,\n    waitForConnections: true,\n    connectionLimit: 10,\n  });\n\n  const conn = await pool.getConnection();\n  await conn.connect(); // &lt;-- error here\n\n  const rows = df.toJSON();\n  // Example bulk insert\n  await conn.query('INSERT INTO tableName (col1, col2) VALUES ?', [\n    rows.map(r =&gt; [r.col1, r.col2]),\n  ]);\n\n  conn.release();\n}\n\n</code></pre>\n<p>The full stack trace looks like this:</p>\n<pre><code>TypeError: connection.connect is not a function\n    at insertToDb (/Users/chent/Desktop/PFSDataParser/src/FetchPFS.js:89:15)\n    at main (/Users/chent/Desktop/PFSDataParser/src/FetchPFS.js:287:5)\n    at /Users/chent/Desktop/PFSDataParser/src/FetchPFS.js:304:1\n</code></pre>\n<p>The versions I am using are <code>mysql2</code> and <code>danfojs-node</code> (both current).</p>\n<p>I tried to execute several SQL queries such as <code>CREATE TABLE IF NOT EXISTS</code> or <code>SELECT * FROM</code>, all of which returned the result I expected.</p>",
  "Title: Alternative to concat on empty DataFrames now that it’s deprecated?\n\nBody: <p>I have two DataFrames that can both be empty, and I want to concat them.</p>\n<p>Before I could just do:</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nconst outputDf = dfd.concat({ dfList: [df1, df2], axis: 0 });\n</code></pre>\n<p>But now I run into a warning about concatenation with empty or all-NA entries being deprecated, and that future behavior will change.</p>\n<p>An easy fix would be:</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nlet resultDf;\n\nif (df1.shape[0] !== 0 &amp;&amp; df2.shape[0] !== 0) {\n  resultDf = dfd.concat({ dfList: [df1, df2], axis: 0 });\n} else if (df1.shape[0] !== 0) {\n  resultDf = df1.copy();\n} else if (df2.shape[0] !== 0) {\n  resultDf = df2.copy();\n} else {\n  resultDf = new dfd.DataFrame();\n}\n</code></pre>\n<p>But that seems pretty ugly. Does anyone have a better solution?</p>",
  "Title: Jupyter JavaScript console throws \"Exception in message handler\" when calling danfojs DataFrame methods\nBody: <p>I am new to JavaScript and use JupyterLab with the JavaScript (IJavascript) kernel for data analysis. A few days ago I reinstalled everything. Now when I type danfojs DataFrame commands like <code>df.describe()</code> or <code>df.head()</code> directly in the console, I get the correct output but then I see an error message saying there was an exception in the message handler, followed by a stack trace pointing into the kernel and danfojs.</p>\n<p>Weirdly, this only shows up when I manually type the commands. If I run the same commands from a notebook cell, or even use the up arrow to select previous commands in the console, the error doesn’t appear. It only happens when I type the commands manually.</p>\n<p>I searched online but couldn’t find any discussion. How do I deal with this error?</p>\n<p>I reinstalled JupyterLab, ijavascript, node, and danfojs-node, but nothing helped.</p>",
  "Title: Danfo.js plot, TypeError when calling df.plot?\nBody: <p>It was working perfectly earlier but for some reason now I am getting strange errors.</p>\n<p>danfojs-node version: <code>1.1.2</code></p>\n<p>plotly.js version: <code>2.27.0</code></p>\n<p>sample dataframe:</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nconst df = new dfd.DataFrame({\n  cap: [1, 2, 3, 4],\n  Date: [\"2022-01-04\", \"2022-01-06\", \"2022-01-07\", \"2022-01-08\"],\n});\n\ndf.dtypes.print();\n</code></pre>\n<pre><code>df.plot({ x: \"cap\", y: \"Date\" });\n</code></pre>\n<p>I get a TypeError from the plotting call. What’s the right way to plot a DataFrame with a date column in Danfo.js?</p>",
  "Title: Danfo.js FutureWarning: Series.__getitem__ treating keys as positions is deprecated.\nBody: <p>I'm having an issue with Danfo.js v2.1.0+ that I can't figure out.</p>\n<p>I have a list of columns in my DataFrame that I need to convert using a custom function. The new values depend on multiple columns in the data, so I'm using apply to convert the column in-place:</p>\n<pre><code>const myColumnsToConvert = ['col1', 'col2', 'col3'];\n\nfor (const k of myColumnsToConvert) {\n  df.addColumn(\n    k,\n    df.loc({ columns: [k, 'colx'] }).apply(row => convertMyData({\n      value_1_in: row[0],\n      value_2_in: row[1]\n    }), { axis: 1 }),\n    { inplace: true }\n  );\n}\n</code></pre>\n<p>This has worked just fine in previous versions. But now I get:</p>\n<pre><code>FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n</code></pre>\n<p>But I'm not using loc or iloc, and everything I've reviewed thus far seems to point at that being the issue. How can I write this code so that I'm doing it the correct way in the future?</p>\n<p>Using previous methods in Danfo.js that did work.</p>",
  "Title: Repeat rows in DataFrame with respect to column.\nBody: <p>I have a Danfo.js DataFrame that looks like this:</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nconst df = new dfd.DataFrame({\n  col1: [1, 2, 3],\n  col2: [4, 5, 6],\n  col3: [7, 8, 9],\n});\n\ndf.print();\n    col1    col2    col3\n0      1       4       7\n1      2       5       8\n2      3       6       9\n</code></pre>\n<p>I would like to create a Danfo.js DataFrame like this:</p>\n<pre><code>df_new\n    col1    col2    col3\n0      1       4       7\n1      1       5       8\n2      1       6       9\n3      2       4       7\n4      2       5       8\n5      2       6       9\n6      3       4       7\n7      3       5       8\n8      3       6       9\n</code></pre>\n<p>Is there a built-in or combination of built-in Danfo.js methods that can achieve this?</p>\n<p>Even if there are duplicates in <code>df</code>, I would like the output to be the same format. In other words:</p>\n<pre><code>df\n    col1    col2    col3\n0      1       4       7\n1      2       5       8\n2      2       6       8\n\ndf_new\n    col1    col2    col3\n0      1       4       7\n1      1       5       8\n2      1       6       8\n3      2       4       7\n4      2       5       8\n5      2       6       8\n6      2       4       7\n7      2       5       8\n8      2       6       8\n</code></pre>",
  "Title: .corr throws an error about converting a string to a number\n\nBody: <p>I'm getting a strange error when trying to follow a correlation example using <code>corr()</code> in JavaScript (Danfo.js).</p>\n<p>Specifically, when I run: <code>df.corr({ method: 'pearson' })</code></p>\n<p>The error message isn’t helpful. I thought <code>corr()</code> would automatically ignore strings and empty values.</p>\n<p>The stack trace ends with an error about converting a string to a number (value: <code>'Avery Bradley'</code>).</p>",
  "Title: What datatype is considered 'array-like' in JavaScript?\nBody: In the Danfo.js documentation for `Series.isin(values)`, they state:\n\n> values : set or array-like\n\nWhat is considered array-like? For a JavaScript object `tempObj`, would `Object.keys(tempObj)` and `Object.values(tempObj)` be considered array-like?",
  "Title: Can calling toUpperCase() result in a longer string?\nBody: <p>I want to use JavaScript’s uppercasing on a string, e.g. <code>str.toUpperCase()</code> or <code>str.toLocaleUpperCase(locale)</code>.</p>\n<p>My question is: am I always safe assuming the uppercased string has the same length as the original? For example, can I preallocate a buffer of <code>source.length</code> and always fit the result?</p>\n<p>If not, can someone provide an example where uppercasing increases the length (including the locale if it’s locale-dependent)?</p>",
  "Title: C/C++ warn or prohibit literal string concatenation.\nBody: <p>Is there a way to warn or prohibit literal string concatenations such as:</p>\n<pre><code>const char *a = \"foo\" \" bar\";\n</code></pre>\n<p>I spent hours finding a bug in a big static array that had</p>\n<pre><code>const char * a[] = {\"foo\" \"bar\"};\n</code></pre>\n<p>instead of</p>\n<pre><code>const char * a[] = {\"foo\", \"bar\"};\n</code></pre>",
  "Title: Is constructing an object in an argument list and passing a pointer to internal data of the object to the function safe?\nBody: <p>Is the JavaScript code below well-formed? Will the temporary string object be eligible for garbage collection before or after the function finishes executing?</p>\n<pre class=\"lang-js prettyprint-override\"><code>function myFunction(s) {}\n\n...\n\nmyFunction(String(\"Something\"));\n</code></pre>\n<p>I know I could do <code>myFunction(\"Something\")</code>, but I am using <code>String()</code> this way to illustrate my point.</p>",
  "Title: How do I split a string by a character without ignoring trailing split-characters?\nBody: <p>I have a string similar to the following</p>\n<pre><code>const myString = \"apple,banana,orange,\";\n</code></pre>\n<p>And I want to split by <code>,</code> to produce the output:</p>\n<pre><code>[\"apple\", \"banana\", \"orange\", \"\"]\n</code></pre>\n<p>I thought <code>split</code> would accomplish this but it treats the trailing ',' like it doesn't exist</p>\n<pre><code>const myString = \"apple,banana,orange,\";\n\nmyString.split(\",\");\n/// [\"apple\", \"banana\", \"orange\"]\n</code></pre>\n<p>What is the simplest approach to achieve the desired output?</p>\n<p>Some more test cases with example strings and desired outputs</p>\n<pre><code>const string1 = \"apple,banana,orange,\";\nconst output1 = [\"apple\", \"banana\", \"orange\", \"\"];\n\nconst string2 = \"apple,banana,orange,pear\";\nconst output2 = [\"apple\", \"banana\", \"orange\", \"pear\"];\n\nconst string3 = \",apple,banana,orange\";\nconst output3 = [\"\", \"apple\", \"banana\", \"orange\"];\n\n// Examples of non-comma separated strings\n// '|' separator\nconst string4 = \"|apple|banana|orange|\";\nconst output4 = [\"\", \"apple\", \"banana\", \"orange\", \"\"];\n\n// 'x' separator\nconst string5 = \"xapplexbananaxorangex\";\nconst output5 = [\"\", \"apple\", \"banana\", \"orange\", \"\"];\n</code></pre>\n<p>EDIT:</p>\n<p>Ideally solution should generalize to any splitting character.</p>\n<p>Would also prefer a built-in JavaScript solution (although do still link any packages which supply this functionality since their source code might be useful to look through!).</p>",
  "Title: C# triple double quotes (three double quotes).\nBody: <p>What is the purpose of triple douple quotes <code>&quot;&quot;&quot;</code> in C#? It seems it is used for multiline text. But why not use single double quotes with <code>@&quot;...&quot;</code>?</p>\n<pre><code>string text = &quot;&quot;&quot;\n  some text\n  some text\n  some text\n  &quot;&quot;&quot;;\n</code></pre>",
  "Title: How to replace characters in a string one at a time generating new string for each replacement?\nBody: <p>I have an array of strings</p>\n<pre><code>[\n  &quot;YSAHEEHHYDK&quot;, &quot;HEHISSDYAGK&quot;, &quot;TFAHTESHISK&quot;, &quot;ISLGEHEGGGK&quot;,\n  &quot;LSSGYDGTSYK&quot;, &quot;FGTGTYAGGEK&quot;, &quot;VGASTGYSGLK&quot;, &quot;TASGVGGFSTK&quot;, &quot;SYASDFGSSAK&quot;,\n  &quot;LYSYYSSTESK&quot;\n]\n</code></pre>\n<p>for each string I would like to replace &quot;Y&quot;, &quot;S&quot; or &quot;T&quot; with &quot;pY&quot;, &quot;pS&quot; or &quot;pT&quot;. But I dont want all the replacements to be in the same final string, I want each replacement to generate a new string, e.g.</p>\n<p>&quot;YSAHEEHHYDK&quot; turns into</p>\n<pre><code>[\n  &quot;pYSAHEEHHYDK&quot;,\n  &quot;YpSAHEEHHYDK&quot;,\n  &quot;YSAHEEHHpYDK&quot;\n]\n</code></pre>",
  "Title: How to find the max and min values of string rows of a DataFrame in JavaScript?\nBody: <p>For each row of my data, I want to get the <em>min</em> and <em>max</em> values and the <em>number of years</em> which are originally stored as a character string. For example, consider the following data:</p>\n<pre><code>const dfd = require(\"danfojs-node\");\n\nconst df = new dfd.DataFrame({\n  id: [1, 2, 3, 4],\n  yr: [\n    \"1543,860,2023\",\n    \"2019,2018,2006,2007\",\n    \"1998,2012,2000,2020\",\n    \"2000\",\n  ],\n});\n</code></pre>\n<p>Output needed:</p>\n<pre><code>id                   yr  min_yr  max_yr  nYears\n 1        1543,860,2023     860    2023       3\n 2  2019,2018,2006,2007    2006    2019       4\n 3  1998,2012,2000,2020    1998    2020       4\n 4                 2000    2000    2000       1\n</code></pre>",
  "Title: JavaScript String object vs primitive when concatenating\nBody: ```js\nfunction main() {\n  const a = new String(\"Jav\");\n  const c = \"Jav\";\n  console.log(a === c); // false\n}\nmain();\n```\n\n```js\nfunction main() {\n  const a = new String(\"Ja\").concat(\"v\");\n  const c = \"Jav\";\n  console.log(a === c); // true\n}\nmain();\n```\n\nI don’t understand why the first one prints false but the second one prints true. I expected both to be true because they look like the same string. Can someone explain the difference? Thanks!\n\nMy runtime: Node.js 20\n\nBtw I get the same result if I use `+` instead of `concat`.",
  "Title: How do I create a multiline string in Raku?.\nBody: <p>In JavaScript (ES6), you can use template literals (``) to create multiline strings as shown in the following example:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const html = `\n  &lt;div&gt;\n    &lt;p&gt;Raku is &lt;b&gt;ofun&lt;/b&gt;.&lt;/p&gt;\n  &lt;/div&gt;\n`\n</code></pre>\n<p>What's the Raku equivalent of this?</p>",
  "Title: Special case when += for string concatenation is more efficient than =\nBody: <p>I have this code using Node.js:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const { performance } = require('perf_hooks');\n\nconst run1 = () =&gt; {\n  let initialString = '';\n  for (let i = 0; i &lt; 10000; i++) {\n    initialString = initialString + 'x' + 'y';\n  }\n};\n\nconst run2 = () =&gt; {\n  let initialString = '';\n  for (let i = 0; i &lt; 10000; i++) {\n    initialString += 'x' + 'y';\n  }\n};\n\nconst timeit = (fn, number = 100) =&gt; {\n  const start = performance.now();\n  for (let i = 0; i &lt; number; i++) fn();\n  return performance.now() - start;\n};\n\nconst time1 = timeit(run1, 100);\nconst time2 = timeit(run2, 100);\n\nconsole.log(time1);\nconsole.log(time2);\n</code></pre>\n<p>Why <code>+=</code> is more efficient <strong>in this case</strong>?\nAs far as I know, there is the same number of concatenations, and the order of execution doesn't change the result.</p>\n<p>Since strings are immutable, it's not because of in-place shenanigans, and the only thing I found about string concat is about <code>.join</code> efficiency, but I don't want the most efficient, just understand why <code>+=</code> seems more efficient than <code>=</code>.</p>\n<p>With this code, performance between forms almost equals:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const { performance } = require('perf_hooks');\n\nconst run1 = () =&gt; {\n  let initialString = '';\n  for (let i = 0; i &lt; 10000; i++) {\n    initialString = initialString + 'x';\n  }\n};\n\nconst run2 = () =&gt; {\n  let initialString = '';\n  for (let i = 0; i &lt; 10000; i++) {\n    initialString += 'x';\n  }\n};\n\nconst timeit = (fn, number = 100) =&gt; {\n  const start = performance.now();\n  for (let i = 0; i &lt; number; i++) fn();\n  return performance.now() - start;\n};\n\nconst time1 = timeit(run1, 100);\nconst time2 = timeit(run2, 100);\n\nconsole.log(time1);\nconsole.log(time2);\n</code></pre>\n<hr />\n<p>I noticed a difference using different Node.js versions (<code>'x' + 'y'</code> form):</p>\n<p>Node 14 to 16:</p>\n<pre class=\"lang-js prettyprint-override\"><code>console.log(time1);\n// ~0.6\nconsole.log(time2);\n// ~0.3\n</code></pre>\n<p>Node 18:</p>\n<pre class=\"lang-js prettyprint-override\"><code>console.log(time1);\n// ~1.7\nconsole.log(time2);\n// ~0.8\n</code></pre>\n<p>Node 20 for comparison:</p>\n<pre class=\"lang-js prettyprint-override\"><code>console.log(time1);\n// ~0.6\nconsole.log(time2);\n// ~0.1\n</code></pre>\n<hr />\n<p>Similar but not answering the question: <a href=\"https://stackoverflow.com/questions/69079181/how-is-the-s-sc-string-concat-optimization-decided\">How is the s=s+c string concat optimization decided?</a></p>\n<blockquote>\n<p>If s is a string, then s = s + 'c' might modify the string in place, while t = s + 'c' can't. But how does the operation s + 'c' know which scenario it's in?</p>\n</blockquote>\n<p>In a nutshell: Optimization occurs when <code>s = s + 'c'</code>, not when <code>t = s + 'c'</code> because the engine needs to keep a ref to the first string and can't concatenate in-place.</p>\n<p>Here, we are always assigning using simple assignment or augmented assignment to the original string, so in-place concatenation should apply in both cases.</p>",
  "Title: Removing second and subsequent occurrences of decimal point in string.\nBody: <p>I want to remove the second and subsequent occurrences of a decimal point in a string. My attempt is below:</p>\n<pre><code>const str = \"3.99-0.13\";\nstr.replace(/\\./g, \"\");\n// \"399-013\"\nstr.replace(/\\./, \"\");\n// \"399-0.13\"\n</code></pre>\n<p>However, I want the output like <code>3.99-013</code>. Any hint, please.</p>",
  "Title: Why some character can’t be edited in JavaScript?\nBody: <p>I’m trying to write my own <code>strcat</code>-style function in JavaScript, but it has some problems.<br />\nMy input is two strings <code>c</code> and <code>a</code>, and my function will return a string which <code>c</code> is concatenated with <code>a</code>.</p>\n<p>For example,<br />\nInput: <code>'abc'</code> <code>'xyz'</code><br />\nExpected Output: <code>'xyzabc'</code><br />\nMy function's Output: <code>'xyza@▲∩'</code></p>\n<p>My function returns some special character different to my input.</p>\n<p>I debugged my function and found that:</p>\n<ul>\n<li>When <code>i=0</code>, <code>destination[3]</code> = <code>source[0]</code> = <code>'a'</code></li>\n<li>But when <code>i=1</code>, <code>destination[8]</code> = <code>source[1]</code> = <code>'b'</code></li>\n<li>And when <code>i=2</code>, <code>destination[9]</code> = <code>source[2]</code> = <code>'c'</code></li>\n<li>Finally, <code>destination[10]</code> = <code>'\\0'</code></li>\n</ul>\n<pre class=\"lang-js prettyprint-override\"><code>function mystrcat(destination, source) {\n  for (let i = 0; i &lt; source.length; i++) {\n    destination[destination.length + i] = source[i];\n  }\n  destination[destination.length + source.length] = '\\0';\n  return destination;\n}\n\nfunction main() {\n  const c = prompt();\n  const a = prompt();\n\n  const result = mystrcat(a, c);\n  console.log(result);\n}\n\nmain();\n</code></pre>",
  "Title: How to prevent a function from accidentally becoming recursive in JavaScript?\nBody: <p>Consider the following Node.js code:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const getValFromDbSigned = (key, value) =&gt; {\n  console.log(\"Getting value from db with Int8Array!\");\n};\n\nconst getValFromDbUnsigned = (key, value) =&gt; {\n  console.log(\"Getting value from db with Uint8Array!\");\n};\n\n// \"overload\" wrapper to convert key from string to Buffer\nfunction getValFromDb(key, value) {\n  if (typeof key === \"string\") {\n    return getValFromDb(Buffer.from(key, \"utf8\"), value);\n  }\n\n  if (value instanceof Int8Array) {\n    return getValFromDbSigned(key, value);\n  }\n\n  if (value instanceof Uint8Array) {\n    return getValFromDbUnsigned(key, value);\n  }\n\n  // fallback so existing string callers keep working\n  return getValFromDb(String(key), value);\n}\n\nfunction main() {\n  const myValueUnsigned = new Uint8Array([0]); // OK\n  getValFromDb(\"my key\", myValueUnsigned);\n\n  const myValueSigned = new Int8Array([0]); // OK\n  getValFromDb(\"my key\", myValueSigned);\n\n  const myValueNumber = 0; // NOK: causes recursion\n  getValFromDb(\"my key\", myValueNumber);\n\n  // Can't remove the string conversion altogether because these need to keep working\n  const key = \"my key\";\n  getValFromDb(key, myValueSigned);\n  getValFromDb(key, myValueUnsigned);\n}\n\nmain();\n</code></pre>\n<p>I have a function <code>getValFromDb</code> that receives a key name and a value, with specific handlers for <code>Int8Array</code> and <code>Uint8Array</code>, plus a wrapper that just converts the key from <code>string</code> to <code>Buffer</code> since those can’t be used interchangeably.</p>\n<p>The program ends up in a recursive loop when passing a type that isn’t supported (e.g. <code>number</code>), because the wrapper keeps converting back and forth between <code>string</code> and <code>Buffer</code>. I could add a new handler for <code>number</code>, but I want the code to be safer for future developers: unsupported types should throw a clear error instead of being captured by the string wrapper and recursing.</p>\n<p>I don’t want to remove the string-to-buffer conversion because existing code relies on it. In summary, how can I prevent this implicit conversion from <code>Buffer</code> back to <code>string</code> in the wrapper so unsupported types produce a clean error instead of recursion?</p>\n<pre class=\"lang-js prettyprint-override\"><code>function getValFromDb(key, value) {\n  if (typeof key === \"string\") {\n    return getValFromDb(Buffer.from(key, \"utf8\"), value);\n  }\n\n  // how to prevent String(key) from being used as a fallback?\n  return getValFromDb(String(key), value);\n}\n</code></pre>\n<p>I’m running this in Node.js.</p>",
  "Title: How to find longest continuous contiguous set of characters in a string based on a given array\nBody: <p>I have the following string in JavaScript.</p>\n<pre><code>const aas = \"QAWDIIKRIDKK\";\n</code></pre>\n<p>And I want to check the longest continuous fragment of that string that contains the characters in the following array:</p>\n<pre><code>const hydrophobicRes = [\"W\", \"F\", \"I\", \"L\", \"V\", \"M\", \"C\", \"A\", \"G\"];\n</code></pre>\n<p>The answer is:</p>\n<pre><code>AW, II\n</code></pre>\n<p>Other example:</p>\n<pre><code>QFILVMD -&gt; FILVM\n</code></pre>\n<p>How can I do that in JavaScript?</p>",
  "Title: Obtain palindromic array by performing these operations.\nBody: <p>An array is called palindromic if it remains the same after reversing the order of its elements.</p>\n<p>You have an array of strings <code>arr</code>. For each <code>i</code>, <code>arr[i]</code> consists of at least two characters. For each pair of consecutive elements <code>arr[i]</code> and <code>arr[i + 1]</code>, you can:</p>\n<ol>\n<li>Move the rightmost character of <code>arr[i]</code> to the leftmost position in <code>arr[i + 1]</code>. For instance, \"abc\" and \"def\" will become \"ab\" and \"cdef\". This operation can be applied only once to any pair of consecutive elements.</li>\n<li>Move the leftmost character of <code>arr[i + 1]</code> to the rightmost position in <code>arr[i]</code>. For instance, \"abc\" and \"def\" will become \"abcd\" and \"ef\". Again, this operation can be applied only once to any pair of consecutive elements.</li>\n<li>Do nothing to the pair of consecutive elements.</li>\n</ol>\n<p>Is it possible to obtain a palindromic array from <code>arr</code> by performing these operations?</p>\n<p>Consider the case when <code>arr = [\"aa\", \"bab\", \"cde\", \"aba\", \"ab\"]</code>. Here the output should be true and here is why:</p>\n<p>Move first char from index 1 to the last position of index 0, <code>arr = [\"aab\", \"ab\", \"cde\", \"aba\", \"ab\"]</code></p>\n<p>Move last char from index 3 to the first position of index 4, <code>arr = [\"aab\", \"ab\", \"cde\", \"ab\", \"aab\"]</code>, which is a palindromic array.</p>\n<p>I tried solutions such as two pointer, etc. but doesn't seem to work.</p>",
  "Title: Prepend leading zeros to each line of a file.\n\nBody: <p>I have a file that looks like this:</p>\n<pre><code>1:line1\n14:line2\n135:line3\n15:line4\n</code></pre>\n<p>I need to prepend leading zeros to each line to make it look like this:</p>\n<pre><code>00001:line1\n00014:line2\n00135:line3\n00015:line4\n</code></pre>\n<p>Is there an easy way to do this in Node.js?</p>\n<p>I have tried using</p>\n<pre><code>const fs = require('fs');\n\nconst input = fs.readFileSync('file', 'utf8').trim().split('\\n');\n\nconst output = input.map((line, i) => {\n  return String(i + 1).padStart(5, '0') + ':' + line;\n}).join('\\n');\n\nconsole.log(output);\n</code></pre>\n<p>but this outputted:</p>\n<pre><code>00001:1:line1\n00002:14:line2\n00003:135:line3\n00004:15:line4\n</code></pre>\n<p>I should note I did not write this code, I got it from Google and don't really understand how it works</p>",
  "Title: Capture the last word on each line.\nBody: <p>I have a file that doesn't have the correct spacing and I would like to add a space between the dollar amount and the word right beside it, i.e., <code>2342.20Hello</code>.</p>\n<p>I tried using <code>sed</code> to resolve this issue but it didn't seem to work.</p>\n<p>I tried this command but it doesn't seem to work.</p>\n<pre><code>sed -r 's/([0-9].*)\\.([a-zA-Z].*) /\\1 \\2/g' /tmp/testfile2.txt\n</code></pre>\n<p>I was expecting the file that has:</p>\n<pre><code>2234.3Hello\n8938.3HeyYou\n1239.0New\n</code></pre>\n<p>To look like this:</p>\n<pre><code>2234.3 Hello\n8938.3 HeyYou\n1239.0 New\n</code></pre>\n<p>I'm okay with a Node.js script using npm packages to accomplish the above.</p>",
  "Title: Fast and efficient substring extraction and comparison in JavaScript  \nBody: <p>I have a problem concerning very fast and efficient comparison between the substrings of two strings in my dataset, which won't run fast enough despite pretty powerful machinery. I have a dataset with 2 columns and about 1.5 billion rows, which has this structure:</p>\n<pre><code>const dt = [\n  { class1: \"002134\", class2: \"002003\" },\n  { class1: \"024345\", class2: \"024234\" },\n  { class1: \"176234\", class2: \"002004\" }\n];\n</code></pre>\n<p>What I want is a function that (1) extracts the first 3 digits from each string by row for both vectors, (2) compares the substrings between the two vectors, and (3) creates a new boolean variable that reports whether the two substrings are equal or not.</p>\n<p>So the desired result is as follows:</p>\n<pre><code>dt[0].sameclass = true;\ndt[1].sameclass = true;\ndt[2].sameclass = false;\n\nconsole.log(dt);\n/*\n[\n  { class1: \"002134\", class2: \"002003\", sameclass: true },\n  { class1: \"024345\", class2: \"024234\", sameclass: true },\n  { class1: \"176234\", class2: \"002004\", sameclass: false }\n]\n*/\n</code></pre>\n<p>I have tried versions using substring extraction in different ways, both with and without helper functions. However, the bottleneck still seems to be the substring extraction.</p>\n<pre><code>// direct substring extraction\ndt.forEach(row =&gt; {\n  row.redclass1 = row.class1.substring(0, 3);\n  row.redclass2 = row.class2.substring(0, 3);\n  row.sameclass = row.redclass1 === row.redclass2;\n});\n\n// inline comparison\ndt.forEach(row =&gt; {\n  row.sameclass = row.class1.substring(0, 3) === row.class2.substring(0, 3);\n});\n\n// separate function\nfunction sameclass(subclass1, subclass2, classdepth) {\n  return subclass1.substring(0, classdepth) === subclass2.substring(0, classdepth);\n}\ndt.forEach(row =&gt; {\n  row.sameclass = sameclass(row.class1, row.class2, 3);\n});\n</code></pre>\n<p>All versions either run into memory problems or take several hours to a day to run. Since I need to do this repeatedly this does not work for me, and I wanted to ask if you can come up with something faster / more efficient. Any help would be greatly appreciated!</p>\n<p><strong>EDIT</strong></p>\n<p>I have benchmarked some of the methods suggested here, which indeed show a substantial speedup:</p>\n<pre><code>const dt = Array.from({ length: 1000 }).flatMap(() =&gt; [\n  { class1: \"002134\", class2: \"002003\" },\n  { class1: \"024345\", class2: \"024234\" },\n  { class1: \"176234\", class2: \"002004\" }\n]);\n\n// crude timing examples\nconsole.time(\"startswithtest\");\ndt.forEach(row =&gt; {\n  row.sameclass = row.class2.startsWith(row.class1.substring(0, 3));\n});\nconsole.timeEnd(\"startswithtest\");\n\nconsole.time(\"lapplytest\");\ndt.forEach(row =&gt; {\n  const a = row.class1.substring(0, 3);\n  const b = row.class2.substring(0, 3);\n  row.sameclass = a === b;\n});\nconsole.timeEnd(\"lapplytest\");\n\nconsole.time(\"numerictest\");\ndt.forEach(row =&gt; {\n  row.sameclass = Math.floor(Number(row.class1) / 1000) === Math.floor(Number(row.class2) / 1000);\n});\nconsole.timeEnd(\"numerictest\");\n\nconsole.time(\"functiontest\");\nfunction sameclass(subclass1, subclass2, classdepth) {\n  return subclass1.substring(0, classdepth) === subclass2.substring(0, classdepth);\n}\ndt.forEach(row =&gt; {\n  row.sameclass = sameclass(row.class1, row.class2, 3);\n});\nconsole.timeEnd(\"functiontest\");\n</code></pre>\n<p>I will go with the startsWith for now, since it seems to offer the highest speed (unfortunately I was not able to use native extensions due to restrictions on my server). Thank you for the help!</p>",
  "Title: Sorting words from process.argv by length\nBody: <p>I'm attempting to read words from the command line using <code>process.argv</code> in Node.js and then sort them in descending order based on their lengths. However, my sorting algorithm is producing unexpected output.</p>\n<p>The code I'm using is as follows:</p>\n<pre><code>const argv = process.argv;\n\nfor (let i = 2; i &lt; argv.length - 1; i++) {\n    for (let j = 2; j &lt; argv.length - i - 1; j++) {\n        if (argv[j].length &lt; argv[j + 1].length) {\n            const tempWord = argv[j];\n            argv[j] = argv[j + 1];\n            argv[j + 1] = tempWord;\n        }\n    }\n}\n\nconsole.log(\"\\n\");\nfor (let i = 2; i &lt; argv.length; i++) {\n    process.stdout.write(argv[i] + \" \");\n}\n</code></pre>\n<pre><code>node test.js I put this words\n\n\npuwordI wordI I  % \n</code></pre>\n<p>Unfortunately, the output is corrupted. I suspect there might be an issue with my sorting logic or how I'm handling the command line arguments. Could someone please review my code and provide guidance on how to correctly sort the words by length?</p>",
  "Title: how do I concatenate and join an array of strings with a delimiter in powershell?.\nBody: <p>PS C:\\Users\\User\\ps-modules&gt; more .\\MyStrings.Tests.ps1</p>\n<pre><code>function slist { \"1\", \"2\", \"3\" }\n\nDescribe 'StringTests' {\n\n  It 'literal -join' {\n    \"1\", \"2\", \"3\" -join \",\" | Should -Be \"1,2,3\"\n  }\n\n  It 'literal -join' {\n    @(\"1\", \"2\", \"3\") -join \",\" | Should -Be \"1,2,3\"\n  }\n\n  It 'slist returns a list of string' {\n    slist | Should -Be @(\"1\", \"2\", \"3\")\n  }\n\n  It 'slist -join' {\n    slist -join \",\" | Should -Be \"1,2,3\"\n  }\n\n}\n</code></pre>\n<p>PS C:\\Users\\User\\ps-modules&gt; pwsh .\\MyStrings.Tests.ps1</p>\n<pre><code>Starting discovery in 1 files.\nDiscovery found 4 tests in 169ms.\nRunning tests.\n[-] StringTests.slist -join 55ms (53ms|2ms)\n Expected '1,2,3', but got @('1', '2', '3').\n at slist -join \",\" | Should -Be \"1,2,3\", C:\\Users\\User\\ps-modules\\MyStrings.Tests.ps1:17\n at &lt;ScriptBlock&gt;, C:\\Users\\User\\ps-modules\\MyStrings.Tests.ps1:17\nTests completed in 731ms\nTests Passed: 3, Failed: 1, Skipped: 0 NotRun: 0\n</code></pre>\n<p>Why is the array treated differently when it comes from a function return vs when it's literally declared?</p>"
]