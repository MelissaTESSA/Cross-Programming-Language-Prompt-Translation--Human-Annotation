{"0":"Title: How do I solve &quot;error: externally-managed-environment&quot; every time I use pip 3?.\nBody: <p>Error message:<\/p>\n<blockquote>\n<pre class=\"lang-none prettyprint-override\"><code>error: externally-managed-environment\n\n\u00d7 This environment is externally managed\n\u2570\u2500&gt; To install Python packages system-wide, try apt install\n    python3-xyz, where xyz is the package you are trying to\n    install.\n\n    If you wish to install a non-Debian-packaged Python package,\n    create a virtual environment using python3 -m venv path\/to\/venv.\n    Then use path\/to\/venv\/bin\/python and path\/to\/venv\/bin\/pip. Make\n    sure you have python3-full installed.\n\n    If you wish to install a non-Debian packaged Python application,\n    it may be easiest to use pipx install xyz, which will manage a\n    virtual environment for you. Make sure you have pipx installed.\n\n    See \/usr\/share\/doc\/python3.11\/README.venv for more information.\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification.\n<\/code><\/pre>\n<\/blockquote>\n<p>I use apt upgrade and update.<\/p>\n"}
{"0":"Title: Error &quot;&#39;DataFrame&#39; object has no attribute &#39;append&#39;&quot;.\nBody: <p>I am trying to append a dictionary to a DataFrame object, but I get the following error:<\/p>\n<blockquote>\n<p>AttributeError: 'DataFrame' object has no attribute 'append'<\/p>\n<\/blockquote>\n<p>As far as I know, DataFrame does have the method &quot;append&quot;.<\/p>\n<p>Code snippet:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame(df).append(new_row, ignore_index=True)\n<\/code><\/pre>\n<p>I was expecting the dictionary <code>new_row<\/code> to be added as a new row.<\/p>\n<p>How can I fix it?<\/p>\n"}
{"0":"Title: Why did Flask start failing with &quot;ImportError: cannot import name &#39;url_quote&#39; from &#39;werkzeug.urls&#39;&quot;?.\nBody: <p>Environment:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>Python 3.10.11\nFlask==2.2.2\n<\/code><\/pre>\n<p>I run my Flask backend code in docker container, with BASE Image:\n<code>FROM pytorch\/pytorch:2.0.1-cuda11.7-cudnn8-runtime<\/code><\/p>\n<p>But when I run the pytest with version <code>pytest 7.4.2<\/code>,<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>pip install pytest\npytest\n<\/code><\/pre>\n<p>it raised an Error, with logs:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>==================================== ERRORS ====================================\n_____________ ERROR collecting tests\/test_fiftyone_utils_utils.py ______________\nImportError while importing test module '\/builds\/kw\/data-auto-analysis-toolkit-backend\/tests\/test_fiftyone_utils_utils.py'.\nHint: make sure your test modules\/packages have valid Python names.\nTraceback:\n\/opt\/conda\/lib\/python3.10\/importlib\/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\/test_fiftyone_utils_utils.py:2: in &lt;module&gt;\n    import daat  # noqa: F401\n\/opt\/conda\/lib\/python3.10\/site-packages\/daat-1.0.0-py3.10.egg\/daat\/__init__.py:1: in &lt;module&gt;\n    from daat.app import app\n\/opt\/conda\/lib\/python3.10\/site-packages\/daat-1.0.0-py3.10.egg\/daat\/app\/__init__.py:6: in &lt;module&gt;\n    from flask import Flask, jsonify, request\n\/opt\/conda\/lib\/python3.10\/site-packages\/flask\/__init__.py:5: in &lt;module&gt;\n    from .app import Flask as Flask\n\/opt\/conda\/lib\/python3.10\/site-packages\/flask\/app.py:30: in &lt;module&gt;\n    from werkzeug.urls import url_quote\nE   ImportError: cannot import name 'url_quote' from 'werkzeug.urls' (\/opt\/conda\/lib\/python3.10\/site-packages\/werkzeug\/urls.py)\n<\/code><\/pre>\n<p>My codes works well when I directly run it with <code>python run.py<\/code><\/p>\n<p><code>run.py<\/code> shown below<\/p>\n<pre><code>from daat import app\n\napp.run(host='0.0.0.0')\n<\/code><\/pre>\n<p>I guess it should be the pytest versions issue, because it used to work well without changing any related code, and I use <code>pip install pytest<\/code> without defined a specific version.<\/p>\n<p>And my backend runs well without pytest.<\/p>\n"}
{"0":"Title: OpenAI ChatGPT (GPT-3.5) API error 429: &quot;You exceeded your current quota, please check your plan and billing details&quot;.\nBody: <p>I'm making a Python script to use OpenAI via its API. However, I'm getting this error:<\/p>\n<blockquote>\n<p>openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details<\/p>\n<\/blockquote>\n<p>My script is the following:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#!\/usr\/bin\/env python3.8\n# -*- coding: utf-8 -*-\n\nimport openai\nopenai.api_key = &quot;&lt;My PAI Key&gt;&quot;\n\ncompletion = openai.ChatCompletion.create(\n  model=&quot;gpt-3.5-turbo&quot;,\n  messages=[\n    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell the world about the ChatGPT API in the style of a pirate.&quot;}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n<\/code><\/pre>\n<p>I'm declaring the shebang <code>python3.8<\/code>, because I'm using <a href=\"https:\/\/github.com\/pyenv\/pyenv\" rel=\"noreferrer\">pyenv<\/a>. I think it should work, since I did 0 API requests, so I'm assuming there's an error in my code.<\/p>\n"}
{"0":"Title: ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the &#39;ssl&#39; module is compiled with LibreSSL 2.8.3.\nBody: <p>After <code>pip install openai<\/code>, when I try to <code>import openai<\/code>, it shows this error:<\/p>\n<blockquote>\n<p>the 'ssl' module of urllib3 is compile with LibreSSL not OpenSSL<\/p>\n<\/blockquote>\n<p>I just followed a tutorial on a project about using API of OpenAI. But when I get to the first step which is the install and import OpenAI, I got stuck. And I tried to find the solution for this error but I found nothing.<\/p>\n<p>Here is the message after I try to import OpenAI:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>Python 3.9.6 (default, Mar 10 2023, 20:16:38)\n[Clang 14.0.3 (clang-1403.0.22.14.1)] on darwin\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.\n\n&gt;&gt;&gt; import openai\n\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;\/Users\/yule\/Library\/Python\/3.9\/lib\/python\/site-packages\/openai\/__init__.py&quot;, line 19, in &lt;module&gt;\n    from openai.api_resources import (\n  File &quot;\/Users\/mic\/Library\/Python\/3.9\/lib\/python\/site-packages\/openai\/api_resources\/__init__.py&quot;, line 1, in &lt;module&gt;\n    from openai.api_resources.audio import Audio  # noqa: F401\n  File &quot;\/Users\/mic\/Library\/Python\/3.9\/lib\/python\/site-packages\/openai\/api_resources\/audio.py&quot;, line 4, in &lt;module&gt;\n    from openai import api_requestor, util\n  File &quot;\/Users\/mic\/Library\/Python\/3.9\/lib\/python\/site-packages\/openai\/api_requestor.py&quot;, line 22, in &lt;module&gt;\n    import requests\n  File &quot;\/Users\/mic\/Library\/Python\/3.9\/lib\/python\/site-packages\/requests\/__init__.py&quot;, line 43, in &lt;module&gt;\n    import urllib3\n  File &quot;\/Users\/mic\/Library\/Python\/3.9\/lib\/python\/site-packages\/urllib3\/__init__.py&quot;, line 38, in &lt;module&gt;\n    raise ImportError(\nImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3. See: https:\/\/github.com\/urllib3\/urllib3\/issues\/2168\n<\/code><\/pre>\n<p>I tried to <code>--upgrade<\/code> the <code>urllib3<\/code>, but it is still not working. The result is:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>pip3 install --upgrade urllib3\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: urllib3 in .\/Library\/Python\/3.9\/lib\/python\/site-packages (2.0.2)\n<\/code><\/pre>\n"}
{"0":"Title: Error Updating Python3 pip AttributeError: module &#39;lib&#39; has no attribute &#39;OpenSSL_add_all_algorithms&#39;.\nBody: <p>I'm having an error when installing\/updating any pip module in python3. Purging and reinstalling <code>pip<\/code> and every package I can thing of hasn't helped. Here's the error that I get in response to running <code>python -m pip install --upgrade pip<\/code> specifically (but the error is the same for attempting to install or update any pip module):<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/usr\/lib\/python3.8\/runpy.py&quot;, line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File &quot;\/usr\/lib\/python3.8\/runpy.py&quot;, line 87, in _run_code\n    exec(code, run_globals)\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/__main__.py&quot;, line 16, in &lt;module&gt;\n    from pip._internal.cli.main import main as _main  # isort:skip # noqa\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/main.py&quot;, line 10, in &lt;module&gt;\n    from pip._internal.cli.autocompletion import autocomplete\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/autocompletion.py&quot;, line 9, in &lt;module&gt;\n    from pip._internal.cli.main_parser import create_main_parser\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/main_parser.py&quot;, line 7, in &lt;module&gt;\n    from pip._internal.cli import cmdoptions\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/cmdoptions.py&quot;, line 24, in &lt;module&gt;\n    from pip._internal.exceptions import CommandError\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/exceptions.py&quot;, line 10, in &lt;module&gt;\n    from pip._vendor.six import iteritems\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_vendor\/__init__.py&quot;, line 65, in &lt;module&gt;\n    vendored(&quot;cachecontrol&quot;)\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_vendor\/__init__.py&quot;, line 36, in vendored\n    __import__(modulename, globals(), locals(), level=0)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/__init__.py&quot;, line 9, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/wrapper.py&quot;, line 1, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/adapter.py&quot;, line 5, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/requests-2.22.0-py2.py3-none-any.whl\/requests\/__init__.py&quot;, line 95, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/urllib3-1.25.8-py2.py3-none-any.whl\/urllib3\/contrib\/pyopenssl.py&quot;, line 46, in &lt;module&gt;\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/__init__.py&quot;, line 8, in &lt;module&gt;\n    from OpenSSL import crypto, SSL\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/crypto.py&quot;, line 3268, in &lt;module&gt;\n    _lib.OpenSSL_add_all_algorithms()\nAttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\nError in sys.excepthook:\nTraceback (most recent call last):\n  File &quot;\/usr\/lib\/python3\/dist-packages\/apport_python_hook.py&quot;, line 72, in apport_excepthook\n    from apport.fileutils import likely_packaged, get_recent_crashes\n  File &quot;\/usr\/lib\/python3\/dist-packages\/apport\/__init__.py&quot;, line 5, in &lt;module&gt;\n    from apport.report import Report\n  File &quot;\/usr\/lib\/python3\/dist-packages\/apport\/report.py&quot;, line 32, in &lt;module&gt;\n    import apport.fileutils\n  File &quot;\/usr\/lib\/python3\/dist-packages\/apport\/fileutils.py&quot;, line 12, in &lt;module&gt;\n    import os, glob, subprocess, os.path, time, pwd, sys, requests_unixsocket\n  File &quot;\/usr\/lib\/python3\/dist-packages\/requests_unixsocket\/__init__.py&quot;, line 1, in &lt;module&gt;\n    import requests\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/requests-2.22.0-py2.py3-none-any.whl\/requests\/__init__.py&quot;, line 95, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/urllib3-1.25.8-py2.py3-none-any.whl\/urllib3\/contrib\/pyopenssl.py&quot;, line 46, in &lt;module&gt;\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/__init__.py&quot;, line 8, in &lt;module&gt;\n    from OpenSSL import crypto, SSL\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/crypto.py&quot;, line 3268, in &lt;module&gt;\n    _lib.OpenSSL_add_all_algorithms()\nAttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\n\nOriginal exception was:\nTraceback (most recent call last):\n  File &quot;\/usr\/lib\/python3.8\/runpy.py&quot;, line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File &quot;\/usr\/lib\/python3.8\/runpy.py&quot;, line 87, in _run_code\n    exec(code, run_globals)\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/__main__.py&quot;, line 16, in &lt;module&gt;\n    from pip._internal.cli.main import main as _main  # isort:skip # noqa\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/main.py&quot;, line 10, in &lt;module&gt;\n    from pip._internal.cli.autocompletion import autocomplete\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/autocompletion.py&quot;, line 9, in &lt;module&gt;\n    from pip._internal.cli.main_parser import create_main_parser\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/main_parser.py&quot;, line 7, in &lt;module&gt;\n    from pip._internal.cli import cmdoptions\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/cli\/cmdoptions.py&quot;, line 24, in &lt;module&gt;\n    from pip._internal.exceptions import CommandError\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_internal\/exceptions.py&quot;, line 10, in &lt;module&gt;\n    from pip._vendor.six import iteritems\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_vendor\/__init__.py&quot;, line 65, in &lt;module&gt;\n    vendored(&quot;cachecontrol&quot;)\n  File &quot;\/usr\/lib\/python3\/dist-packages\/pip\/_vendor\/__init__.py&quot;, line 36, in vendored\n    __import__(modulename, globals(), locals(), level=0)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/__init__.py&quot;, line 9, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/wrapper.py&quot;, line 1, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/CacheControl-0.12.6-py2.py3-none-any.whl\/cachecontrol\/adapter.py&quot;, line 5, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/requests-2.22.0-py2.py3-none-any.whl\/requests\/__init__.py&quot;, line 95, in &lt;module&gt;\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module\n  File &quot;\/usr\/share\/python-wheels\/urllib3-1.25.8-py2.py3-none-any.whl\/urllib3\/contrib\/pyopenssl.py&quot;, line 46, in &lt;module&gt;\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/__init__.py&quot;, line 8, in &lt;module&gt;\n    from OpenSSL import crypto, SSL\n  File &quot;\/home\/patrick\/.local\/lib\/python3.8\/site-packages\/OpenSSL\/crypto.py&quot;, line 3268, in &lt;module&gt;\n    _lib.OpenSSL_add_all_algorithms()\nAttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\n<\/code><\/pre>\n<p>I'm running Ubuntu 20.04 in WSL. Python <code>openssl<\/code> is already installed.<\/p>\n<pre><code>sudo apt install python3-openssl\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\npython3-openssl is already the newest version (19.0.0-1build1).\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n<\/code><\/pre>\n<p>My assumption is that I need to re-install some stuff, but I'm not sure what. I've tried the obvious stuff like <code>python3-openssl<\/code>, <code>libssl-dev<\/code>, <code>libffi-dev<\/code>, and <code>python3-pip<\/code> itself and <code>python3<\/code> alltogether.<\/p>\n"}
{"0":"Title: Error: Unable to extract uploader id - Youtube, Discord.py.\nBody: <p>I have a very powerful bot in discord (discord.py, PYTHON) and it can play music in voice channels. It gets the music from youtube (youtube_dl). It <strong>worked perfectly before<\/strong> but now it doesn't want to work with any video.\nI tried updating youtube_dl but it still doesn't work\nI searched everywhere but I still can't find a answer that might help me.<\/p>\n<p>This is the Error: <code>Error: Unable to extract uploader id<\/code><\/p>\n<p>After and before the error log there is no more information.\nCan anyone help?<\/p>\n<p>I will leave some of the code that I use for my bot...\nThe youtube setup settings:<\/p>\n<pre><code>youtube_dl.utils.bug_reports_message = lambda: ''\n\n\nytdl_format_options = {\n    'format': 'bestaudio\/best',\n    'outtmpl': '%(extractor)s-%(id)s-%(title)s.%(ext)s',\n    'restrictfilenames': True,\n    'noplaylist': True,\n    'nocheckcertificate': True,\n    'ignoreerrors': False,\n    'logtostderr': False,\n    'quiet': True,\n    'no_warnings': True,\n    'default_search': 'auto',\n    'source_address': '0.0.0.0',  # bind to ipv4 since ipv6 addresses cause issues sometimes\n}\n\nffmpeg_options = {\n    'options': '-vn',\n}\n\nytdl = youtube_dl.YoutubeDL(ytdl_format_options)\n\n\nclass YTDLSource(discord.PCMVolumeTransformer):\n    def __init__(self, source, *, data, volume=0.5):\n        super().__init__(source, volume)\n\n        self.data = data\n\n        self.title = data.get('title')\n        self.url = data.get('url')\n        self.duration = data.get('duration')\n        self.image = data.get(&quot;thumbnails&quot;)[0][&quot;url&quot;]\n    @classmethod\n    async def from_url(cls, url, *, loop=None, stream=False):\n        loop = loop or asyncio.get_event_loop()\n        data = await loop.run_in_executor(None, lambda: ytdl.extract_info(url, download=not stream))\n        #print(data)\n\n        if 'entries' in data:\n            # take first item from a playlist\n            data = data['entries'][0]\n        #print(data[&quot;thumbnails&quot;][0][&quot;url&quot;])\n        #print(data[&quot;duration&quot;])\n        filename = data['url'] if stream else ytdl.prepare_filename(data)\n        return cls(discord.FFmpegPCMAudio(filename, **ffmpeg_options), data=data)\n\n<\/code><\/pre>\n<p>Approximately the command to run the audio (from my bot):<\/p>\n<pre><code>sessionChanel = message.author.voice.channel\nawait sessionChannel.connect()\nurl = matched.group(1)\nplayer = await YTDLSource.from_url(url, loop=client.loop, stream=True)\nsessionChannel.guild.voice_client.play(player, after=lambda e: print(\n                                       f'Player error: {e}') if e else None)\n<\/code><\/pre>\n"}
{"0":"Title: pre-commit fails to install isort 5.11.4 with error &quot;RuntimeError: The Poetry configuration is invalid&quot;.\nBody: <p><a href=\"https:\/\/pre-commit.com\/\" rel=\"noreferrer\">pre-commit<\/a> suddenly started to fail installing the <a href=\"https:\/\/github.com\/pycqa\/isort\" rel=\"noreferrer\">isort<\/a> hook in our builds today with the following error<\/p>\n<pre><code>[INFO] Installing environment for https:\/\/github.com\/pycqa\/isort.\n[INFO] Once installed this environment will be reused.\n[INFO] This may take a few minutes...\nAn unexpected error has occurred: CalledProcessError: command: ('\/builds\/...\/.cache\/pre-commit\/repo0_h0f938\/py_env-python3.8\/bin\/python', '-mpip', 'install', '.')\nreturn code: 1\nexpected return code: 0\n[...]\nstderr:\n      ERROR: Command errored out with exit status 1:\n[...]\n        File &quot;\/tmp\/pip-build-env-_3j1398p\/overlay\/lib\/python3.8\/site-packages\/poetry\/core\/masonry\/api.py&quot;, line 40, in prepare_metadata_for_build_wheel\n          poetry = Factory().create_poetry(Path(&quot;.&quot;).resolve(), with_groups=False)\n        File &quot;\/tmp\/pip-build-env-_3j1398p\/overlay\/lib\/python3.8\/site-packages\/poetry\/core\/factory.py&quot;, line 57, in create_poetry\n          raise RuntimeError(&quot;The Poetry configuration is invalid:\\n&quot; + message)\n      RuntimeError: The Poetry configuration is invalid:\n        - [extras.pipfile_deprecated_finder.2] 'pip-shims&lt;=0.3.4' does not match '^[a-zA-Z-_.0-9]+$'\n<\/code><\/pre>\n<p>It seems to be related with poetry configuration..<\/p>\n"}
{"0":"Title: Poetry install on an existing project Error &quot;does not contain any element&quot;.\nBody: <p>I am using Poetry for the first time.\nI have a very simple project. Basically<\/p>\n<pre><code>a_project\n|\n|--test\n|    |---test_something.py\n|\n|-script_to_test.py\n<\/code><\/pre>\n<p>From a project I do <code>poetry init<\/code> and then <code>poetry install<\/code><\/p>\n<p>I get the following<\/p>\n<pre><code> poetry install\nUpdating dependencies\nResolving dependencies... (0.5s)\n\nWriting lock file\n\nPackage operations: 7 installs, 0 updates, 0 removals\n\n  \u2022 Installing attrs (22.2.0)\n  \u2022 Installing exceptiongroup (1.1.0)\n  \u2022 Installing iniconfig (2.0.0)\n  \u2022 Installing packaging (23.0)\n  \u2022 Installing pluggy (1.0.0)\n  \u2022 Installing tomli (2.0.1)\n  \u2022 Installing pytest (7.2.1)\n\n\/home\/me\/MyStudy\/2023\/pyenv_practice\/dos\/a_project\/a_project does not contain any element\n<\/code><\/pre>\n<p>after this I can run <code>poetry run pytest<\/code> without problem but what does that error message mean?<\/p>\n"}
{"0":"Title: pip install -r requirements.txt is failing: &quot;This environment is externally managed&quot;.\nBody: <p>Command:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>pip install -r requirements.txt\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>error: externally-managed-environment\n\n\u00d7 This environment is externally managed\n\u2570\u2500&gt; To install Python packages system-wide, try apt install\npython3-xyz, where xyz is the package you are trying to\ninstall.\n\nIf you wish to install a non-Debian-packaged Python package,\ncreate a virtual environment using python3 -m venv path\/to\/venv.\nThen use path\/to\/venv\/bin\/python and path\/to\/venv\/bin\/pip. Make\nsure you have python3-full installed.\n\nIf you wish to install a non-Debian packaged Python application,\nit may be easiest to use pipx install xyz, which will manage a\nvirtual environment for you. Make sure you have pipx installed.\n\nSee \/usr\/share\/doc\/python3.11\/README.venv for more information.\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification.\n<\/code><\/pre>\n<p>I wish someone would explain to me what to do and how to solve it.<\/p>\n"}
{"0":"Title: Why is b.pop(0) over 200 times slower than del b[0] for bytearray?.\nBody: <p>Letting them compete three times (a million pops\/dels each time):<\/p>\n<pre><code>from timeit import timeit\n\nfor _ in range(3):\n    t1 = timeit('b.pop(0)', 'b = bytearray(1000000)')\n    t2 = timeit('del b[0]', 'b = bytearray(1000000)')\n    print(t1 \/ t2)\n<\/code><\/pre>\n<p>Time ratios (<a href=\"https:\/\/tio.run\/##hZDBasMwDIbvfoqfXpxA6NyWwij0tvNeYIzhMCUxc@JMVjb89JnS9bDbdBGW@b5f9lxkSNPpceZ17TiNkDBSEIRxTiz3kzEzh0kqa@1zErpgt@TFx1h2kIHAXkJCyCZ9EePoHAZiatAugpxG2iTZ@IyYvqHt7JqtbWgmVsaEjC76j7LHU6I8WQHT5sfoRfS@S4yx4HOhrFFTo2xa@mHTmLPTaOg8RqirIHruaa@71uYGviFMuuPUU3WqLwZacsD1\/rbKtvs5zZWrbQPb6rwtQp7Zl@rgblWr6UYd\/1DvFNG@uNd\/qd@v08QHFdTr@gM\" rel=\"noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!<\/a>):<\/p>\n<pre><code>274.6037053753368\n219.38099365582403\n252.08691226683823\n<\/code><\/pre>\n<p>Why is <code>pop<\/code> that much slower at doing the same thing?<\/p>\n"}
{"0":"Title: Why is the simpler loop slower?.\nBody: <p>Called with <code>n = 10**8<\/code>, the simple loop is consistently significantly slower for me than the complex one, and I don't see why:<\/p>\n<pre><code>def simple(n):\n    while n:\n        n -= 1\n\ndef complex(n):\n    while True:\n        if not n:\n            break\n        n -= 1\n<\/code><\/pre>\n<p>Some times in seconds:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>simple 4.340795516967773\ncomplex 3.6490490436553955\nsimple 4.374553918838501\ncomplex 3.639145851135254\nsimple 4.336690425872803\ncomplex 3.624480724334717\nPython: 3.11.4 (main, Sep  9 2023, 15:09:21) [GCC 13.2.1 20230801]\n<\/code><\/pre>\n<p>Here's the looping part of the bytecode as shown by <code>dis.dis(simple)<\/code>:<\/p>\n<pre><code>  6     &gt;&gt;    6 LOAD_FAST                0 (n)\n              8 LOAD_CONST               1 (1)\n             10 BINARY_OP               23 (-=)\n             14 STORE_FAST               0 (n)\n\n  5          16 LOAD_FAST                0 (n)\n             18 POP_JUMP_BACKWARD_IF_TRUE     7 (to 6)\n<\/code><\/pre>\n<p>And for <code>complex<\/code>:<\/p>\n<pre><code> 10     &gt;&gt;    4 LOAD_FAST                0 (n)\n              6 POP_JUMP_FORWARD_IF_TRUE     2 (to 12)\n\n 11           8 LOAD_CONST               0 (None)\n             10 RETURN_VALUE\n\n 12     &gt;&gt;   12 LOAD_FAST                0 (n)\n             14 LOAD_CONST               2 (1)\n             16 BINARY_OP               23 (-=)\n             20 STORE_FAST               0 (n)\n\n  9          22 JUMP_BACKWARD           10 (to 4)\n<\/code><\/pre>\n<p>So it looks like the complex one does more work per iteration (two jumps instead of one). Then why is it faster?<\/p>\n<p>Seems to be a Python 3.11 phenomenon, see the comments.<\/p>\n<p>Benchmark script (<a href=\"https:\/\/ato.pxeger.com\/run?1=ZZBBDoIwEEXjtocws6MQIBI3hIQ7uHBnTIPahkaYklJUzuKGjR7K0wgUotG_mt--_E7__Vm1JlfYdY_GiCB-LZZCqxKMLDnIslLajDOZ5rqtCTlxAXV_UHCKbkKg1zWXBQe0ZhBCkEJk2aMa2NsPvNUN__BSACrznTDooHl2_ssUSoMAibCzW_jzC3vwYG0TDKTj4tQdraDRyvNiayot0VARMoZZyRnzJxICMC4h9trZjMUkjj98OrxwXUuFrq1pamtu7Q0\" rel=\"noreferrer\">Attempt This Online!<\/a>):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from time import time\nimport sys\n\ndef simple(n):\n    while n:\n        n -= 1\n\ndef complex(n):\n    while True:\n        if not n:\n            break\n        n -= 1\n\nfor f in [simple, complex] * 3:\n    t = time()\n    f(10**8)\n    print(f.__name__, time() - t)\n\nprint('Python:', sys.version)\n<\/code><\/pre>\n"}
{"0":"Title: AttributeError: module &#39;PIL.Image&#39; has no attribute &#39;ANTIALIAS&#39;.\nBody: <ul>\n<li>Trying to have images in my Tkinter GUI, hence using PIL.<\/li>\n<li>Image.ANTIALAIS is not working, however Image.BILINEAR works<\/li>\n<\/ul>\n<p>Here's some sample code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import tkinter as tk\nfrom PIL import Image, ImageTk\n\nwindow = tk.Tk()\n\nimage = Image.open(r&quot;VC.png&quot;)\nimage = image.resize((20, 20), Image.ANTIALIAS)\n\ntk_image = ImageTk.PhotoImage(image)\n\nimage_label = tk.Label(window, image=tk_image)\nimage_label.pack()\n\nwindow.mainloop()\n<\/code><\/pre>\n<p>Here's the error:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>Traceback (most recent call last):\n  File &quot;&lt;module1&gt;&quot;, line 19, in &lt;module&gt;\nAttributeError: module 'PIL.Image' has no attribute 'ANTIALIAS'\n<\/code><\/pre>\n<ul>\n<li>Tried reinstalling pip AND Pillow. Didn't work.<\/li>\n<li>Asked Chat-GPT about this, advised me to upgrade to Pillow's latest ver. I am on the latest ver (10.0.0)<\/li>\n<\/ul>\n"}
{"0":"Title: &quot;cannot import name &#39;DEFAULT_CIPHERS&#39; from &#39;urllib3.util.ssl_&#39;&quot; on AWS Lambda using a layer.\nBody: <h1>What I want to achieve<\/h1>\n<p>To scrape an website using AWS Lambda and save the data on S3.<\/p>\n<h1>The issues I'm having<\/h1>\n<p>When I execute Lambda, the following error message appears.<\/p>\n<blockquote>\n<p>{   &quot;errorMessage&quot;: &quot;Unable to import module 'lambda_function': cannot\nimport name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_'\n(\/opt\/python\/urllib3\/util\/ssl_.py)&quot;,   &quot;errorType&quot;:\n&quot;Runtime.ImportModuleError&quot;,   &quot;requestId&quot;:\n&quot;fb66bea9-cbad-4bd3-bd4d-6125454e21be&quot;,   &quot;stackTrace&quot;: [] }<\/p>\n<\/blockquote>\n<h1>Code<\/h1>\n<p>The minimum Lambda code is as follows.<\/p>\n<pre><code>import requests\nimport boto3 \n\ndef lambda_handler(event, context):\n    s3 = boto3.client('s3')\n    upload_res = s3.put_object(Bucket='horserace-dx', Key='\/raw\/a.html', Body='testtext')\n    \n    return event\n<\/code><\/pre>\n<p>An layer was added to the Lambda. Files were save in <code>python<\/code> folder using the commands below , frozen in a zip file, then uploaded to AWS Lambda as a layer.<\/p>\n<pre><code>!pip install requests -t .\/python --no-user\n!pip install pandas -t .\/python --no-user\n!pip install beautifulsoup4 -t .\/python --no-user\n<\/code><\/pre>\n<ul>\n<li>The bucket <code>horserace-dx<\/code> exists<\/li>\n<li>The folder <code>raw<\/code> exists<\/li>\n<li>The role of the Lambda is properly set. It can read from and write to S3<\/li>\n<li>The runtime of the Lambda is Python 3.9. The python version of the local computer is 3.9.13.<\/li>\n<\/ul>\n<h1>What I did so far<\/h1>\n<p>I google &quot;cannot import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_'&quot; and found some suggestions. I made the layer with the following code and tried again in vain.<\/p>\n<pre><code>!pip install requests -t .\/python --no-user\n!pip install pandas -t .\/python --no-user\n!pip install beautifulsoup4 -t .\/python --no-user\n!pip install urllib3==1.26.15 -t .\/python --no-user\n<\/code><\/pre>\n<p>So what should I do to achieve what I want to achieve? Any suggestions would be greatly appreciated.<\/p>\n"}
{"0":"Title: Why is np.dot so much faster than np.sum?.\nBody: <p>Why is np.dot so much faster than np.sum?  Following this <a href=\"https:\/\/stackoverflow.com\/questions\/61945412\/which-method-is-faster-and-why-np-sumarr-vs-arr-sum\/61945719#61945719\">answer<\/a> we know that np.sum is slow and has faster alternatives.<\/p>\n<p>For example:<\/p>\n<pre><code>In [20]: A = np.random.rand(1000)\n\nIn [21]: B = np.random.rand(1000)\n\nIn [22]: %timeit np.sum(A)\n3.21 \u00b5s \u00b1 270 ns per loop (mean \u00b1 std. dev. of 7 runs, 100,000 loops each)\n\nIn [23]: %timeit A.sum()\n1.7 \u00b5s \u00b1 11.5 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n\nIn [24]: %timeit np.add.reduce(A)\n1.61 \u00b5s \u00b1 19.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n<\/code><\/pre>\n<p>But all of them are slower than:<\/p>\n<pre><code>In [25]: %timeit np.dot(A,B)\n1.18 \u00b5s \u00b1 43.9 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n<\/code><\/pre>\n<p>Given that np.dot is both multiplying two arrays elementwise and then summing them, how can this be faster than just summing one array?  If B were set to the all ones array then np.dot would simply be summing A.<\/p>\n<p>So it seems the  fastest option to sum A is:<\/p>\n<pre><code>In [26]: O = np.ones(1000)\nIn [27]: %timeit np.dot(A,O)\n1.16 \u00b5s \u00b1 6.37 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n<\/code><\/pre>\n<p>This can't be right, can it?<\/p>\n<p>This is on Ubuntu with numpy 1.24.2 using openblas64 on Python 3.10.6.<\/p>\n<p>Supported SIMD extensions in this NumPy install:<\/p>\n<pre><code>baseline = SSE,SSE2,SSE3\nfound = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2\n<\/code><\/pre>\n<p><strong>Update<\/strong><\/p>\n<p>The order of the timings reverses if the array is much longer.  That is:<\/p>\n<pre><code>In [28]: A = np.random.rand(1000000)\nIn [29]: O = np.ones(1000000)\nIn [30]: %timeit np.dot(A,O)\n545 \u00b5s \u00b1 8.87 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\nIn [31]: %timeit np.sum(A)\n429 \u00b5s \u00b1 11 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)    \nIn [32]: %timeit A.sum()\n404 \u00b5s \u00b1 2.95 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\nIn [33]: %timeit np.add.reduce(A)\n401 \u00b5s \u00b1 4.21 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n<\/code><\/pre>\n<p>This implies to me that there is some fixed sized overhead when calling np.sum(A), A.sum(), np.add.reduce(A) that doesn't exist when calling np.dot() but the part of the code that does the summation is in fact faster.<\/p>\n<p>\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014-<\/p>\n<p>Any speed ups using cython, numba, python etc would be great to see.<\/p>\n"}
{"0":"Title: Why list comprehensions create a function internally?.\nBody: <p>This is disassembly of a list comprehension in <a href=\"\/questions\/tagged\/python-3.10\" class=\"post-tag\" title=\"show questions tagged &#39;python-3.10&#39;\" aria-label=\"show questions tagged &#39;python-3.10&#39;\" rel=\"tag\" aria-labelledby=\"tag-python-3.10-tooltip-container\">python-3.10<\/a>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.\n&gt;&gt;&gt; import dis\n&gt;&gt;&gt; \n&gt;&gt;&gt; dis.dis(&quot;[True for _ in ()]&quot;)\n  1           0 LOAD_CONST               0 (&lt;code object &lt;listcomp&gt; at 0x7fea68e0dc60, file &quot;&lt;dis&gt;&quot;, line 1&gt;)\n              2 LOAD_CONST               1 ('&lt;listcomp&gt;')\n              4 MAKE_FUNCTION            0\n              6 LOAD_CONST               2 (())\n              8 GET_ITER\n             10 CALL_FUNCTION            1\n             12 RETURN_VALUE\n\nDisassembly of &lt;code object &lt;listcomp&gt; at 0x7fea68e0dc60, file &quot;&lt;dis&gt;&quot;, line 1&gt;:\n  1           0 BUILD_LIST               0\n              2 LOAD_FAST                0 (.0)\n        &gt;&gt;    4 FOR_ITER                 4 (to 14)\n              6 STORE_FAST               1 (_)\n              8 LOAD_CONST               0 (True)\n             10 LIST_APPEND              2\n             12 JUMP_ABSOLUTE            2 (to 4)\n        &gt;&gt;   14 RETURN_VALUE\n<\/code><\/pre>\n<p>From what I understand it creates a code object called <code>listcomp<\/code> which does the actual iteration and return the result list, and immediately call it.\nI can't figure out the need to create a separate function to execute this job. Is this kind of an optimization trick?<\/p>\n"}
{"0":"Title: Unexpected uint64 behaviour 0xFFFF&#39;FFFF&#39;FFFF&#39;FFFF - 1 = 0?.\nBody: <p>Consider the following brief numpy session showcasing <code>uint64<\/code> data type<\/p>\n<pre><code>import numpy as np\n \na = np.zeros(1,np.uint64)\n \na\n# array([0], dtype=uint64)\n \na[0] -= 1\na\n# array([18446744073709551615], dtype=uint64)\n# this is 0xffff ffff ffff ffff, as expected\n\na[0] -= 1\na\n# array([0], dtype=uint64)\n# what the heck?\n<\/code><\/pre>\n<p>I'm utterly confused by this last output.<\/p>\n<p>I would expect 0xFFFF'FFFF'FFFF'FFFE.<\/p>\n<p>What exactly is going on here?<\/p>\n<p>My setup:<\/p>\n<pre><code>&gt;&gt;&gt; sys.platform\n'linux'\n&gt;&gt;&gt; sys.version\n'3.10.5 (main, Jul 20 2022, 08:58:47) [GCC 7.5.0]'\n&gt;&gt;&gt; np.version.version\n'1.23.1'\n<\/code><\/pre>\n"}
{"0":"Title: read_sql_query() throws &quot;&#39;OptionEngine&#39; object has no attribute &#39;execute&#39;&quot; with SQLAlchemy 2.0.0.\nBody: <p>First of all, I'm a totally new guys in the dev world\nI'm currently taking courses in AI \/ Data Science and one of my work is to use a SQL Database to make prediction using Prophet, then use these predition to make a PowerBI\nBut currently, I'm stuck with the Python code, I'm not a developer initially, so I have no clue where the problem is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sqlalchemy\nfrom sqlalchemy import create_engine\nimport pandas as pd\nfrom prophet import Prophet\nimport pymysql\n\n\nengine = create_engine(&quot;mysql+pymysql:\/\/root:Password@localhost:3306\/data&quot;)\nquery = &quot;SELECT Cle_Produit, Date_Facturation, SUM(Quantite) AS Total_Quantite FROM ventes GROUP BY         Cle_Produit, Date_Facturation&quot;\ndf = pd.read_sql_query(query, engine)\n\ndf = df.pivot(index='Date_Facturation', columns='Cle_Produit', values='Total_Quantite')\ndf = df.reset_index()\ndf.rename(columns={'Date_Facturation': 'ds', 'Total_Quantite': 'y'}, inplace=True)\n\n\nm = Prophet()\nm.fit(df)\nfuture = m.make_future_dataframe(periods=365)\nforecast = m.predict(future)\n\nforecast[['ds', 'yhat']].to_csv('forecast.csv', index=False)\n<\/code><\/pre>\n<p>It returns me this message:<\/p>\n<blockquote>\n<p>Importing plotly failed. Interactive plots will not work.\nTraceback (most recent call last):\nFile &quot;f:\\Backup\\Cours\\Cours\\Explo Data\\app3.py&quot;, line 9, in \ndf = pd.read_sql_query(query, engine)\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 397, in    read_sql_query\nreturn pandas_sql.read_query(\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 1560, in read_query\nresult = self.execute(*args)\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 1405, in execute\nreturn self.connectable.execution_options().execute(*args, **kwargs)\nAttributeError: 'OptionEngine' object has no attribute 'execute'<\/p>\n<\/blockquote>\n<p>Please, can somebody help me?<\/p>\n<p>I want this python script to create a csv file with the prediction from prophet.\nI want Prophet to use the table ventes from the DB data, and it should use the column <code>Cle_Produit<\/code>, <code>Quantite<\/code> and <code>Date_Facturation<\/code><\/p>\n"}
{"0":"Title: Cuda 12 + tf-nightly 2.12: Could not find cuda drivers on your machine, GPU will not be used, while every checking is fine and in torch it works.\nBody: <ul>\n<li><strong>tf-nightly version<\/strong> = 2.12.0-dev2023203<\/li>\n<li><strong>Python version<\/strong> = 3.10.6<\/li>\n<li><strong>CUDA drivers version<\/strong> = 525.85.12<\/li>\n<li><strong>CUDA version<\/strong> = 12.0<\/li>\n<li><strong>Cudnn version<\/strong> = 8.5.0<\/li>\n<li>I am using <strong>Linux<\/strong> (x86_64, Ubuntu 22.04)<\/li>\n<li>I am coding in <strong>Visual Studio Code<\/strong> on a <strong>venv<\/strong> virtual environment<\/li>\n<\/ul>\n<p>I am trying to run some models on the GPU (NVIDIA GeForce RTX 3050) using tensorflow nightly 2.12 (to be able to use Cuda 12.0). The problem that I have is that apparently every checking that I am making seems to be correct, but in the end the script is not able to detect the GPU. I've dedicated a lot of time trying to see what is happening and nothing seems to work, so any advice or solution will be more than welcomed. The GPU seems to be working for torch as you can see at the very end of the question.<\/p>\n<p>I will show some of the most common checkings regarding CUDA that I did (Visual Studio Code terminal), I hope you find them useful:<\/p>\n<ol>\n<li><p><strong>Check CUDA version:<\/strong><\/p>\n<p><code>$ nvcc --version<\/code><\/p>\n<pre><code>nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Fri_Jan__6_16:45:21_PST_2023\nCuda compilation tools, release 12.0, V12.0.140\nBuild cuda_12.0.r12.0\/compiler.32267302_0\n<\/code><\/pre>\n<\/li>\n<li><p><strong>Check if the connection with the CUDA libraries is correct:<\/strong><\/p>\n<p><code>$ echo $LD_LIBRARY_PATH<\/code><\/p>\n<pre><code>\/usr\/cuda\/lib\n<\/code><\/pre>\n<\/li>\n<li><p><strong>Check nvidia drivers for the GPU and check if GPU is readable for the venv:<\/strong><\/p>\n<p><code>$ nvidia-smi<\/code><\/p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage\/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N\/A |\n| N\/A   40C    P5     6W \/  20W |     46MiB \/  4096MiB |     22%      Default |\n|                               |                      |                  N\/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N\/A  N\/A      1356      G   \/usr\/lib\/xorg\/Xorg                 45MiB |\n+-----------------------------------------------------------------------------+\n<\/code><\/pre>\n<\/li>\n<li><p><strong>Add cuda\/bin PATH and Check it:<\/strong><\/p>\n<p><code>$ export PATH=&quot;\/usr\/local\/cuda\/bin:$PATH&quot;<\/code><\/p>\n<p><code>$ echo $PATH<\/code><\/p>\n<pre><code>\/usr\/local\/cuda-12.0\/bin:\/home\/victus-linux\/Escritorio\/MasterThesis_CODE\/to_share\/venv_master\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/usr\/games:\/usr\/local\/games:\/snap\/bin:\/snap\/bin\n<\/code><\/pre>\n<\/li>\n<li><p><strong>Custom function to check if CUDA is correctly installed: [<a href=\"https:\/\/stackoverflow.com\/questions\/31326015\/how-to-verify-cudnn-installation\">function by Sherlock<\/a>]<\/strong><\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>function lib_installed() { \/sbin\/ldconfig -N -v $(sed 's\/:\/ \/' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;\/dev\/null | grep $1; }\nfunction check() { lib_installed $1 &amp;&amp; echo &quot;$1 is installed&quot; || echo &quot;ERROR: $1 is NOT installed&quot;; }\ncheck libcuda\ncheck libcudart\n<\/code><\/pre>\n<pre><code>libcudart.so.12 -&gt; libcudart.so.12.0.146\n        libcuda.so.1 -&gt; libcuda.so.525.85.12\n        libcuda.so.1 -&gt; libcuda.so.525.85.12\n        libcudadebugger.so.1 -&gt; libcudadebugger.so.525.85.12\nlibcuda is installed\n        libcudart.so.12 -&gt; libcudart.so.12.0.146\nlibcudart is installed\n<\/code><\/pre>\n<\/li>\n<li><p><strong>Custom function to check if Cudnn is correctly installed: [<a href=\"https:\/\/stackoverflow.com\/questions\/31326015\/how-to-verify-cudnn-installation\">function by Sherlock<\/a>]<\/strong><\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>function lib_installed() { \/sbin\/ldconfig -N -v $(sed 's\/:\/ \/' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;\/dev\/null | grep $1; }\nfunction check() { lib_installed $1 &amp;&amp; echo &quot;$1 is installed&quot; || echo &quot;ERROR: $1 is NOT installed&quot;; }\ncheck libcudnn \n<\/code><\/pre>\n<pre><code>        libcudnn_cnn_train.so.8 -&gt; libcudnn_cnn_train.so.8.8.0\n        libcudnn_cnn_infer.so.8 -&gt; libcudnn_cnn_infer.so.8.8.0\n        libcudnn_adv_train.so.8 -&gt; libcudnn_adv_train.so.8.8.0\n        libcudnn.so.8 -&gt; libcudnn.so.8.8.0\n        libcudnn_ops_train.so.8 -&gt; libcudnn_ops_train.so.8.8.0\n        libcudnn_adv_infer.so.8 -&gt; libcudnn_adv_infer.so.8.8.0\n        libcudnn_ops_infer.so.8 -&gt; libcudnn_ops_infer.so.8.8.0\nlibcudnn is installed\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>So, once I did these previous checkings I used a script to evaluate if everything was finally ok and then the following error appeared:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import tensorflow as tf\n\nprint(f'\\nTensorflow version = {tf.__version__}\\n')\nprint(f'\\n{tf.config.list_physical_devices(&quot;GPU&quot;)}\\n')\n<\/code><\/pre>\n<pre><code>2023-03-02 12:05:09.463343: I tensorflow\/tsl\/cuda\/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-03-02 12:05:09.489911: I tensorflow\/tsl\/cuda\/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-03-02 12:05:09.490522: I tensorflow\/core\/platform\/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-03-02 12:05:10.066759: W tensorflow\/compiler\/tf2tensorrt\/utils\/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\nTensorflow version = 2.12.0-dev20230203\n\n2023-03-02 12:05:10.748675: I tensorflow\/compiler\/xla\/stream_executor\/cuda\/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https:\/\/github.com\/torvalds\/linux\/blob\/v6.0\/Documentation\/ABI\/testing\/sysfs-bus-pci#L344-L355\n2023-03-02 12:05:10.771263: W tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https:\/\/www.tensorflow.org\/install\/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n\n[]\n<\/code><\/pre>\n<p><strong>Extra check:<\/strong> I tried to run a checking script on torch and in here it worked so I guess the problem is related with tensorflow\/tf-nightly<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import torch\n\nprint(f'\\nAvailable cuda = {torch.cuda.is_available()}')\n\nprint(f'\\nGPUs availables = {torch.cuda.device_count()}')\n\nprint(f'\\nCurrent device = {torch.cuda.current_device()}')\n\nprint(f'\\nCurrent Device location = {torch.cuda.device(0)}')\n\nprint(f'\\nName of the device = {torch.cuda.get_device_name(0)}')\n<\/code><\/pre>\n<pre><code>Available cuda = True\n\nGPUs availables = 1\n\nCurrent device = 0\n\nCurrent Device location = &lt;torch.cuda.device object at 0x7fbe26fd2ec0&gt;\n\nName of the device = NVIDIA GeForce RTX 3050 Laptop GPU\n<\/code><\/pre>\n<p>Please, if you know something that might help solve this issue, don't hesitate on telling me.<\/p>\n"}
{"0":"Title: Theoretically can the Ackermann function be optimized?.\nBody: <p>I am wondering if there can be a version of Ackermann function with better time complexity than the standard variation.<\/p>\n<p>This is not a homework and I am just curious. I know the Ackermann function doesn't have any practical use besides as a performance benchmark, because of the deep recursion. I know the numbers grow very large very quickly, and I am not interested in computing it.<\/p>\n<p>Even though I use Python 3 and the integers won't overflow, I do have finite time, but I have implemented a version of it myself according to the definition found on <a href=\"https:\/\/en.wikipedia.org\/wiki\/Ackermann_function\" rel=\"noreferrer\">Wikipedia<\/a>, and computed the output for extremely small values, just to make sure the output is correct.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vsPES.jpg\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vsPES.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>def A(m, n):\n    if not m:\n        return n + 1\n    return A(m - 1, A(m, n - 1)) if n else A(m - 1, 1)\n<\/code><\/pre>\n<p>The above code is a direct translation of the image, and is extremely slow, I don't know how it can be optimized, is it impossible to optimize it?<\/p>\n<p>One thing I can think of is to memoize it, but the recursion runs backwards, each time the function is recursively called the arguments were not encountered before, each successive function call the arguments decrease rather than increase, therefore each return value of the function needs to be calculated, memoization doesn't help when you call the function with different arguments the first time.<\/p>\n<p>Memoization can only help if you call it with the same arguments again, it won't compute the results and will retrieve cached result instead, but if you call the function with any input with (m, n) &gt;= (4, 2) it will crash the interpreter regardless.<\/p>\n<p>I also implemented another version according to this <a href=\"https:\/\/stackoverflow.com\/a\/20411205\/16383578\">answer<\/a>:<\/p>\n<pre><code>def ack(x, y):\n    for i in range(x, 0, -1):\n        y = ack(i, y - 1) if y else 1\n    return y + 1\n<\/code><\/pre>\n<p>But it is actually slower:<\/p>\n<pre><code>In [2]: %timeit A(3, 4)\n1.3 ms \u00b1 9.75 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n\nIn [3]: %timeit ack(3, 4)\n2 ms \u00b1 59.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n<\/code><\/pre>\n<p>Theoretically can Ackermann function be optimized? If not, can it be definitely proven that its time complexity cannot decrease?<\/p>\n<hr \/>\n<p>I have just tested <code>A(3, 9)<\/code> and <code>A(4, 1)<\/code> will crash the interpreter, and the performance of the two functions for <code>A(3, 8)<\/code>:<\/p>\n<pre><code>In [2]: %timeit A(3, 8)\n432 ms \u00b1 4.63 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nIn [3]: %timeit ack(3, 8)\n588 ms \u00b1 10.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n<\/code><\/pre>\n<hr \/>\n<p>I did some more experiments:<\/p>\n<pre><code>from collections import Counter\nfrom functools import cache\n\nc = Counter()\ndef A1(m, n):\n    c[(m, n)] += 1\n    if not m:\n        return n + 1\n    return A(m - 1, A(m, n - 1)) if n else A(m - 1, 1)\n\ndef test(m, n):\n    c.clear()\n    A1(m, n)\n    return c\n<\/code><\/pre>\n<p>The arguments indeed repeat.<\/p>\n<p>But surprisingly caching doesn't help at all:<\/p>\n<pre><code>In [9]: %timeit Ackermann = cache(A); Ackermann(3, 4)\n1.3 ms \u00b1 10.1 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n<\/code><\/pre>\n<p>Caching only helps when the function is called with the same arguments again, as explained:<\/p>\n<pre><code>In [14]: %timeit Ackermann(3, 2)\n101 ns \u00b1 0.47 ns per loop (mean \u00b1 std. dev. of 7 runs, 10,000,000 loops each)\n<\/code><\/pre>\n<p>I have tested it with different arguments numerous times, and it always gives the same efficiency boost (which is none).<\/p>\n"}
{"0":"Title: Why is b.pop(0) over 200 times slower than del b[0] for bytearray?.\nBody: <p>Letting them compete three times (a million pops\/dels each time):<\/p>\n<pre><code>from timeit import timeit\n\nfor _ in range(3):\n    t1 = timeit('b.pop(0)', 'b = bytearray(1000000)')\n    t2 = timeit('del b[0]', 'b = bytearray(1000000)')\n    print(t1 \/ t2)\n<\/code><\/pre>\n<p>Time ratios (<a href=\"https:\/\/tio.run\/##hZDBasMwDIbvfoqfXpxA6NyWwij0tvNeYIzhMCUxc@JMVjb89JnS9bDbdBGW@b5f9lxkSNPpceZ17TiNkDBSEIRxTiz3kzEzh0kqa@1zErpgt@TFx1h2kIHAXkJCyCZ9EePoHAZiatAugpxG2iTZ@IyYvqHt7JqtbWgmVsaEjC76j7LHU6I8WQHT5sfoRfS@S4yx4HOhrFFTo2xa@mHTmLPTaOg8RqirIHruaa@71uYGviFMuuPUU3WqLwZacsD1\/rbKtvs5zZWrbQPb6rwtQp7Zl@rgblWr6UYd\/1DvFNG@uNd\/qd@v08QHFdTr@gM\" rel=\"noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!<\/a>):<\/p>\n<pre><code>274.6037053753368\n219.38099365582403\n252.08691226683823\n<\/code><\/pre>\n<p>Why is <code>pop<\/code> that much slower at doing the same thing?<\/p>\n"}
{"0":"Title: Why is the (virtual) destructor of the derived class not called when deleting an array through a pointer to the base class?.\nBody: <p>I have an <code>Animal<\/code> class with a virtual destructor, and a derived class <code>Cat<\/code>.<\/p>\n<pre><code>#include &lt;iostream&gt;\n\nstruct Animal\n{\n    Animal() { std::cout &lt;&lt; &quot;Animal constructor&quot; &lt;&lt; std::endl; }\n    virtual ~Animal() { std::cout &lt;&lt; &quot;Animal destructor&quot; &lt;&lt; std::endl; }\n};\n\nstruct Cat : public Animal\n{\n    Cat() { std::cout &lt;&lt; &quot;Cat constructor&quot; &lt;&lt; std::endl; }\n    ~Cat() override { std::cout &lt;&lt; &quot;Cat destructor&quot; &lt;&lt; std::endl; }\n};\n\nint main()\n{\n    const Animal *j = new Cat[1];\n    delete[] j;\n}\n<\/code><\/pre>\n<p>This gives the output:<\/p>\n<blockquote>\n<p>Animal constructor  <br \/>\nCat constructor  <br \/>\nAnimal destructor<\/p>\n<\/blockquote>\n<p>I don't understand why is the <code>Cat<\/code>'s destructor not called, when my base class destructor is virtual?<\/p>\n"}
{"0":"Title: Convenient way to declare 2D (or even higher dimension) arrays with std::array.\nBody: <p>I'm about to convert a lot of old C++ code to more modern C++.<\/p>\n<p>There are many raw 2D arrays in that code like:<\/p>\n<pre><code>Foo bar[XSIZE][YSIZE];\n<\/code><\/pre>\n<p>And I'm about to replace these declarations with<\/p>\n<pre><code>std::array&lt;std::array&lt;Foo, YSIZE&gt;, XSIZE&gt; bar;\n<\/code><\/pre>\n<p>This is a convenient way because the statements stay the same and the code is supposed to behave the same as with raw arrays with the additional benefit of being able to have out of bounds checks in debug builds.<\/p>\n<p>But IMO the <code>std::array&lt;std::array&lt;Foo, YSIZE&gt;&gt;<\/code> is somewhat cumbersome and not easy to read, and with 3D arrays (although I have none) it would even be worse.<\/p>\n<p>Right now I'm using this macro to make the declaration more readable:<\/p>\n<pre><code>#define DECLARE_2D_ARRAY(type, x, y) std::array&lt;std::array&lt;type, y&gt;, x&gt;\n...\nDECLARE_2D_ARRAY(Foo, XSIZE, YSIZE) bar;\n<\/code><\/pre>\n<p>But I feel this to be a macro hack, and I'm wondering if there is a cleaner, more C++ way to do something similar.<\/p>\n"}
{"0":"Title: GCC removes a bounds check in the right operand of &amp;&amp;, but not in the left operand, why?.\nBody: <p>I have the following C\/C++ code snippet:<\/p>\n<pre><code>#define ARRAY_LENGTH 666\n\nint g_sum = 0;\nextern int *g_ptrArray[ ARRAY_LENGTH ];\n\nvoid test()\n{\n    unsigned int idx = 0;\n\n    \/\/ either enable or disable the check &quot;idx &lt; ARRAY_LENGTH&quot; in the while loop\n    while( g_ptrArray[ idx ] != nullptr \/* &amp;&amp; idx &lt; ARRAY_LENGTH *\/ )\n    {\n        g_sum += *g_ptrArray[ idx ];\n        ++idx;\n    }\n\n    return;\n}\n<\/code><\/pre>\n<hr \/>\n<p>When I compile the above code using GCC compiler in version 12.2.0 with the option <code>-Os<\/code> for both cases:<\/p>\n<ol>\n<li>the while loop condition is <code>g_ptrArray[ idx ] != nullptr<\/code><\/li>\n<li>the while loop condition is <code>g_ptrArray[ idx ] != nullptr &amp;&amp; idx &lt; ARRAY_LENGTH<\/code><\/li>\n<\/ol>\n<p>I get the following assembly:<\/p>\n<pre><code>test():\n        ldr     r2, .L4\n        ldr     r1, .L4+4\n.L2:\n        ldr     r3, [r2], #4\n        cbnz    r3, .L3\n        bx      lr\n.L3:\n        ldr     r3, [r3]\n        ldr     r0, [r1]\n        add     r3, r3, r0\n        str     r3, [r1]\n        b       .L2\n.L4:\n        .word   g_ptrArray\n        .word   .LANCHOR0\ng_sum:\n        .space  4\n<\/code><\/pre>\n<p>As you can see the assembly does !NOT! do any checking of the variable <code>idx<\/code> against the value <code>ARRAY_LENGTH<\/code>.<\/p>\n<hr \/>\n<h2>My question<\/h2>\n<p>How is that possible?\nHow can the compiler generate the exactly same assembly for both cases and ignore the <code>idx &lt; ARRAY_LENGTH<\/code> condition if it is present in the code? Explain me the rule or procedure, how the compiler comes to the conclusion that it can completely remove the condition.<\/p>\n<p>The output assembly shown in Compiler Explorer (see both assemblies are identical):<\/p>\n<ol>\n<li><p>the while condition is <code>g_ptrArray[ idx ] != nullptr<\/code>:<\/p>\n<ul>\n<li><a href=\"https:\/\/godbolt.org\/z\/M13oEcKqM\" rel=\"noreferrer\">https:\/\/godbolt.org\/z\/M13oEcKqM<\/a><\/li>\n<\/ul>\n<\/li>\n<li><p>the while condition is <code>g_ptrArray[ idx ] != nullptr &amp;&amp; idx &lt; ARRAY_LENGTH<\/code>:<\/p>\n<ul>\n<li><a href=\"https:\/\/godbolt.org\/z\/T6e3PWjn6\" rel=\"noreferrer\">https:\/\/godbolt.org\/z\/T6e3PWjn6<\/a><\/li>\n<\/ul>\n<\/li>\n<\/ol>\n<p>NOTE: If I swap the order of conditions to be <code>idx &lt; ARRAY_LENGTH &amp;&amp; g_ptrArray[ idx ] != nullptr<\/code>, the output assembly contains the check for value of <code>idx<\/code> as you can see here: <a href=\"https:\/\/godbolt.org\/z\/fvbsTfr9P\" rel=\"noreferrer\">https:\/\/godbolt.org\/z\/fvbsTfr9P<\/a>.<\/p>\n"}
{"0":"Title: Are multidimensional array accesses sequenced?.\nBody: <p>Take the following:<\/p>\n<pre><code>int a(void) {\n    puts(&quot;a&quot;);\n    return 0;\n}\n\nint b(void) {\n    puts(&quot;b&quot;);\n    return 1;\n}\n\nint c(void) {\n    puts(&quot;c&quot;);\n    return 2;\n}\n\nint d(void) {\n    puts(&quot;d&quot;);\n    return 3;\n}\n<\/code><\/pre>\n<p>Will the following have predictable behavior?<\/p>\n<pre><code>int arr[4][4][4][4];\narr[a()][b()][c()][d()] = 1;\n<\/code><\/pre>\n<p>Is it guaranteed to print in this order:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>a\nb\nc\nd\n<\/code><\/pre>\n<p>I am aware that constructs such as the following are invalid:<\/p>\n<pre><code>int i;\ni = i++;\n<\/code><\/pre>\n<p>This is because <code>=<\/code> is an unsequenced operator, so whether <code>i<\/code> or <code>i++<\/code> is evaluated first is undefined. It is undefined behavior to access and modify a single object before another sequence point.<\/p>\n<p>Put another way, is the following valid:<\/p>\n<pre><code>int i = 0, arr[4][4][4][4];\narr[i++][i++][i++][i++] = 1;\n<\/code><\/pre>\n<p>Or does it invoke undefined behavior due to unsequenced modification and access to <code>i<\/code>?<\/p>\n<p>According to the C standard, is there a defined sequence point between each successive <code>[]<\/code> while indexing a multidimensional array?<\/p>\n<p>To be clear, neither of these examples have to do with precedence, the placement of implicit parenthesis, the order in which the operators operate on their operands. The question is about sequencing, the order in which the <em>operands themselves<\/em> are evaluated.<\/p>\n"}
{"0":"Title: How to use array input for a custom GitHub Actions.\nBody: <p>I'm working on a GitHub Action <a href=\"https:\/\/github.com\/MathieuSoysal\/Javadoc-publisher.yml\/blob\/4ea2062374784e3de840530c99365039f5fa76bb\/action.yml#L47-L50\" rel=\"noreferrer\">workflow<\/a> that uses an array for input.<\/p>\n<p>I used this solution to simulate an array:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>      - uses: actions\/my-custom-ci\n        with:\n          subdirectories: src\/main\/java src\/test\/java\n<\/code><\/pre>\n<p>But I want to use a solution like this:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>      - uses: actions\/my-custom-ci\n        with:\n          subdirectories: \n                - src\/main\/java \n                - src\/test\/java\n<\/code><\/pre>\n<p>Is it possible to use an array input for custom GitHub Actions? If yes, how can we use an array input for custom GitHub Actions?<\/p>\n"}
{"0":"Title: Merging users with multiple refs and count their collective assets.\nBody: <p>There is a set of users. A person can have multiple users, but <code>ref1<\/code> and <code>ref2<\/code> might be alike and can therefore link users together. <code>ref1<\/code> and <code>ref2<\/code> does not overlap, one value in <code>ref1<\/code> does not exist in <code>ref2<\/code>.<\/p>\n<p>A user can own multiple assets. I want to &quot;merge&quot; users that has one or more refs alike and then count how many assets they own together. There could be missing entries in the user table, in that case I just want to propagate the owner into ref2 and set the asset_count and asset_ids.<\/p>\n<p>Here is an example schema to illustrate:<\/p>\n<p><strong>Example assets<\/strong><\/p>\n<pre><code>SELECT * FROM assets;\n<\/code><\/pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id<\/th>\n<th>name<\/th>\n<th>owner<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1<\/td>\n<td>#1<\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>2<\/td>\n<td>#2<\/td>\n<td>b<\/td>\n<\/tr>\n<tr>\n<td>3<\/td>\n<td>#3<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>4<\/td>\n<td>#4<\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>5<\/td>\n<td>#5<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>6<\/td>\n<td>#6<\/td>\n<td>d<\/td>\n<\/tr>\n<tr>\n<td>7<\/td>\n<td>#7<\/td>\n<td>e<\/td>\n<\/tr>\n<tr>\n<td>8<\/td>\n<td>#8<\/td>\n<td>d<\/td>\n<\/tr>\n<tr>\n<td>9<\/td>\n<td>#9<\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>10<\/td>\n<td>#10<\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>11<\/td>\n<td>#11<\/td>\n<td>z<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div><hr \/>\n<p><strong>Example users<\/strong><\/p>\n<pre><code>SELECT * FROM users;\n<\/code><\/pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id<\/th>\n<th>username<\/th>\n<th>ref1<\/th>\n<th>ref2<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1<\/td>\n<td>bobo<\/td>\n<td>a<\/td>\n<td>d<\/td>\n<\/tr>\n<tr>\n<td>2<\/td>\n<td>toto<\/td>\n<td>b<\/td>\n<td>e<\/td>\n<\/tr>\n<tr>\n<td>3<\/td>\n<td>momo<\/td>\n<td>c<\/td>\n<td>d<\/td>\n<\/tr>\n<tr>\n<td>4<\/td>\n<td>lolo<\/td>\n<td>a<\/td>\n<td>f<\/td>\n<\/tr>\n<tr>\n<td>5<\/td>\n<td>popo<\/td>\n<td>c<\/td>\n<td>f<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p><strong>What I want to get in the end<\/strong><\/p>\n<pre><code>SELECT * FROM results;\n<\/code><\/pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ids<\/th>\n<th>usernames<\/th>\n<th>refs1<\/th>\n<th>refs2<\/th>\n<th>asset_ids<\/th>\n<th>asset_count<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1,3,4,5<\/td>\n<td>bobo,momo,lolo,popo<\/td>\n<td>a,c<\/td>\n<td>d,f<\/td>\n<td>1,3,4,5,6,8,9,10<\/td>\n<td>8<\/td>\n<\/tr>\n<tr>\n<td>2<\/td>\n<td>toto<\/td>\n<td>b<\/td>\n<td>e<\/td>\n<td>2,7<\/td>\n<td>2<\/td>\n<\/tr>\n<tr>\n<td><\/td>\n<td><\/td>\n<td><\/td>\n<td>z<\/td>\n<td>11<\/td>\n<td>1<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I've tried different approaches, but this is what I currently have:<\/p>\n<p><strong>Closest I have got<\/strong><\/p>\n<pre><code>SELECT\n  ARRAY_AGG(DISTINCT u.id) AS ids,\n  ARRAY_AGG(DISTINCT u.username) AS usernames,\n  ARRAY_AGG(DISTINCT u.ref1) AS refs1,\n  ARRAY_AGG(DISTINCT u.ref2) AS refs2,\n  COUNT(DISTINCT a.id) AS asset_count\nFROM assets a\nJOIN users u ON a.owner = u.ref1 OR a.owner = u.ref2\nGROUP BY a.owner\nORDER BY MIN(a.id);\n<\/code><\/pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ids<\/th>\n<th>usernames<\/th>\n<th>refs1<\/th>\n<th>refs2<\/th>\n<th>asset_count<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1,4<\/td>\n<td>bobo,lolo<\/td>\n<td>a<\/td>\n<td>d,f<\/td>\n<td>4<\/td>\n<\/tr>\n<tr>\n<td>2<\/td>\n<td>toto<\/td>\n<td>b<\/td>\n<td>e<\/td>\n<td>1<\/td>\n<\/tr>\n<tr>\n<td>3,5<\/td>\n<td>momo,popo<\/td>\n<td>c<\/td>\n<td>d,f<\/td>\n<td>2<\/td>\n<\/tr>\n<tr>\n<td>1,3<\/td>\n<td>bobo,momo<\/td>\n<td>a,c<\/td>\n<td>d<\/td>\n<td>2<\/td>\n<\/tr>\n<tr>\n<td>2<\/td>\n<td>toto<\/td>\n<td>b<\/td>\n<td>e<\/td>\n<td>1<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>If I merge the above table on ids, I almost get the result I want (without the missing entries in the user table). The merging can easily be done in code, but then I cannot paginate etc. I want to to this in DB layer if possible.<\/p>\n<p>I want either a solution to the problem or a good explanation of why it is not possible to do (with examples).<\/p>\n<p>Please check out my <a href=\"https:\/\/www.db-fiddle.com\/f\/4jyoMCicNSZpjMt4jFYoz5\/8836\" rel=\"noreferrer\">DB Fiddle<\/a>.<\/p>\n"}
{"0":"Title: std::sort invocation causes subscript out of range compile-time error.\nBody: <p>The below code fails to compile with error: &quot;array subscript 16 is outside array bounds of \u2026&quot;.\nI don't understand why, <code>w<\/code> is guaranteed to be &lt;= arr1.size().<\/p>\n<p><a href=\"https:\/\/godbolt.org\/z\/5n5KohsnW\" rel=\"nofollow noreferrer\">https:\/\/godbolt.org\/z\/5n5KohsnW<\/a><\/p>\n<pre><code>#include &lt;array&gt;\n#include &lt;algorithm&gt;\n#include &lt;tuple&gt;\n\nextern bool test_func();\n\nint tempfunc() \n{\n    std::array&lt;std::tuple&lt;double,int&gt;,5&gt; arr1;\n    int w = 0;\n    for (int i = 0; i &lt; 5; ++i ) {\n        if( test_func()) {\n            arr1[w] = {3.,4};\n            w++;\n        }\n    }\n    std::sort(arr1.begin(), arr1.begin() + w);\n\n    return 0;\n}\n<\/code><\/pre>\n"}
{"0":"Title: Why is this Raku program producing a Seq of Array rather than a simple Array?.\nBody: <pre><code>my %f;\nfor $*HOME.dir() -&gt; $file {\n    my $filename = $file.basename;\n    %f{$filename}.push: $file, rand;\n}\nmy $p = %f.pick; # just need any old random element\nsay $p.^name;\nsay &quot;{$p.values.^name} has {$p.values.elems} elements&quot;;\nsay &quot;{$p.values[0].^name} has {$p.values[0].elems} elements&quot;;\n\nsay '';\nsay $*RAKU;\nsay $*DISTRO;\nsay $*KERNEL;\nsay $*VM;\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>Pair\nSeq has 1 elements\nArray has 2 elements\n\nRaku (6.d)\nmacos (13.2.1)\ndarwin\nmoar (2023.02)\n<\/code><\/pre>\n<p>Why is the <code>.values<\/code> of <code>$p<\/code> a <code>Seq<\/code> of <code>Array<\/code>, rather than a simple <code>Array<\/code>?<\/p>\n"}
{"0":"Title: Extend list with another list in specific index?.\nBody: <p>In python we can add lists to each other with the extend() method but it adds the second list at the end of the first list.<\/p>\n<pre><code>lst1 = [1, 4, 5]\nlst2 = [2, 3]\n\nlst1.extend(lst2)\n\nOutput:\n[1, 4, 5, 2, 3]\n<\/code><\/pre>\n<p>How would I add the second list to be apart of the 1st element? Such that the result is this;<\/p>\n<pre><code>[1, 2, 3, 4, 5 ]\n<\/code><\/pre>\n<p>I've tried using <code>lst1.insert(1, *lst2)<\/code> and got an error;<\/p>\n<pre><code>TypeError: insert expected 2 arguments, got 3\n<\/code><\/pre>\n"}
{"0":"Title: Can you initialize a &quot;cv char[]&quot; with a string literal?.\nBody: <p>The current wording in <a href=\"https:\/\/eel.is\/c++draft\/dcl.init.string#1\" rel=\"nofollow noreferrer\">[dcl.init.string] p1<\/a> states:<\/p>\n<blockquote>\n<p>An array of ordinary character type, [...] may be initialized by an ordinary string literal, [...], or by an appropriately-typed <em>string-literal<\/em> enclosed in braces.<\/p>\n<\/blockquote>\n<p><em>Ordinary character type<\/em> includes <code>char<\/code>, <code>signed char<\/code>, and <code>unsigned char<\/code> (see <a href=\"https:\/\/eel.is\/c++draft\/basic.fundamental#def:type,ordinary_character\" rel=\"nofollow noreferrer\">[basic.fundamental]<\/a>). It does not include the cv-qualified versions of those types.<\/p>\n<p>From this, it isn't clear whether an array of <code>const char<\/code> or <code>volatile char<\/code> may also be initialized using a string literal, not just an array of <code>char<\/code>. The wording is unclear because it doesn't say:<\/p>\n<blockquote>\n<p>An array of <em>cv<\/em> ordinary character type, [...]<\/p>\n<\/blockquote>\n<p>This matters in the following situation:<\/p>\n<pre class=\"lang-cpp prettyprint-override\"><code>const char str[] = &quot;test&quot;; \/\/ is this valid?\n<\/code><\/pre>\n<p>I'm 99% sure that the intention is that you <em>should<\/em> be able to do it. However, is there a paragraph that definitively allows you to, or is this a wording defect?<\/p>\n"}
{"0":"Title: Is gcc wrong to allow the initialization of a const array member with another array reference?.\nBody: <p>While (re)implementing a simple constexpr map, I wrote this\n(<a href=\"https:\/\/gcc.godbolt.org\/z\/6TnKn6zx4\" rel=\"nofollow noreferrer\">godbolt<\/a>):<\/p>\n<pre class=\"lang-cpp prettyprint-override\"><code>template &lt;class key_type, class value_type, int N&gt;\nclass flat_map\n{\nprivate:\n    struct pair\n    {\n        key_type key;\n        value_type value;\n    };\n    const pair elements[N];\n\npublic:\n    consteval flat_map(const pair (&amp;arr)[N]) noexcept\n        : elements(arr) \/\/ works on gcc?!\n    {}\n\n    [[nodiscard]] consteval value_type operator[](const key_type key) const\n    {\n        for (const pair &amp;elem : elements)\n            if (elem.key == key)\n                return elem.value;\n        throw &quot;Key not found&quot;;\n    }\n};\n\nconstexpr flat_map&lt;int, char, 3&gt; m = {{\n    { 4, 'a' }, { -1, 'b' }, { 42, 'c' }\n}};\nstatic_assert(m[4] == 'a');\nstatic_assert(m[-1] == 'b');\nstatic_assert(m[42] == 'c');\n\nint main()\n{\n    return m[4]; \/\/ 97=='a'\n}\n<\/code><\/pre>\n<p>I naively thought to set the private array <code>elements<\/code> as <code>const<\/code> and initialize it in the constructor; I was using <em>gcc<\/em> trunk as compiler, and all was seemingly working well.\nWhen I decided to try it with <em>msvc<\/em> and <em>clang<\/em>, I had compilation errors: both were complaining about the array initialization requiring a brace-enclosed initializer list.<\/p>\n<p>In hindsight the other compilers aren't particularly wrong, are they?\nAm I inadvertently using some <em>gcc<\/em> non standard extensions here?<\/p>\n<p>Ehm, by the way, what would you do to avoid copying the array elements by hand?<\/p>\n"}
{"0":"Title: why std::pair&lt;int[N], int[N]&gt; is not allowed in C++?.\nBody: <p>Why the C++ code below can't be compiled?<\/p>\n<pre><code>#include &lt;utility&gt;\n\nint main() {\n    int x[6];\n    int y[6];\n    std::pair&lt;int[6], int[6]&gt; a(x, y);\n    return 0;\n}\n<\/code><\/pre>\n<p>For example MSVC gives the following error:<\/p>\n<blockquote>\n<p>error C2661: 'std::pair&lt;int [6],int [6]&gt;::pair': no overloaded function takes 2 argument<\/p>\n<\/blockquote>\n<p>Thanks for the comments that using C++ alternatives to construct arrays, but I also want to know the reason that the code can't be compiled.<\/p>\n"}
{"0":"Title: toSpliced() method throwing TypeError in VS Code Debug Console.\nBody: <p>I am getting the following error on VS Code Debug Console;<\/p>\n<p>&quot;Uncaught TypeError TypeError: months.toSpliced is not a function&quot;<\/p>\n<p>when I run this code;<\/p>\n<pre><code>const months = [&quot;Jan&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;];\n\n\/\/ Inserting an element at index 1\nconst months2 = months.toSpliced(1, 0, &quot;Feb&quot;);\nconsole.log(months2); \/\/ [&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;]\n<\/code><\/pre>\n<p>It is not even my code, I copy-pasted it from here; <a href=\"https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Reference\/Global_Objects\/Array\/toSpliced\" rel=\"noreferrer\">https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Reference\/Global_Objects\/Array\/toSpliced<\/a><\/p>\n<p>I came across this error while trying to learn toSpliced() method.<\/p>\n<p>Any help would be highly appreciated. Thank you.<\/p>\n"}
{"0":"Title: Is a two-dimensional array implemented as a continuous one-dimensional array\uff1f.\nBody: <p>I have a question about the memory layout of a two-dimensional array.\nWhen we define one, just like int <code>a[3][4]<\/code>, is the memory allocated to this array continuous?<\/p>\n<p>Or in other words, is a two-dimensional array implemented as a continuous one-dimensional array?<\/p>\n<p>If the answer is yes, is accessing <code>a[0][6]<\/code> equivalent to accessing <code>a[1][2]<\/code>?<\/p>\n<p>I wrote the following C program.<\/p>\n<pre><code>#include &lt;stdio.h&gt;\nint main(){\n    int a[3][4] = {{1, 2, 3, 4},\n                   {5, 6, 7, 8},\n                   {9, 10, 11, 12}};\n    printf(&quot;%d %d\\n&quot;, a[0][6], a[1][2]);\n    return 0;\n}\n<\/code><\/pre>\n<p>I find that the output is <code>7 7<\/code>.<\/p>\n<p><code>a[0][6]<\/code> seems illegal, but it points to <code>a[1][2]<\/code>, I want to know why and is such operation legal?<\/p>\n"}
{"0":"Title: How to shuffle array of items but allow weights to influence the order.\nBody: <p>I'm trying to write a TypeScript function to shuffle an array.<\/p>\n<p>By default, I want the shuffle order to be random (but subject to a seed).\n(I already have access to this function: <code>function random(seed: number): number<\/code>)<\/p>\n<p>However, I want to also allow influencing the order via weights per item.<\/p>\n<p>In other words, I want the the default item weight to be 1, and if an item has a weight of 10, it should be 10 times more likely to appear sooner in the shuffled order.<\/p>\n<p>Am I even thinking about this correctly? Is this a reasonable goal?<\/p>\n<p>I was thinking that I'd need to use the Fisher-Yates algorithm but adapted to honor a weights array of the same length as the main array, and the main array will be shuffled such that higher weighted items are more likely to appear first.<\/p>\n<pre><code>function removeDuplicates&lt;T&gt;(array: T[]): T[] {\n  const uniqueValues = new Set&lt;T&gt;();\n  return array.filter((item) =&gt; {\n    if (!uniqueValues.has(item)) {\n      uniqueValues.add(item);\n      return true;\n    }\n\n    return false;\n  });\n}\n\nfunction duplicateItemsBasedOnWeights&lt;T&gt;(array: T[], weights: number[]): T[] {\n  const result = [];\n  for (const [index, element] of array.entries()) {\n    for (let position = 0; position &lt; weights[index]; position++) {\n      result.push(element);\n    }\n  }\n\n  return result;\n}\n\nexport function shuffleWithWeights&lt;T&gt;(array: T[], weights: number[], seed: number): T[] {\n  const arrayWithDuplicateValuesBasedOnWeights: T[] = duplicateItemsBasedOnWeights(array, weights);\n\n  const shuffledArrayWithDuplicateValuesBasedOnWeights = shuffleArrayUsingFisherYates(arrayWithDuplicateValuesBasedOnWeights, seed);\n\n  return removeDuplicates(shuffledArrayWithDuplicateValuesBasedOnWeights);\n}\n<\/code><\/pre>\n<p>I've looked at empirical results by calling it a bunch of different times with these values (and a different seed each time), and the results don't seem distributed how I'd hoped, so I must have been approaching this problem incorrectly.<\/p>\n<pre><code>const items = [1, 2, 3, 4, 5];\nconst weights = [1, 1, 1, 200, 1_000];\n<\/code><\/pre>\n<p>In my real-world cases, I'll be shuffling 70,000 objects (which would explore to <em>many<\/em> more than that if I use my current approach of creating duplicate items based on item weight).<\/p>\n"}
{"0":"Title: Why does a nested array object prevent providing storage?.\nBody: <p>At <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/lifetime\" rel=\"noreferrer\">Lifetime<\/a> under <strong>Providing storage<\/strong>, it says:<\/p>\n<blockquote>\n<p>As a special case, objects can be created in arrays of unsigned char or std::byte (since C++17) (in which case it is said that the array provides storage for the object) if<\/p>\n<ul>\n<li>the lifetime of the array has begun and not ended<\/li>\n<li>the storage for the new object fits entirely within the array<\/li>\n<li>there is no array object that satisfies these constraints nested within the array.<\/li>\n<\/ul>\n<\/blockquote>\n<p>Why is the third condition there?<\/p>\n<p>Even if there's a nested array (I believe it means an array which starts at some index of the outer array and ends at an index that's no farther, not an array which is an item of the outer array, as the term nested would probably be understood in most languages), what difficulty does it pose to the standard authors or implementations to enable a segment of the outer array disjoint with the nested array to provide storage?<\/p>\n<p>And, if the nested array doesn't have any array nested in it, do I understand correctly that it can provide storage? If so, why can't the outer array provide storage in the same place, i.e. with the segment providing storage not straddling the start or end of any nested (perhaps indirectly) array?<\/p>\n<p>And, even with straddling, what problems could arise that the standard included this requirement to avoid?<\/p>\n<p>Additionally, can a nested array not satisfy the second condition, i.e. overlap it partially? Can such arrays even exist? In what sense and under ehat conditions is then one nested in another? Can both ever be nested in each other?<\/p>\n"}
{"0":"Title: Why can I declare array with a constant size in some cases and not others?.\nBody: <p>Im trying to create a struct that includes a 2d array along with some member functions.<\/p>\n<p>When I write:<\/p>\n<pre><code>struct Board {\n    const int BOARDSIZE = 8;\n\n    bool data[BOARDSIZE][BOARDSIZE];\n};\n<\/code><\/pre>\n<p>I get &quot;a nonstatic member reference must be relative to a specific object.&quot; However, when I write:<\/p>\n<pre><code>const int BOARDSIZE = 8;\n\nstruct Board {\n    bool data[BOARDSIZE][BOARDSIZE];\n};\n<\/code><\/pre>\n<p>or:<\/p>\n<pre><code>struct Board {\n    bool data[8][8];\n};\n<\/code><\/pre>\n<p>there is no error. I've searched around and cant figure out why it wont accept one and not the other. I'd rather not declare BOARDSIZE as a global variable because I dont want it just floating around in a large project but I also dont want to have to write 8 every time a member function of the struct needs the board size for flexability's sake down the line.<\/p>\n<p>Is there a way to have a local variable that represents the size of the board?<\/p>\n"}
{"0":"Title: Obtain palindromic array by performing these operations.\nBody: <p>An array is called palindromic if it remains the same after reversing the order of its elements.<\/p>\n<p>You have an array of strings arr. For each i, <code>arr[i]<\/code> consists of at least two characters. For each pair of consecutive elements <code>arr[i]<\/code> and <code>arr[i + 1]<\/code>, you can:<\/p>\n<ol>\n<li>Move the rightmost character of <code>arr[i]<\/code> to the leftmost position in <code>arr[i + 1]<\/code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;ab&quot; and &quot;cdef&quot;. This operation can be applied only once to any pair of consecutive elements.<\/li>\n<li>Move the leftmost character of <code>arr[i + 1]<\/code> to the rightmost position in <code>arr[i]<\/code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;abcd&quot; and &quot;ef&quot;. Again, this operation can be applied only once to any pair of consecutive elements.<\/li>\n<li>Do nothing to the pair of consecutive elements.<\/li>\n<\/ol>\n<p>Is it possible to obtain a palindromic array from arr by performing these operations?<\/p>\n<p>Consider the case when arr = <code>{&quot;aa&quot;, &quot;bab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}<\/code>. Here the output should be true and here is why:<\/p>\n<p>Move first char from 1st index to the last position of 0th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}<\/code>\nMove last char from 3rd index to the first position of 4th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;ab&quot;, &quot;aab&quot;}<\/code>, which is a palindromic array.<\/p>\n<p>I tried solutions such as two pointer, etc. but doesn't seem to work.<\/p>\n"}
{"0":"Title: sorting an array of objects JS.\nBody: <p>Hello everyone I still can't sort the array correctly. We need to sort the following array:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>const arr = [\n     {id: 3123124, parentId: 0o0000, title: 'title', type: 'block'},\n     {id: 3542132, parentId: 3123124, title: 'title', type: 'child'},\n     {id: 12345, parentId: 88888, title: 'title', type: 'block'},\n     {id: 24124, parentId: 12345, title: 'title', type: 'child'},\n     {id: 99999, parentId: 45324, title: 'title', type: 'child'},\n     {id: 986648, parentId: 3123124, title: 'title', type: 'block'},\n     {id: 77777, parentId: 88888, title: 'title', type: 'child'},\n     {id: 54232, parentId: 3123124, title: 'title', type: 'child'},\n     {id: 54308, parentId: 15075, title: 'title', type: 'child'},\n     {id: 66666, parentId: 88888, title: 'title', type: 'block'},\n     {id: 56445, parentId: 12345, title: 'title', type: 'child'},\n     {id: 88888, parentId: 45324, title: 'title', type: 'block'},\n     {id: 15075, parentId: 12345, title: 'title', type: 'block'},\n     {id: 84356, parentId: 66666, title: 'title', type: 'child'},\n     {id: 45324, parentId: 0o0000, title: 'title', type: 'block'},\n]\n\nconst newArr = [\n    {id: 3123124, parentId: 0o0000, title: 'title', type: 'block'},\n    {id: 3542132, parentId: 3123124, title: 'title', type: 'child'},\n    {id: 54232, parentId: 3123124, title: 'title', type: 'child'},\n    {id: 986648, parentId: 3123124, title: 'title', type: 'block'},\n    {id: 45324, parentId: 0o0000, title: 'title', type: 'block'},\n    {id: 99999, parentId: 45324, title: 'title', type: 'child'},\n    {id: 88888, parentId: 45324, title: 'title', type: 'block'},\n    {id: 77777, parentId: 88888, title: 'title', type: 'child'},\n    {id: 12345, parentId: 88888, title: 'title', type: 'block'},\n    {id: 56445, parentId: 12345, title: 'title', type: 'child'},\n    {id: 24124, parentId: 12345, title: 'title', type: 'child'},\n    {id: 15075, parentId: 12345, title: 'title', type: 'block'},\n    {id: 54308, parentId: 15075, title: 'title', type: 'child'},\n    {id: 66666, parentId: 88888, title: 'title', type: 'block'},\n    {id: 84356, parentId: 66666, title: 'title', type: 'child'},\n]\n<\/code><\/pre>\n<ul>\n<li>arr - array to sort<\/li>\n<li>newArr - is an array that should turn out to be<\/li>\n<\/ul>\n<p>So that the topmost elements have <code>parentId: 0o000<\/code>, and their lowest children, who have the same <code>parentId<\/code> <code>id<\/code>, and so on, there can be as many elements as you like.\nIf the <code>parentId<\/code> is the same for several elements, then <code>child<\/code> comes first, the most recent <code>block<\/code> and its children below, if there are any.<\/p>\n<p>I tried to add to a new array by the <code>parentId<\/code> property, but in the end the order of the elements was lost<\/p>\n"}
{"0":"Title: ValueError: libcublas.so.*[0-9] not found in the system path.\nBody: <p>I'm trying to import and use ultralytics library in my Django rest framework project, I use poetry as my dependency manager, I installed ultralytics using <code>poetry add ultralytics<\/code> and on trying to import the library in my code I recieve this error<\/p>\n<pre><code>ValueError: libcublas.so.*[0-9] not found in the system path [my project and virtual environment paths]\n<\/code><\/pre>\n<p>how can I solve that?<\/p>\n"}
{"0":"Title: Django returns &#39;TemplateDoesNotExist&#39; when using Crispy Forms.\nBody: <p>Using Crispy Forms with Django, I can only get a <code>TemplateDoesNotExist<\/code> error when using any feature of Crispy Forms.<\/p>\n<p>As I'm new to Crispy Forms (which seems to be universally recommended for <em>quickly<\/em> making forms look better), I have followed the instructions at <a href=\"https:\/\/django-crispy-forms.readthedocs.io\/en\/latest\/install.html\" rel=\"noreferrer\">https:\/\/django-crispy-forms.readthedocs.io\/en\/latest\/install.html<\/a> and as far as I know, the installation is correct (installed using <code>pip<\/code> and changes in <code>settings.py<\/code>). I am running this in a virtual environment (the <code>.venv<\/code> folder referred to below) on a Windows machine.<\/p>\n<p>I have even created a new project specifically to look at this, with absolutely minimal content, and the same problem persists. The project is called 'stuff' and the single app in it 'other'.<\/p>\n<p><strong>settings.py<\/strong><\/p>\n<pre><code>...\n\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'crispy_forms',\n    'other',\n    'bootstrap4'\n]\n\nCRISPY_TEMPLATE_PACK = 'bootstrap4'\n\n...\n<\/code><\/pre>\n<p><strong>models.py<\/strong><\/p>\n<pre><code>from django.db import models\n\nclass Mine(models.Model):\n    name = models.CharField(max_length=100)\n    email = models.EmailField()\n<\/code><\/pre>\n<p><strong>forms.py<\/strong><\/p>\n<pre><code>from django import forms\nfrom .models import Mine\n\nclass MineForm(forms.ModelForm):\n    class Meta:\n        model = Mine\n        fields = ('name','email')\n<\/code><\/pre>\n<p><strong>views.py<\/strong><\/p>\n<pre><code>from django.shortcuts import render\nfrom .forms import *\n\ndef idx(request):\n    tform = MineForm()\n\n    return render(request,'test.html',{'aform': tform})\n<\/code><\/pre>\n<p><strong>test.html<\/strong><\/p>\n<pre><code>{% load bootstrap4 %}\n{% load crispy_forms_tags %}\n&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;meta charset=&quot;UTF-8&quot;&gt;\n    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;\n    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n    &lt;title&gt;TestThing&lt;\/title&gt;\n&lt;\/head&gt;\n&lt;body&gt;\n    &lt;form action=&quot;\/&quot;&gt;\n        {% csrf_token %}\n        {{ aform|crispy }}\n    &lt;\/form&gt;\n&lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n<p><strong>results of pip freeze<\/strong><\/p>\n<pre><code>asgiref==3.6.0\nbeautifulsoup4==4.11.2\nDjango==4.1.7\ndjango-bootstrap4==22.3\ndjango-crispy-forms==2.0\nsoupsieve==2.4\nsqlparse==0.4.3\ntzdata==2022.7\n<\/code><\/pre>\n<p><strong>error reported on debug page<\/strong><\/p>\n<pre><code>TemplateDoesNotExist at \/\nbootstrap4\/uni_form.html\n<\/code><\/pre>\n<p><em><strong>Template-loader postmortem<\/strong><\/em><\/p>\n<pre><code>Template-loader postmortem\nDjango tried loading these templates, in this order:\n\nUsing engine django:\n\ndjango.template.loaders.app_directories.Loader: C:\\ProjectDir\\.venv\\lib\\site-packages\\django\\contrib\\admin\\templates\\bootstrap4\\uni_form.html (Source does not exist)\ndjango.template.loaders.app_directories.Loader: C:\\ProjectDir\\.venv\\lib\\site-packages\\django\\contrib\\auth\\templates\\bootstrap4\\uni_form.html (Source does not exist)\ndjango.template.loaders.app_directories.Loader: C:\\ProjectDir\\other\\templates\\bootstrap4\\uni_form.html (Source does not exist)\ndjango.template.loaders.app_directories.Loader: C:\\ProjectDir\\.venv\\lib\\site-packages\\bootstrap4\\templates\\bootstrap4\\uni_form.html (Source does not exist)\n<\/code><\/pre>\n<p>It looks to me like Crispy can't see the templates which should have been installed. Or perhaps there's something else I'm supposed to download or create?<\/p>\n<p>I wanted to quickly tidy a form up in my Django project before moving on to more pressing matters, and hours later I still can't get Crispy Forms to function at all (it would have been quicker to sort this in other ways). It's clear I'm missing something, but what?<\/p>\n<p><strong>Other Weird and Wonderful things I've tried<\/strong><\/p>\n<p>Not all of these might be logical, but hey!<\/p>\n<ul>\n<li>deliberately putting the wrong string in <code>CRISPY_TEMPLATE_PACK<\/code> -- this results in an error suggesting I need to use <code>bootstrap3<\/code>, <code>bootstrap4<\/code>, or <code>uni_form<\/code>. Although repeating this experiment keeps the error reported above (with the misspelling)<\/li>\n<li>removing the <code>django-bootstrap4<\/code> module and loading from CDN (no difference)<\/li>\n<li>creating a blank HTML file at the path shown for the template, which just fails to render the form<\/li>\n<li>using <code>{% crispy aform %}<\/code> - same result<\/li>\n<\/ul>\n"}
{"0":"Title: How to fetch data server-side in the latest Next.js? Tried getStaticProps but it&#39;s not running and getting undefined.\nBody: <p>I am working on a Django Rest Framework with Next.js, and I am getting stuck with fetching data from the API. I have data in this url <code>http:\/\/127.0.0.1:8000\/api\/campaigns<\/code> and when I visit the url I see the data.<\/p>\n<p>The problem is when I fetch and console the data with Next.js, I get <code>undefined<\/code>. Also when I try mapping the data, I get the error:<\/p>\n<blockquote>\n<p>Unhandled Runtime Error<\/p>\n<p>Error: Cannot read properties of undefined (reading 'map')<\/p>\n<\/blockquote>\n<p>Here is my <code>Index.js<\/code> file where the data fetching is done:<\/p>\n<pre><code>import React from 'react'\n\nexport default function Index ({data}) {\n  console.log(data)\n  return (\n    &lt;div&gt;\n      &lt;main&gt;\n        &lt;h1&gt;Available Campaigns&lt;\/h1&gt;\n        {data.map((element) =&gt; &lt;div key={element.slug}&gt;\n          &lt;div&gt;\n            &lt;div&gt;\n              &lt;img src={element.logo} height={120} width={100} alt=&quot;image&quot; \/&gt;\n            &lt;\/div&gt;\n            &lt;div&gt;&lt;\/div&gt;\n          &lt;\/div&gt;\n\n        &lt;\/div&gt;)}\n      &lt;\/main&gt;\n    &lt;\/div&gt;\n  );\n}\n\nexport async function getStaticProps() {\n  const response = await fetch(&quot;http:\/\/127.0.0.1:8000\/api\/campaigns&quot;);\n  const data = await response.json();\n  return {\n    props: {\n      data: data\n    },\n  }\n}\n<\/code><\/pre>\n<p>Here is a screenshot of the data I am getting when I visit the URL:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4vU7y.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4vU7y.png\" alt=\"Image\" \/><\/a><\/p>\n<p>Here is the file structure for the Next.js app inside the front end:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MnfjC.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MnfjC.png\" alt=\"File Structure\" \/><\/a><\/p>\n<p>Also, note that I am using the latest version of Next.js. Any help will be highly appreciated. Thanks.<\/p>\n"}
{"0":"Title: Django admin showing a white box instead of toggle theme icon.\nBody: <p>As I open Django admin page, a wide white box appears instead of the theme icon (using Django 4.2.1).<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/dXqnL.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dXqnL.png\" alt=\"admin page as appears on production\" \/><\/a><\/p>\n<p>While testing on Docker container, everything seems ok.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zoDtk.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zoDtk.png\" alt=\"admin page while testing on Docker container\" \/><\/a><\/p>\n<p>I have been looking at the <a href=\"https:\/\/docs.djangoproject.com\/en\/4.1\/ref\/contrib\/admin\/#theming-support\" rel=\"noreferrer\">documentation<\/a> on overriding admin\/base.html, but I'm not sure this is the issue.<\/p>\n<p>Checking the log after deployment (on EC cloud), nothing comes to my attention.<\/p>\n<p>I am letting serve the static content by nginx (1.23).<\/p>\n<pre><code>python manage.py collectstatic --noinput\n<\/code><\/pre>\n<p>Overall, all static files are working properly on the rest of the site.<\/p>\n<p>I tried inspecting the element <code>&lt;button class=&quot;theme-toggle&quot;&gt;<\/code>. Nothing anomalous.<\/p>\n<p>Everything looks <em>normal<\/em> to me. Apart from this, production looks identical to the Docker container.<\/p>\n"}
{"0":"Title: How to safely and atomically decrement a counter with Django and PostgreSQL?.\nBody: <p>I've been reading up on PostgreSQL transaction isolation and how that relates to Django's <code>transaction.atomic()<\/code> (e.g. <a href=\"https:\/\/charemza.name\/blog\/posts\/django\/postgres\/transactions\/not-as-atomic-as-you-may-think\/\" rel=\"noreferrer\">this article<\/a>, <a href=\"https:\/\/www.postgresql.org\/docs\/15\/transaction-iso.html\" rel=\"noreferrer\">PostgreSQL docs<\/a>), but I'm far from fluent in this topic and I'm not sure I understand what I've read.<\/p>\n<p>We've got a PostgreSQL-backed Django app that involves quota objects. Simplified, it's just this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Quota(models.Model):\n    obj = models.OneToOneField(AnotherModel)\n    count = models.PositiveIntegerField()\n<\/code><\/pre>\n<p>An instance of this controls how many times a certain operation can be performed against the <code>obj<\/code> instance. <code>count<\/code> is initialized to a certain number, and will only ever decrement until it hits zero.<\/p>\n<p>Any number of processes\/threads can concurrently perform these operations. Basically, we need to atomically decrement (with UPDATE) the <code>count<\/code> of a single database row without deadlocking and without two processes\/threads ever e.g. starting with a <code>count<\/code> of 100 and both trying to decrement it to 99.<\/p>\n<p>My naive approach would be this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with transaction.atomic():\n    cursor = connection.cursor()\n    cursor.execute('SET TRANSACTION ISOLATION LEVEL SERIALIZABLE')\n    Quota.objects.filter(obj=instance).update(count=F('count')-1)\n<\/code><\/pre>\n<p>However, I'm not sure if this is subject to this issue, from the linked article:<\/p>\n<blockquote>\n<p>if at COMMIT the database cannot determine that the transaction could have been performed serially with respect to the read\/writes of other transactions, then it will fail with a django.db.DatabaseError. This can happen even if they updated different rows.<\/p>\n<\/blockquote>\n<p>All the processes\/threads performing operations against the same <code>obj<\/code> would be decrementing the same column of the same row, so... maybe? I don't actually know what's involved in PostgreSQL &quot;determin[ing] that the transaction could have been performed serially&quot;.<\/p>\n<p>An alternate approach could be:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with transaction.atomic():\n    Quota.objects.select_for_update().filter(obj=instance).update(count=F('count')-1)\n<\/code><\/pre>\n<p>This seems to do row-level locking, and my understanding is that the isolation level change isn't needed, but I don't know if this is sufficient for correct handling of concurrent operations.<\/p>\n<p>Is one of these approaches preferrable here, and are some modifications still necessary to guarantee atomicity and deadlock avoidance? We could use something like <code>python-redis-lock<\/code> to also prevent concurrent DB operations at the Django view level, but this feels like a more natural fit to do at the DB level.<\/p>\n"}
{"0":"Title: how to resolve django : ImportError: cannot import name &#39;parse_header&#39; from &#39;django.http.multipartparser&#39;.\nBody: <p>My application was running fine till few days back, but now all of a sudden i'm seeing this error and not sure what it means, please help.<\/p>\n<p>Error:<\/p>\n<pre><code>File &quot;\/myproj\/myapp\/urls.py&quot;, line 8, in &lt;module&gt;\nfrom rest_framework import routers\nFile &quot;\/usr\/local\/lib\/python3.8\/site-packages\/rest_framework\/routers.py&quot;, line 22, in &lt;module&gt;\nfrom rest_framework import views\nFile &quot;\/usr\/local\/lib\/python3.8\/site-packages\/rest_framework\/views.py&quot;, line 15, in &lt;module&gt;\nfrom rest_framework.request import Request\nFile &quot;\/usr\/local\/lib\/python3.8\/site-packages\/rest_framework\/request.py&quot;, line 17, in &lt;module&gt;\nfrom django.http.multipartparser import parse_header\nImportError: cannot import name 'parse_header' from 'django.http.multipartparser' (\/usr\/local\/lib\/python3.8\/site-packages\/django\/http\/multipartparser.py)\n<\/code><\/pre>\n<p>my line 8 of urls.py is:<\/p>\n<pre><code>from rest_framework import routers\n<\/code><\/pre>\n<p>and i could see the parse_header method in the multipartparser.py file PFA<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/c70Wy.png\" rel=\"noreferrer\">multipartparser file<\/a><\/p>\n"}
{"0":"Title: Django EmbeddedField raises ValidationError because of renamed field.\nBody: <p>I've got a Django application with <code>djongo<\/code> as a database driver. The models are:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Blog(models.Model):\n    _id = models.ObjectIdField()\n    name = models.CharField(max_length=100, db_column=&quot;Name&quot;)\n    tagline = models.TextField()\n\nclass Entry(models.Model):\n    _id = models.ObjectIdField()\n    blog = models.EmbeddedField(\n        model_container=Blog\n    )\n<\/code><\/pre>\n<p>When I run this application, I got an error:<\/p>\n<pre><code>File &quot;\\.venv\\lib\\site-packages\\djongo\\models\\fields.py&quot;, line 125, in _validate_container\n    raise ValidationError(\ndjango.core.exceptions.ValidationError: ['Field &quot;m.Blog.name&quot;  of model container:&quot;&lt;class \\'project.m.models.Blog\\'&gt;&quot; cannot be named as &quot;name&quot;, different from column name &quot;Name&quot;']\n<\/code><\/pre>\n<p>I want to keep the name of the field <code>name<\/code> in my model and database different because the database already exists, and I can't change it. The database uses camelCase for naming fields, whereas in the application, I want to use snake_case.<\/p>\n<p>How to avoid this error?<\/p>\n"}
{"0":"Title: django.db.utils.NotSupportedError: MySQL 8 or later is required (found 5.7.33). in Django.\nBody: <p>I have this error when performing migrations to my file command<\/p>\n<p>I tried this command<\/p>\n<pre><code>python manage.py makemigrations\n<\/code><\/pre>\n<p><strong>but Error insist<\/strong><\/p>\n<pre><code>django.db.utils.NotSupportedError: MySQL 8 or later is required (found 5.7.33).\n<\/code><\/pre>\n<p>Is there anyway to perform migration? or should I downgrade my python version to v.9?<\/p>\n<p><strong>python version<\/strong><\/p>\n<pre><code>python v.3.10\n<\/code><\/pre>\n"}
{"0":"Title: Microservices architecture with Django.\nBody: <p>I have some questions about creating microservices with Django.<\/p>\n<p>Let's say we have an online shop or a larger system with many database requests and users. I want to practice and simulate a simple microservice to learn something new.<\/p>\n<p>We want to create a microservices-based system with the following components:<\/p>\n<ol>\n<li>A Django-based microservice with its admin panel and full functionality (excluding DRF).<\/li>\n<li>One or more microservices with a React\/Angular frontend.<\/li>\n<li>Several additional microservices to separate functionalities.\nI'm unsure about the architecture. Let's assume we want to manage data using the Django admin panel.<\/li>\n<\/ol>\n<p>The simplest solution would be to add DRF to the first microservice and extend its functionality (REST app) - instead of creating different services (3.).<\/p>\n<ol>\n<li>But what if we want to separate functionality into different microservices?<\/li>\n<li>Should the microservices in point 3 be connected to the same database and treated as different Django projects (with DRF)?<\/li>\n<li>Can we use GoLang, FastAPI, or Java Spring for the third microservice? If yes, should all models be duplicated and registered in the first microservice?<\/li>\n<li>Alternatively, is there a better way to approach this?<\/li>\n<\/ol>\n<p>It would be great to hear your perspective and methods on how to proceed with this.<\/p>\n<p>Have a wonderful day!<\/p>\n"}
{"0":"Title: Django &quot;Detected change in ..., reloading&quot; Error in Docker.\nBody: <p>I'm having a problem which I don't understand, and therefore can't resolve.<\/p>\n<p>I have a Dockerised Django project, which I created using Cookiecutter Django months ago. Today, my development environment has started displaying the following error on every request:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jq1A9.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jq1A9.png\" alt=\"code of error\" \/><\/a><\/p>\n<p>I am not currently having this issue in production. I tried rolling back to commits that worked properly before (1 week old commits, for example), and I'm still getting this error.<\/p>\n<p>The reloading is causing connections to the database to close and therefore my project isn't working properly at all.<\/p>\n<p>Does anyone know what causes this, and how I might fix it? It feels like an issue with my Docker setup, but that hasn't changed in months, so I don't understand why that would change now.<\/p>\n<p>Many Thanks for any help anyone can offer!<\/p>\n"}
{"0":"Title: lib-sodium\/pynacl errors while building arm64-Python images for Python\/Django.\nBody: <p>Summary:\nI am trying to build an ARM64 image for my project to be able to run it faster locally on my macbook M1 (pro) machine, instead of using normal x64 images which run extremely slow (long startup time, long response time for local dev HTTP server, long test running times).<\/p>\n<p>I have the following docker file:<\/p>\n<pre><code>FROM arm64v8\/python\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    curl \\\n    libpq-dev \\\n    build-essential \\\n    libssl-dev \\\n    libffi-dev\n\n# Install Node.js for ARM64\nRUN curl -fsSL https:\/\/deb.nodesource.com\/setup_16.x | bash -\nRUN apt-get install -y nodejs\n\n# Set the working directory in the container\nWORKDIR \/app\n\n# Install Python dependencies\nRUN pip install --no-cache-dir cryptography\nRUN pip install --no-cache-dir pyNaCl==1.3.0\n\n# Copy the requirements.txt file to the container\nCOPY requirements.txt .\n\n# Install additional Python dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the Django project files to the container\nCOPY . .\n\n# Expose the Django development server port\nEXPOSE 8000\n\n# Start the Django development server\nCMD [&quot;python&quot;, &quot;manage.py&quot;, &quot;runserver&quot;, &quot;0.0.0.0:8000&quot;]\n<\/code><\/pre>\n<p><code>requirements.txt<\/code>:<\/p>\n<pre><code>autopep8==1.6.0\nkombu&gt;=5.0.0  # celery dependency\ncelery==5.0.0\ndj-database-url==0.5\ndjango==3.2.13\ndjango-bootstrap4==2.2.0\ndjango-cors-headers==3.4.0\ndjango-debug-toolbar==3.2.1\ndjango-phonenumber-field==4.0.0\ndjango-safedelete==0.5.6\ndjangorestframework==3.13.0\ndjangorestframework-xml==2.0.0\ndjango-model-utils==4.2.0\ngunicorn==20.0.4\nipdb==0.13.3\njedi==0.18.1  # ipython dependency\nipython==7.32.0\nipython-genutils==0.2.0\nnewrelic==7.16.0.178\npep8==1.7.1\npython-dateutil&gt;=2.8.0\npytz&gt;=2019.2\nredis==3.5.3\ndjango-redis==4.12.1\nrequests==2.27.1\nrequests-mock&gt;=1.6.0\nselenium==3.141.0\ntwilio==7.8.0\ndjango-filter==2.4.0\npsycopg2==2.9.3\ndjango-session-security==2.6.6\ndjango-axes==5.4.1\nbeautifulsoup4==4.9.1\ngit+https:\/\/github.com\/onitsoft\/uphold-sdk-python.git#egg=uphold\nisort==5.2.0\nfreezegun&gt;=0.3.1\nsuds-community&gt;=1.1.0\ndrf-extensions&gt;=0.5.0\nrequests-cache==0.5.2\nxmltodict==0.12\npython-bitcoinrpc==1.0\nurllib3==1.26.5\npillow==9.1.0\ngit+https:\/\/github.com\/onitsoft\/django-loginurl.git#egg=django-loginurl\ndjango-countries==7.3.2\ntornado==6.0.4 # flower dependency\nflower==0.9.5\ndjango-guardian==2.4.0\ndredd-hooks==0.2.0\ndjango-fsm==2.8.0\ngit+https:\/\/github.com\/onitsoft\/python-bittrex.git#egg=python-bittrex\ncached-property==1.5.1\nweb3==5.25.0\n# pycrypto==2.6.1\npycryptodome==3.14.1\ndjango-extensions==3.1.5\ndjango-oauth-toolkit==1.7.1\niptools==0.7.0\ndjango-otp==0.9.3\nqrcode==6.1\ngit+https:\/\/github.com\/onitsoft\/django-audit-log.git@django3-support\nrlp==1.2.0\ndjango-newsletter==0.9.1\ngit+https:\/\/github.com\/onitsoft\/py-stellar-base.git@2.10.0\ndjango-email-log==1.2.0\ndjango-nested-admin==3.4.0\n#bintrees==2.0.7\nsortedcontainers==2.2.2\ngit+https:\/\/github.com\/onitsoft\/OrderBook.git@5dbd18b4534ac4945b7e53315c65e1d49d9e340d#egg=orderbook\ndjango-picklefield===2.1.1\npdbpp==0.10.2\npyyaml==5.4.1\ngit+https:\/\/github.com\/onitsoft\/ripple-python\ndjango-constance==2.9.1\ndjango-admin-rangefilter==0.8.4\ntoml==0.10.1\nphonenumbers==8.12.7\ndjango-post-office==3.4.1\nslackclient==2.7.3\ndjango-intercom==0.1.3\ndjango-ipware==3.0.7\ndjango-enum-choices==2.1.3\ngit+https:\/\/github.com\/onitsoft\/monero-python.git@v0.9.3\nsimplejson==3.17.2\ndjango-polymorphic==3.1.0\nretrying==1.3.3\nccxt==3.0.51\ndjango-admin-multiple-choice-list-filter==0.1.1\ncelery-once==3.0.1\nbidict==0.21.2\nfireblocks-sdk==1.19.0\npycountry==20.7.3\ncbor==1.0.0\ngit+https:\/\/github.com\/onitsoft\/django-admin-comments.git\nlxml==4.9.1\nsupervisor==4.2.4\ndjango-admin-csvexport==1.11\nrsa==4.9\npydantic==1.10.2\nXlsxWriter==3.0.8\n<\/code><\/pre>\n<p>Traceback:\n<a href=\"https:\/\/pastebin.com\/1xtwdfXY\" rel=\"nofollow noreferrer\">https:\/\/pastebin.com\/1xtwdfXY<\/a> (too long to paste here)<\/p>\n<p>I have already tried everything you can find online, including:<\/p>\n<ul>\n<li>Installing lib-sodium via apt instead of via pip<\/li>\n<li>Installing version 1.3.0 of pynacl specifically using <code>pynacl==1.3.0<\/code><\/li>\n<li>Installing lib-sodium locally on the host machine (MacOs) via <code>brew install libsodium<\/code><\/li>\n<\/ul>\n<p>But sadly nothing helps. Sources:<\/p>\n<ul>\n<li><a href=\"https:\/\/github.com\/pyca\/pynacl\/issues\/654\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pyca\/pynacl\/issues\/654<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/pyca\/pynacl\/issues\/654#issuecomment-901266575\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pyca\/pynacl\/issues\/654#issuecomment-901266575<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/pyca\/pynacl\/issues\/430\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pyca\/pynacl\/issues\/430<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/jedisct1\/libsodium\/issues\/721\" rel=\"nofollow noreferrer\">https:\/\/github.com\/jedisct1\/libsodium\/issues\/721<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/65517524\/pynacl-building-problems\">PyNaCl building problems<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/jedisct1\/libsodium\/issues\/1302\" rel=\"nofollow noreferrer\">https:\/\/github.com\/jedisct1\/libsodium\/issues\/1302<\/a><\/li>\n<\/ul>\n"}
{"0":"Title: Django Allauth - ModuleNotFoundError: No module named &#39;allauth.account.middleware&#39; even when django-allauth is properly installed.\nBody: <p>&quot;ModuleNotFoundError: No module named 'allauth.account.middleware'&quot;<\/p>\n<p>I keep getting this error in my django project even when django-allauth is all installed and setup???<\/p>\n<p>I tried even reinstalling and changing my python to python3 but didn't change anything, can't figure out why all other imports are working but the MIDDLEWARE one...<\/p>\n<p>Help pls?<\/p>\n<p>settings.py:<\/p>\n<pre><code>&quot;&quot;&quot;\nDjango settings for youtube2blog2 project.\n\nGenerated by 'django-admin startproject' using Django 4.2.4.\n\nFor more information on this file, see\n\nFor the full list of settings and their values, see\n&quot;&quot;&quot;\n\nfrom pathlib import Path\nimport django\nimport os\nimport logging\nimport pyfiglet\n\nimport allauth\n\n# Build paths inside the project like this: BASE_DIR \/ 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n\n\n# Quick-start development settings - unsuitable for production\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'omegalul'\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# CUSTOM CODE\n\n# os.environ['FFMPEG_PATH'] = '\/third-party\/ffmpeg.exe'\n# os.environ['FFPROBE_PATH'] = '\/third-party\/ffplay.exe'\n\nOFFLINE_VERSION = False\n\ndef offline_version_setup(databases):\n    if (OFFLINE_VERSION):\n\n        # WRITE CODE TO REPLACE DATABASES DICT DATA FOR OFFLINE SETUP HERE\n\n        return True\n    return\n\nbanner_ascii_art = pyfiglet.figlet_format(&quot;CHRIST IS KING ENTERPRISES&quot;)\n\nlogger = logging.getLogger()\n\nlogger.setLevel(logging.DEBUG)\n\nprint(&quot;\\n - CURRENT DJANGO VERSION: &quot; + str(django.get_version()))\n\nprint(&quot;\\n - settings.py: Current logger level is &quot; + str(logger.getEffectiveLevel()))\nlogger.debug('settings.py: Logger is working.\\n\\n')\n\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nMEDIA_URL = '\/media\/'\n\nAUTHENTICATION_BACKENDS = [\n    \n    # Needed to login by username in Django admin, regardless of `allauth`\n    'django.contrib.auth.backends.ModelBackend',\n\n    # `allauth` specific authentication methods, such as login by email\n    'allauth.account.auth_backends.AuthenticationBackend',\n    \n]\n\n'''\n\nNEEDED SETUP FOR SOCIAL AUTH\n\nREQUIRES DEVELOPER CREDENTIALS\n\nON PAUSE UNTIL MVP IS DONE\n\n# Provider specific settings\nSOCIALACCOUNT_PROVIDERS = {\n    'google': {\n        # For each OAuth based provider, either add a ``SocialApp``\n        # (``socialaccount`` app) containing the required client\n        # credentials, or list them here:\n        'APP': {\n            'client_id': '123',\n            'secret': '456',\n            'key': ''\n        }\n    }\n    'apple': {\n        \n    }\n    'discord' {\n\n    }\n}\n'''\nLOGIN_REDIRECT_URL = 'dashboard'\n\n#\n\n# Application definition\n\nINSTALLED_APPS = [\n\n    # My Apps\n    'yt2b2',\n    'home',\n    'dashboard',\n\n    # Django Apps\n\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n\n    # Downloaded Apps\n    'rest_framework',\n    'embed_video',\n    'allauth',\n    'allauth.account',\n    'allauth.socialaccount',\n    #'allauth.socialaccount.providers.google',\n    #'allauth.socialaccount.providers.apple',\n    #'allauth.socialaccount.providers.discord',\n]\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n\n    # Downloaded Middleware\n    'allauth.account.middleware.AccountMiddleware',\n]\n\nROOT_URLCONF = 'youtube2blog2.urls'\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = 'youtube2blog2.wsgi.application'\n\n\n# Database\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR \/ 'db.sqlite3', # &lt;--------- OFFLINE VERSION\n\n        # Consider masking these secret variables using a .env file to beef up your Django app's security. Besides, Vercel allows you to list your environment variables during deployment.\n        \n        #'URL' : 'postgresql:\/\/postgres:oibkk5LL9sI5dzY5PAnj@containers-us-west-128.railway.app:5968\/railway',\n        #'NAME' : 'railway',\n        #'USER' : 'postgres',\n        #'PASSWORD' : 'oibkk5LL9sI5dzY5PAnj',\n        #'HOST' : 'containers-us-west-128.railway.app',\n        #'PORT' : '5968'\n    }\n}\n\n# Password validation\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n    },\n]\n\n\n# Internationalization\n\nLANGUAGE_CODE = 'en-us'\n\nTIME_ZONE = 'UTC'\n\nUSE_I18N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n\nSTATIC_URL = '\/static\/' # the path in url\n\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, &quot;static&quot;),\n]\n\n# Default primary key field type\n\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\n\n<\/code><\/pre>\n<p>Tried changing to python3, reinstalling django-allauth through pip, other stackoverflow solutions, shifting through allauth docs... Nothing worked until now<\/p>\n<p>Update: removed https links because of spam filter<\/p>\n<p>Error location:<\/p>\n<pre><code>MIDDLEWARE = [\n'django.middleware.security.SecurityMiddleware',\n'django.contrib.sessions.middleware.SessionMiddleware',\n'django.middleware.common.CommonMiddleware',\n'django.middleware.csrf.CsrfViewMiddleware',\n'django.contrib.auth.middleware.AuthenticationMiddleware',\n'django.contrib.messages.middleware.MessageMiddleware',\n'django.middleware.clickjacking.XFrameOptionsMiddleware',\n\n# Downloaded Middleware\n'allauth.account.middleware.AccountMiddleware',\n<\/code><\/pre>\n<p>]<\/p>\n"}
{"0":"Title: Wagtail 4.1, &#39;NoneType&#39; object has no attribute &#39;_inc_path&#39;.\nBody: <p>I am trying to integrate wagtail into an existing django project, but I am getting the above error when I add a child page.<\/p>\n<p>In my settings I have followed the instructions so:<\/p>\n<pre><code>INSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django.contrib.humanize',\n    'whitenoise.runserver_nostatic',\n    'home',\n    'news',\n    'wagtail.contrib.forms',\n    'wagtail.contrib.redirects',\n    'wagtail.embeds',\n    'wagtail.sites',\n    'wagtail.users',\n    'wagtail.snippets',\n    'wagtail.documents',\n    'wagtail.images',\n    'wagtail.search',\n    'wagtail.admin',\n    'wagtail',\n    'modelcluster',\n]\n\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django_permissions_policy.PermissionsPolicyMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'corsheaders.middleware.CorsMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'wagtail.contrib.redirects.middleware.RedirectMiddleware',\n]\n<\/code><\/pre>\n<p>my project urls:<\/p>\n<pre><code>from django.urls import include, path\nfrom django.conf import settings\nfrom django.conf.urls.static import static\nfrom django.urls import reverse\nfrom wagtail.admin import urls as wagtailadmin_urls\nfrom wagtail import urls as wagtail_urls\nfrom wagtail.documents import urls as wagtaildocs_urls\n\n\nurlpatterns = [\n    path('', include('home.urls')),\n    path('news\/', include('news.urls')),\n    path('cms\/', include(wagtailadmin_urls)),\n    path('documents\/', include(wagtaildocs_urls)),\n    path('news\/', include(wagtail_urls)),\n] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n<\/code><\/pre>\n<p>my news urls:<\/p>\n<pre><code>from django.urls import path\nfrom .views import news_article_detail\n\nurlpatterns = [\n    path('news\/&lt;int:pk&gt;\/', news_article_detail, name='news_article_detail'),\n]\n<\/code><\/pre>\n<p>in my news view:<\/p>\n<pre><code>from django.shortcuts import render\nfrom .models import NewsArticlePage\n#import pdb; pdb.set_trace()\n\ndef news_article_detail(request, pk):\n    news_article = NewsArticlePage.objects.get(pk=pk)\n    return render(request, 'news\/news_page.html', {'news_article': news_article})\n<\/code><\/pre>\n<p>and my model:<\/p>\n<pre><code>from django.db import models\nfrom wagtail.core.models import Page\nfrom wagtail.admin.edit_handlers import FieldPanel\nfrom wagtail.core.fields import RichTextField\n\nclass NewsArticlePage(Page):\n    article_body = RichTextField(blank=True)\n\n    content_panels = Page.content_panels + [\n        FieldPanel('article_body'),\n    ]\n    \n    template = &quot;news\/news_page.html&quot;\n<\/code><\/pre>\n<p>and in my template:<\/p>\n<pre><code>{% extends &quot;base.html&quot; %}\n\n{% block content %}\n&lt;h1&gt;{{ page.title }}&lt;\/h1&gt;\n{{ page.article_body|richtext }}\n{% endblock %}\n<\/code><\/pre>\n<p>I have also added the root page, made sure that the url's are pointing to the correct place, made migrations &amp; migrated but still I get the same error. So when I go to localhost\/cms in the backend I have a page set up, when I go to add a child page I get the error, I tried the python manage.py fixtree but I still get the error, here is the stack trace:<\/p>\n<p>nvironment:<\/p>\n<p>Request Method: POST\nRequest URL: <a href=\"http:\/\/127.0.0.1:7000\/cms\/pages\/add\/news\/newsarticlepage\/2\/\" rel=\"noreferrer\">http:\/\/127.0.0.1:7000\/cms\/pages\/add\/news\/newsarticlepage\/2\/<\/a><\/p>\n<pre><code>Django Version: 3.2.4\nPython Version: 3.11.1\nInstalled Applications:\n['django.contrib.admin',\n 'django.contrib.auth',\n 'django.contrib.contenttypes',\n 'django.contrib.sessions',\n 'django.contrib.messages',\n 'django.contrib.staticfiles',\n 'django.contrib.humanize',\n 'whitenoise.runserver_nostatic',\n 'accounts',\n 'compressor',\n 'corsheaders',\n 'home',\n 'news',\n 'taggit',\n 'widget_tweaks',\n 'sass_processor',\n 'wagtail.contrib.forms',\n 'wagtail.contrib.redirects',\n 'wagtail.embeds',\n 'wagtail.sites',\n 'wagtail.users',\n 'wagtail.snippets',\n 'wagtail.documents',\n 'wagtail.images',\n 'wagtail.search',\n 'wagtail.admin',\n 'wagtail',\n 'modelcluster']\nInstalled Middleware:\n['django.middleware.security.SecurityMiddleware',\n 'django_permissions_policy.PermissionsPolicyMiddleware',\n 'django.contrib.sessions.middleware.SessionMiddleware',\n 'django.middleware.common.CommonMiddleware',\n 'corsheaders.middleware.CorsMiddleware',\n 'django.middleware.csrf.CsrfViewMiddleware',\n 'django.contrib.auth.middleware.AuthenticationMiddleware',\n 'django.contrib.messages.middleware.MessageMiddleware',\n 'django.middleware.clickjacking.XFrameOptionsMiddleware',\n 'wagtail.contrib.redirects.middleware.RedirectMiddleware']\n\n\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\django\\core\\handlers\\exception.py&quot;, line 47, in inner\n    response = get_response(request)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\django\\core\\handlers\\base.py&quot;, line 181, in _get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\django\\views\\decorators\\cache.py&quot;, line 44, in _wrapped_view_func\n    response = view_func(request, *args, **kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\urls\\__init__.py&quot;, line 170, in wrapper\n    return view_func(request, *args, **kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\auth.py&quot;, line 182, in decorated_view\n    response = view_func(request, *args, **kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\django\\views\\generic\\base.py&quot;, line 70, in view\n    return self.dispatch(request, *args, **kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\views\\pages\\create.py&quot;, line 119, in dispatch\n    return super().dispatch(request)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\django\\views\\generic\\base.py&quot;, line 98, in dispatch\n    return handler(request, *args, **kwargs)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\views\\pages\\create.py&quot;, line 132, in post\n    return self.form_valid(self.form)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\views\\pages\\create.py&quot;, line 148, in form_valid\n    return self.save_action()\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\wagtail\\admin\\views\\pages\\create.py&quot;, line 170, in save_action\n    self.parent_page.add_child(instance=self.page)\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\treebeard\\mp_tree.py&quot;, line 1089, in add_child\n    return MP_AddChildHandler(self, **kwargs).process()\n  File &quot;C:\\Users\\sesa301575\\sites\\Django.Azure\\venv\\Lib\\site-packages\\treebeard\\mp_tree.py&quot;, line 383, in process\n    newobj.path = self.node.get_last_child()._inc_path()\n\nException Type: AttributeError at \/cms\/pages\/add\/news\/newsarticlepage\/2\/\nException Value: 'NoneType' object has no attribute '_inc_path'\n \n<\/code><\/pre>\n"}
{"0":"Title: dj_rest_auth (jwt) refresh token is empty when login - django rest framework.\nBody: <p>im having a trouble with dj_rest_auth jwt package. when i signup for a new account it gives me both access token and refresh token in response, but when i try to login with credentials, all i get is access token, and refresh token is entirely empty!\ni configured the code as described in the documentation and the the tutorial that im following.\nAny idea about this problem? please let me know.<\/p>\n<p>UPDATE: i just found that refresh token has been set correctly in the response header, but i cant figure out why its not in the response body and its shown empty?!<\/p>\n<p>Settings.py<\/p>\n<pre><code>INSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django.contrib.sites',\n\n    'rest_framework',\n    'rest_framework.authtoken',\n    'allauth',\n    'allauth.account',\n    'allauth.socialaccount',\n    'dj_rest_auth',\n    'dj_rest_auth.registration',\n\n    'accounts.apps.AccountsConfig',\n]\n\nREST_FRAMEWORK = {\n    'DEFAULT_PERMISSION_CLASSES': [\n        'accounts.permissions.IsStaffOrReadOnly',\n    ],\n    'DEFAULT_AUTHENTICATION_CLASSES': [\n        'dj_rest_auth.jwt_auth.JWTCookieAuthentication',\n    ],\n}\n\nSITE_ID = 1\n\nREST_AUTH = {\n    'USE_JWT': True,\n    'JWT_AUTH_COOKIE': 'access',\n    'JWT_AUTH_REFRESH_COOKIE': 'refresh',\n}\n<\/code><\/pre>\n<p>Response:<\/p>\n<pre><code>{\n    &quot;access_token&quot;: &quot;eyJhbGciOiJ.....&quot;,\n    &quot;refresh_token&quot;: &quot;&quot;,\n    &quot;user&quot;: {\n        &quot;pk&quot;: 2,\n        &quot;username&quot;: &quot;test_user_0&quot;,\n        &quot;email&quot;: &quot;test0@mysite.co&quot;,\n        &quot;first_name&quot;: &quot;&quot;,\n        &quot;last_name&quot;: &quot;&quot;\n    }\n}\n<\/code><\/pre>\n"}
{"0":"Title: &quot;error: --plat-name must be one of (&#39;win32&#39;, &#39;win-amd64&#39;, &#39;win-arm32&#39;, &#39;win-arm64&#39;)&quot; with pip on venv while installing psycopg2.\nBody: <p>pip version: 23.1.1<\/p>\n<p>Python version: 3.9.11<\/p>\n<p>OS: Windows 11<\/p>\n<p>My python project is created and env is used as virtual environment. psycopg2 fails to install.\nAccording to log, &quot;Failed building wheel for psycopg2&quot; and it also shows that the &quot;The license_file parameter is deprecated&quot;.<\/p>\n<p>I have not found any solutions for my platform even though the solution exists for other platforms.\nBoth wheel and setuptools are latest.<\/p>\n<p><code>pip install psycopg2-binary<\/code> also does not work.<\/p>\n<p>The full error is below:<\/p>\n<pre><code>\n(env) PS C:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\&gt; pip install psycopg2\nCollecting psycopg2\nUsing cached psycopg2-2.9.6.tar.gz (383 kB)\nPreparing metadata (setup.py) ... done\nBuilding wheels for collected packages: psycopg2\nBuilding wheel for psycopg2 (setup.py) ... error\nerror: subprocess-exited-with-error\n\n\u00d7 python setup.py bdist_wheel did not run successfully.\n\u2502 exit code: 1\n\u2570\u2500\\&gt; \\[34 lines of output\\]\nC:\\\\Aavash files\\\\COMP206\\\\Project\\\\Movie4AllMoods\\\\env\\\\lib\\\\python3.9\\\\site-packages\\\\setuptools\\\\config\\\\setupcfg.py:293: \\_DeprecatedConfig: Deprecated config in `setup.cfg`\n!!\n\n              ********************************************************************************\n              The license_file parameter is deprecated, use license_files instead.\n      \n              By 2023-Oct-30, you need to update your project and remove deprecated calls\n              or your builds will no longer be supported.\n      \n              See https:\/\/setuptools.pypa.io\/en\/latest\/https:\/\/setuptools.pypa.io\/en\/latest\/userguide\/declarative_config.html for details.\n              ********************************************************************************\n      \n      !!\n        parsed = self.parsers.get(option_name, lambda x: x)(value)\n      running bdist_wheel\n      running build\n      running build_py\n      creating build\n      creating build\\lib.mingw_x86_64-cpython-39\n      creating build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\errorcodes.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\errors.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\extensions.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\extras.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\pool.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\sql.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\tz.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\_ipaddress.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\_json.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\_range.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      copying lib\\__init__.py -&gt; build\\lib.mingw_x86_64-cpython-39\\psycopg2\n      running build_ext\n      building 'psycopg2._psycopg' extension\n      error: --plat-name must be one of ('win32', 'win-amd64', 'win-arm32', 'win-arm64')\n      [end of output]\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\nERROR: Failed building wheel for psycopg2\nRunning setup.py clean for psycopg2\nFailed to build psycopg2\nERROR: Could not build wheels for psycopg2, which is required to install pyproject.toml-based projects\n<\/code><\/pre>\n<pre><code><\/code><\/pre>\n<p>I have tried updating pip, wheel and setup tools but that didn't work. Everything else I found were linux commands that I have been unable to run. It installed fine in global but shows errors in my virtual environment. I have tried everything but nothing seems to work.<\/p>\n"}
{"0":"Title: How does Celery worker run the code defined elsewhere in a task?.\nBody: <p>I tried reading official documentation as well as other SO threads, but it is still not clear how Celery works.<\/p>\n<p>From what I understand:<\/p>\n<ol>\n<li><strong>Django app<\/strong>: Celery is installed in Django (or any app) where <code>@shared_task<\/code> decorator function defines the work to be performed.<\/li>\n<li><strong>Message broker<\/strong>: A message broker gets this task from 1. and queues it.<\/li>\n<li><strong>Celery Worker<\/strong>: A completely separate Celery worker picks up the task and runs it. This worker can be in a completely different machine even, so long as it has access to the message broker.<\/li>\n<\/ol>\n<p>So, then the burning question is:<\/p>\n<p><strong>How does the Celery worker get the code defined in @shared_task to run the task?<\/strong><\/p>\n<p>Basically, how does 3. get what's defined in 1. if they are only connected using a message broker? Is the python code stored in the message broker as string? What is the data structure of the message broker item\/record?<\/p>\n"}
{"0":"Title: Dokku: how to change heroku stack to heroku-20 or heroku-22 (from heroku-18).\nBody: <p>I have been working on a Django (Python) project using Dokku (thus Heroku) for deployments. Up until today, all deployments worked just fine, but since this morning, I get this error message:<\/p>\n<p><em>Requested runtime 'python-3.10.12' is not available for this stack (heroku-18).<\/em><\/p>\n<p>I know that python-3.10.12 is available on heroku-18 so I assume I (finally) have to change stack since heroku-18 is deprecated.<\/p>\n<p>I have tried using this command on Dokku:<\/p>\n<p>dokku buildpacks:add --index 1 {APP-NAME} <a href=\"https:\/\/github.com\/heroku\/heroku-buildpack-python.git\" rel=\"nofollow noreferrer\">https:\/\/github.com\/heroku\/heroku-buildpack-python.git<\/a>,<\/p>\n<p>but it doesn't solve my problem (heroku-18 is still being used).<\/p>\n<p>Any help would be greatly appreciated<\/p>\n"}
{"0":"Title: How to use the OpenAI stream=true property with a Django Rest Framework response, and still save the content returned?.\nBody: <p>I'm trying to use the stream=true property as follows.<\/p>\n<pre><code>completion = openai.Completion.create(\n            model=&quot;text-davinci-003&quot;,\n            prompt=&quot;Write me a story about dogs.&quot;,\n            temperature=0.7,\n            max_tokens=MAX_TOKENS,\n            frequency_penalty=1.0,\n            presence_penalty=1.0,\n            stream=True,\n        )\n<\/code><\/pre>\n<p>Unfortunately, I don't know what to do from here to return it to my React frontend. Typically, I've used standard response objects, setting a status and the serializer.data as the data. From my readings online, it seems I have to use the <code>StreamingHttpResponse<\/code>, but I'm not sure how to integrate that with the iterator object of <code>completion<\/code>, and actually save the outputted data once it is done streaming, as the view will end after returning the iterator to the endpoint. Any help?<\/p>\n"}
{"0":"Title: Too many db connections (django 4.x \/ ASGI).\nBody: <p>I have deployed a django app (on ASGI using uvicorn) and getting a lot of  <code>OperationalError FATAL: sorry, too many clients already<\/code><\/p>\n<p>It seems that this is a known <a href=\"https:\/\/code.djangoproject.com\/ticket\/33497\" rel=\"noreferrer\">issue #33497<\/a> for django 4.x and ASGI, but I cant find anything on it (other than acknowledging it) so far<\/p>\n<p>Is there some way around this, or should I switch to WSGI (or downgrade to 3.2)?<\/p>\n<p>It seems to me that this is a blocking issue for using to ASGI altogether. Shouldn't it be better documented? (unless I missed it)<\/p>\n"}
{"0":"Title: How a child serializer can access a respective field value from its parent serializer initalized with many=True?.\nBody: <p>In case we want to initialize the parent serializer with <code>many=True<\/code>, then how can the child serializer can access a respective field value from its parent serializer?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class ChildSerializer(serializers.Serializer):\n    field1 = serializers.CharField()\n\n    def validate(self, data):\n        # How to get the value of batch_key from the parent serializer (here self.batch_key)?\n        if not self.batch_key == data['field1']:\n            raise serializers.ValidationError('invalid field1')\n        return data\n\n\nclass ParentSerializer(serializers.Serializer):\n    child = ChildSerializer(many=True)\n    batch_key = serializers.CharField()\n\n\nclass MyAPIView(APIView):\n\n    def post(self, request):\n        serializer = ParentSerializer(data=request.data, many=True)\n        serializer.is_valid(raise_exception=True)\n        return\n<\/code><\/pre>\n<p>request data is as follows:<\/p>\n<pre><code>[\n   {\n      &quot;batch_key&quot;:&quot;batch_key_value_1&quot;,\n      &quot;child&quot;:[\n         {\n            &quot;field1&quot;:&quot;value1&quot;\n         },\n         {\n            &quot;field1&quot;:&quot;value2&quot;\n         },\n         {\n            &quot;field1&quot;:&quot;value3&quot;\n         }\n      ]\n   },\n   {\n      &quot;batch_key&quot;:&quot;batch_key_value_2&quot;,\n      &quot;child&quot;:[\n         {\n            &quot;field1&quot;:&quot;value4&quot;\n         },\n         {\n            &quot;field1&quot;:&quot;value5&quot;\n         },\n         {\n            &quot;field1&quot;:&quot;value6&quot;\n         }\n      ]\n   }\n]\n<\/code><\/pre>\n"}
{"0":"Title: Error &quot;&#39;DataFrame&#39; object has no attribute &#39;append&#39;&quot;.\nBody: <p>I am trying to append a dictionary to a DataFrame object, but I get the following error:<\/p>\n<blockquote>\n<p>AttributeError: 'DataFrame' object has no attribute 'append'<\/p>\n<\/blockquote>\n<p>As far as I know, DataFrame does have the method &quot;append&quot;.<\/p>\n<p>Code snippet:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame(df).append(new_row, ignore_index=True)\n<\/code><\/pre>\n<p>I was expecting the dictionary <code>new_row<\/code> to be added as a new row.<\/p>\n<p>How can I fix it?<\/p>\n"}
{"0":"Title: read_sql_query() throws &quot;&#39;OptionEngine&#39; object has no attribute &#39;execute&#39;&quot; with SQLAlchemy 2.0.0.\nBody: <p>First of all, I'm a totally new guys in the dev world\nI'm currently taking courses in AI \/ Data Science and one of my work is to use a SQL Database to make prediction using Prophet, then use these predition to make a PowerBI\nBut currently, I'm stuck with the Python code, I'm not a developer initially, so I have no clue where the problem is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sqlalchemy\nfrom sqlalchemy import create_engine\nimport pandas as pd\nfrom prophet import Prophet\nimport pymysql\n\n\nengine = create_engine(&quot;mysql+pymysql:\/\/root:Password@localhost:3306\/data&quot;)\nquery = &quot;SELECT Cle_Produit, Date_Facturation, SUM(Quantite) AS Total_Quantite FROM ventes GROUP BY         Cle_Produit, Date_Facturation&quot;\ndf = pd.read_sql_query(query, engine)\n\ndf = df.pivot(index='Date_Facturation', columns='Cle_Produit', values='Total_Quantite')\ndf = df.reset_index()\ndf.rename(columns={'Date_Facturation': 'ds', 'Total_Quantite': 'y'}, inplace=True)\n\n\nm = Prophet()\nm.fit(df)\nfuture = m.make_future_dataframe(periods=365)\nforecast = m.predict(future)\n\nforecast[['ds', 'yhat']].to_csv('forecast.csv', index=False)\n<\/code><\/pre>\n<p>It returns me this message:<\/p>\n<blockquote>\n<p>Importing plotly failed. Interactive plots will not work.\nTraceback (most recent call last):\nFile &quot;f:\\Backup\\Cours\\Cours\\Explo Data\\app3.py&quot;, line 9, in \ndf = pd.read_sql_query(query, engine)\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 397, in    read_sql_query\nreturn pandas_sql.read_query(\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 1560, in read_query\nresult = self.execute(*args)\nFile &quot;F:\\Programmes\\Anaconda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\sql.py&quot;,\nline 1405, in execute\nreturn self.connectable.execution_options().execute(*args, **kwargs)\nAttributeError: 'OptionEngine' object has no attribute 'execute'<\/p>\n<\/blockquote>\n<p>Please, can somebody help me?<\/p>\n<p>I want this python script to create a csv file with the prediction from prophet.\nI want Prophet to use the table ventes from the DB data, and it should use the column <code>Cle_Produit<\/code>, <code>Quantite<\/code> and <code>Date_Facturation<\/code><\/p>\n"}
{"0":"Title: ModuleNotFoundError: No module named &#39;pandas.core.indexes.numeric&#39; using Metaflow.\nBody: <p>I used Metaflow to load a Dataframe. It was successfully unpickled from the artifact store, but when I try to view its index using <code>df.index<\/code>, I get an error that says <code>ModuleNotFoundError: No module named 'pandas.core.indexes.numeric'<\/code>. Why?<\/p>\n<p>I've looked at other answers with similar error messages <a href=\"https:\/\/stackoverflow.com\/questions\/51285798\">here<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/37371451\">here<\/a>, which say that this is caused by trying to unpickle a dataframe with older versions of Pandas. However, my error is slightly different, and it is not fixed by upgrading Pandas (<code>pip install pandas -U<\/code>).<\/p>\n"}
{"0":"Title: &#39;XlsxWriter&#39; object has no attribute &#39;save&#39;. Did you mean: &#39;_save&#39;?.\nBody: <p>I was trying the following code that I found.<\/p>\n<pre><code>import pandas as pd\nimport xlsxwriter\ndata = {'Name': ['John', 'Jane', 'Adam'], 'Age': [25, 30, 35], 'Gender': ['M', 'F', 'M']}\ndf = pd.DataFrame(data)\n\nwriter = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\ndf.to_excel(writer, sheet_name='Sheet1')\n\nworkbook = writer.book\nworksheet = writer.sheets['Sheet1']\n\n# Example: Adding a chart\nchart = workbook.add_chart({'type': 'line'})\nchart.add_series({'values': '=Sheet1.$B$2:$B$4'})\nworksheet.insert_chart('D2', chart)\nwriter.save()\n<\/code><\/pre>\n<p>But I get the following error:<\/p>\n<pre><code>writer.save()\n    ^^^^^^^^^^^\nAttributeError: 'XlsxWriter' object has no attribute 'save'. Did you mean: '_save'?\n<\/code><\/pre>\n<p>Does anyone know how to solve it?\nThanks in advance!\nGiuseppe<\/p>\n<p>Trying to save data from a dataframe in excel file by using pandas<\/p>\n"}
{"0":"Title: AttributeError: &#39;OptionEngine&#39; object has no attribute &#39;execute&#39;.\nBody: <p>SQLAlchemy v2.0.0 works in a different way - they have changed some of the api.<\/p>\n<p>Following investigation I found a solution.\nMy code was simply:<\/p>\n<pre><code>s_settings_df = pd.read_sql_query(query, engine_cloud)\n<\/code><\/pre>\n<p>The error like the title, &quot;AttributeError: 'OptionEngine' object has no attribute 'execute'&quot;<\/p>\n<p>I will answer my own post below.<\/p>\n<p>I tried using various versions but did not like the idea of getting locked with historic components.<\/p>\n"}
{"0":"Title: Databricks: Issue while creating spark data frame from pandas.\nBody: <p>I have a pandas data frame which I want to convert into spark data frame. Usually, I use the below code to create spark data frame from pandas but all of sudden I started to get the below error, I am aware that pandas has removed iteritems() but my current pandas version is 2.0.0 and also I tried to install lesser version and tried to created spark df but I still get the same error. The error invokes inside the spark function. What is the solution for this? which pandas version should I install in order to create spark df. I also tried to change the runtime of cluster databricks and tried re running but I still get the same error.<\/p>\n<pre><code>import pandas as pd\nspark.createDataFrame(pd.DataFrame({'i':[1,2,3],'j':[1,2,3]}))\n\nerror:-\nUserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  'DataFrame' object has no attribute 'iteritems'\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\nAttributeError: 'DataFrame' object has no attribute 'iteritems'\n<\/code><\/pre>\n"}
{"0":"Title: AttributeError: &#39;str&#39; object has no attribute &#39;_execute_on_connection&#39;.\nBody: <p>I have a problem with following code:<\/p>\n<pre><code>from pandasql import sqldf\nimport pandas as pd\n\ndf = pd.DataFrame({'column1': [1, 2, 3], 'column2': [4, 5, 6]})\n\nquery = &quot;SELECT * FROM df WHERE column1 &gt; 1&quot;\n\nnew_dataframe = sqldf(query)\n\nprint(new_dataframe)\n<\/code><\/pre>\n<p>When I submit, I have this error:<\/p>\n<pre><code>Traceback (most recent call last):\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1410 in execute\n    meth = statement._execute_on_connection\n\nAttributeError: 'str' object has no attribute '_execute_on_connection'\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\pkgs\\spyder_kernels\\py3compat.py:356 in compat_exec\n    exec(code, globals, locals)\n\n  File c:\\users\\yv663dz\\downloads\\untitled1.py:18\n    new_dataframe = sqldf(query)\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\pandasql\\sqldf.py:156 in sqldf\n    return PandaSQL(db_uri)(query, env)\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\pandasql\\sqldf.py:61 in __call__\n    result = read_sql(query, conn)\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\pandas\\io\\sql.py:592 in read_sql\n    return pandas_sql.read_query(\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\pandas\\io\\sql.py:1557 in read_query\n    result = self.execute(*args)\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\pandas\\io\\sql.py:1402 in execute\n    return self.connectable.execution_options().execute(*args, **kwargs)\n\n  File ~\\AppData\\Local\\Programs\\Spyder\\Python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1412 in execute\n    raise exc.ObjectNotExecutableError(statement) from err\n\nObjectNotExecutableError: Not an executable object: 'SELECT * FROM df WHERE column1 &gt; 1'\n<\/code><\/pre>\n<p>I installed the latest versions of pandas, pandasql and sqlalchemy and I use Spyder as IDE. Could someone help me please?<\/p>\n"}
{"0":"Title: df to table throw error TypeError: __init__() got multiple values for argument &#39;schema&#39;.\nBody: <p>I have dataframe in pandas :- purchase_df. I want to convert it to sql table so I can perform sql query in pandas. I tried this method<\/p>\n<pre><code>purchase_df.to_sql('purchase_df', con=engine, if_exists='replace', index=False)\n<\/code><\/pre>\n<p>It throw an error<\/p>\n<pre><code>TypeError: __init__() got multiple values for argument 'schema'\n<\/code><\/pre>\n<p>I have dataframe name purchase_df and I need to perform sql query on it. I need to perform sql query on this dataframe like this ....engine.execute('''select * from purchase_df where condition'''). For this I need to convert dataframe into sql table as in our server pandas_sql is not installed only sql alchemy is installed.<\/p>\n<p>I ran this code in pycharm locally and it work perfectly fine but when i tried this in databrick notebook it is showing an error. Even though week ago it was running fine in databrick notebook too. Help me to fix this.<\/p>\n<p>note:- pandas version '1.3.4'\nName: SQLAlchemy\nVersion: 2.0.0<\/p>\n"}
{"0":"Title: Different behavior of apply(str) and astype(str) for datetime64[ns] pandas columns.\nBody: <p>I'm working with datetime information in pandas and wanted to convert a bunch of <code>datetime64[ns]<\/code> columns to <code>str<\/code>. I noticed a different behavior from the two approaches that I expected to yield the same result.<\/p>\n<p>Here's a <a href=\"https:\/\/stackoverflow.com\/help\/minimal-reproducible-example\">MCVE<\/a>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\n\n# Create a dataframe with dates according to ISO8601\ndf = pd.DataFrame({&quot;dt_column&quot;: [&quot;2023-01-01&quot;, &quot;2023-01-02&quot;, &quot;2023-01-02&quot;]})\n\n# Convert the strings to datetimes\n# (I expect the time portion to be 00:00:00)\ndf[&quot;dt_column&quot;] = pd.to_datetime(df[&quot;dt_column&quot;])\n\ndf[&quot;str_from_astype&quot;] = df[&quot;dt_column&quot;].astype(str)\ndf[&quot;str_from_apply&quot;] = df[&quot;dt_column&quot;].apply(str)\n\nprint(df)\nprint()\nprint(&quot;Datatypes of the dataframe&quot;)\nprint(df.dtypes)\n<\/code><\/pre>\n<p><strong>Output<\/strong><\/p>\n<pre><code>   dt_column str_from_astype       str_from_apply\n0 2023-01-01      2023-01-01  2023-01-01 00:00:00\n1 2023-01-02      2023-01-02  2023-01-02 00:00:00\n2 2023-01-02      2023-01-02  2023-01-02 00:00:00\n\nDatatypes of the dataframe\ndt_column          datetime64[ns]\nstr_from_astype            object\nstr_from_apply             object\ndtype: object\n<\/code><\/pre>\n<p>If I use <code>.astype(str)<\/code> the time information is lost and when I use <code>.apply(str)<\/code> the time information is retained (or inferred).<\/p>\n<p>Why is that?<\/p>\n<p>(Pandas v1.5.2, Python 3.9.15)<\/p>\n"}
{"0":"Title: Improving performance for a nested for loop iterating over dates.\nBody: <p>I am looking to learn how to improve the performance of code over a large dataframe (10 million rows) and my solution loops over multiple dates <code>(2023-01-10, 2023-01-20, 2023-01-30)<\/code> for different combinations of <code>category_a<\/code> and <code>category_b<\/code>.<\/p>\n<p>The working approach is shown below, which iterates over the dates for different pairings of the two-category data by first locating a subset of a particular pair. However, I would want to refactor it to see if there is an approach that is more efficient.<\/p>\n<p>My input (<code>df<\/code>) looks like:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: right;\"><\/th>\n<th style=\"text-align: left;\">date<\/th>\n<th style=\"text-align: right;\">category_a<\/th>\n<th style=\"text-align: right;\">category_b<\/th>\n<th style=\"text-align: right;\">outflow<\/th>\n<th style=\"text-align: right;\">open<\/th>\n<th style=\"text-align: right;\">inflow<\/th>\n<th style=\"text-align: right;\">max<\/th>\n<th style=\"text-align: right;\">close<\/th>\n<th style=\"text-align: right;\">buy<\/th>\n<th style=\"text-align: left;\">random_str<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: left;\">2023-01-10<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: left;\">2023-01-20<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: left;\">2023-01-30<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">3<\/td>\n<td style=\"text-align: left;\">2023-01-10<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: left;\">2023-01-20<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">5<\/td>\n<td style=\"text-align: left;\">2023-01-30<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>with 2 pairs <code>(4, 1)<\/code> and <code>(4,2)<\/code> over the days and my expected output (<code>results<\/code>) looks like this:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: right;\"><\/th>\n<th style=\"text-align: left;\">date<\/th>\n<th style=\"text-align: right;\">category_a<\/th>\n<th style=\"text-align: right;\">category_b<\/th>\n<th style=\"text-align: right;\">outflow<\/th>\n<th style=\"text-align: right;\">open<\/th>\n<th style=\"text-align: right;\">inflow<\/th>\n<th style=\"text-align: right;\">max<\/th>\n<th style=\"text-align: right;\">close<\/th>\n<th style=\"text-align: right;\">buy<\/th>\n<th style=\"text-align: left;\">random_str<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: left;\">2023-01-10<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">-1<\/td>\n<td style=\"text-align: right;\">23<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: left;\">2023-01-20<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">-1<\/td>\n<td style=\"text-align: right;\">23<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: left;\">2023-01-30<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">1<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">a<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">3<\/td>\n<td style=\"text-align: left;\">2023-01-10<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">10<\/td>\n<td style=\"text-align: right;\">-2<\/td>\n<td style=\"text-align: right;\">24<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: left;\">2023-01-20<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">-2<\/td>\n<td style=\"text-align: right;\">24<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: right;\">5<\/td>\n<td style=\"text-align: left;\">2023-01-30<\/td>\n<td style=\"text-align: right;\">4<\/td>\n<td style=\"text-align: right;\">2<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">0<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">20<\/td>\n<td style=\"text-align: right;\">nan<\/td>\n<td style=\"text-align: left;\">b<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I have a working solution using pandas dataframes to take a subset then loop over it to get a solution but I would like to see how I can improve the performance of this using perhaps ;<code>numpy<\/code>, <code>numba<\/code>, <code>pandas-multiprocessing<\/code> or <code>dask<\/code>. Another great idea was to rewrite it in BigQuery SQL.<\/p>\n<p>I am not sure what the best solution would be and I would appreciate any help in improving the performance.<\/p>\n<p><em><strong>Minimum working example<\/strong><\/em><\/p>\n<p>The code below generates the input dataframe.<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\n\n# prepare the input  df\ndf = pd.DataFrame({\n'date' : ['2023-01-10', '2023-01-20','2023-01-30', '2023-01-10', '2023-01-20','2023-01-30'] ,\n'category_a' : [4, 4,4,4, 4, 4] ,\n'category_b' : [1, 1,1, 2, 2,2] ,\n'outflow' : [1.0, 2.0,10.0, 2.0, 2.0, 0.0],\n'open' : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] ,\n'inflow' : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] ,\n'max' : [10.0, 20.0, 20.0 , 10.0, 20.0,  20.0] ,\n'close' : [0.0, np.nan,np.nan, 0.0, np.nan, np.nan] ,\n'buy' : [0.0, np.nan,np.nan, 0.0, np.nan,np.nan],\n'random_str' : ['a', 'a', 'a', 'b', 'b', 'b'] \n})\n\ndf['date'] = pd.to_datetime(df['date'])\n\n# get unique pairs of category_a and category_b in a dictionary\nunique_pairs = df.groupby(['category_a', 'category_b']).size().reset_index().rename(columns={0:'count'})[['category_a', 'category_b']].to_dict('records')\nunique_dates = np.sort(df['date'].unique())\n<\/code><\/pre>\n<p>Using this input dataframe and Numpy, the code below is what I am trying to optmizize.<\/p>\n<pre><code>df = df.set_index('date')\nday_0 = unique_dates[0] # first date\n\n# Using Dictionary comprehension\n\nlist_of_numbers = list(range(len(unique_pairs)))\nmyset  = {key: None for key in list_of_numbers}\n\nfor count_pair, value in enumerate(unique_pairs):\n    \n    # pair of category_a and category_b\n    category_a = value['category_a']\n    category_b = value['category_b']\n\n    # subset the dataframe for the pair\n    df_subset = df.loc[(df['category_a'] == category_a) &amp; (df['category_b'] == category_b)]\n\n    log.info(f&quot; running for {category_a} and {category_b}&quot;)\n\n    # day 0\n    df_subset.loc[day_0, 'close'] = df_subset.loc[day_0, 'open'] + df_subset.loc[day_0, 'inflow'] - df_subset.loc[day_0, 'outflow']\n    \n    \n    # loop over single pair using date\n    for count, date in enumerate(unique_dates[1:], start=1):\n        previous_date = unique_dates[count-1]\n\n        df_subset.loc[date, 'open'] = df_subset.loc[previous_date, 'close']\n        df_subset.loc[date, 'close'] = df_subset.loc[date, 'open'] + df_subset.loc[date, 'inflow'] - df_subset.loc[date, 'outflow']\n\n        # check if closing value is negative, if so, set inflow to buy for next weeks deficit\n\n        if df_subset.loc[date, 'close'] &lt; df_subset.loc[date, 'max']:\n            df_subset.loc[previous_date, 'buy'] = df_subset.loc[date, 'max'] - df_subset.loc[date, 'close'] + df_subset.loc[date, 'inflow']\n        elif df_subset.loc[date, 'close'] &gt; df_subset.loc[date, 'max']:\n            df_subset.loc[previous_date, 'buy'] = 0\n        else:\n            df_subset.loc[previous_date, 'buy'] = df_subset.loc[date, 'inflow']\n        \n        df_subset.loc[date, 'inflow'] = df_subset.loc[previous_date, 'buy']\n        df_subset.loc[date, 'close'] = df_subset.loc[date, 'open'] + df_subset.loc[date, 'inflow'] - df_subset.loc[date, 'outflow']\n    \n    # store all the dataframes in a container myset\n    myset[count_pair] = df_subset\n    \n# make myset into a dataframe\nresult = pd.concat(myset.values()).reset_index(drop=False)\nresult\n\n<\/code><\/pre>\n<p>After which we can check that the solution is the same as what we expected.<\/p>\n<pre><code>from pandas.testing import assert_frame_equal\n\nexpected = pd.DataFrame({\n'date' : [pd.Timestamp('2023-01-10 00:00:00'), pd.Timestamp('2023-01-20 00:00:00'), pd.Timestamp('2023-01-30 00:00:00'), pd.Timestamp('2023-01-10 00:00:00'), pd.Timestamp('2023-01-20 00:00:00'), pd.Timestamp('2023-01-30 00:00:00')] ,\n'category_a' : [4, 4, 4, 4, 4, 4] ,\n'category_b' : [1, 1, 1, 2, 2, 2] ,\n'outflow' : [1, 2, 10, 2, 2, 0] ,\n'open' : [0.0, -1.0, 20.0, 0.0, -2.0, 20.0] ,\n'inflow' : [0.0, 23.0, 10.0, 0.0, 24.0, 0.0] ,\n'max' : [10, 20, 20, 10, 20, 20] ,\n'close' : [-1.0, 20.0, 20.0, -2.0, 20.0, 20.0] ,\n'buy' : [23.0, 10.0, np.nan, 24.0, 0.0, np.nan] ,\n'random_str' : ['a', 'a', 'a', 'b', 'b', 'b'] \n})\n\n# check that the result is the same as expected\nassert_frame_equal(result, expected)\n<\/code><\/pre>\n<p><em><strong>SQL to create first table<\/strong><\/em><\/p>\n<p>The solution can also be in sql, if so you can use the following code to create the initial table.<\/p>\n<p>I am busy trying to implement a solution in big query sql using a user defined function to keep the logic going too. This would be a nice approach to solving the problem too.<\/p>\n<pre><code>WITH data AS (\n  SELECT \n    DATE '2023-01-10' as date, 4 as category_a, 1 as category_b, 1 as outflow, 0 as open, 0 as inflow, 10 as max, 0 as close, 0 as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-20' as date, 4 as category_a, 1 as category_b, 2 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-30' as date, 4 as category_a, 1 as category_b, 10 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'a' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-10' as date, 4 as category_a, 2 as category_b, 2 as outflow, 0 as open, 0 as inflow, 10 as max, 0 as close, 0 as buy, 'b' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-20' as date, 4 as category_a, 2 as category_b, 2 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'b' as random_str\n  UNION ALL\n  SELECT \n    DATE '2023-01-30' as date, 4 as category_a, 2 as category_b, 0 as outflow, 0 as open, 0 as inflow, 20 as max, NULL as close, NULL as buy, 'b' as random_str\n)\n\nSELECT \n  ROW_NUMBER() OVER (ORDER BY date) as &quot; &quot;,\n  date,\n  category_a,\n  category_b,\n  outflow,\n  open,\n  inflow,\n  max,\n  close,\n  buy,\n  random_str\nFROM data\n<\/code><\/pre>\n"}
{"0":"Title: Why does pandas read_excel fail on an openpyxl error saying &#39;ReadOnlyWorksheet&#39; object has no attribute &#39;defined_names&#39;?.\nBody: <p>This bug suddenly came up literally today after read_excel previously was working fine.  Fails no matter which version of python3 I use - either 10 or 11.<\/p>\n<p>Do folks know the fix?<\/p>\n<pre><code>  File &quot;\/Users\/aizenman\/My Drive\/code\/daily_new_clients\/code\/run_daily_housekeeping.py&quot;, line 38, in &lt;module&gt;\n    main()\n  File &quot;\/Users\/aizenman\/My Drive\/code\/daily_new_clients\/code\/run_daily_housekeeping.py&quot;, line 25, in main\n    sb = diana.superbills.load_superbills_births(args.site, ath)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Users\/aizenman\/My Drive\/code\/daily_new_clients\/code\/diana\/superbills.py&quot;, line 148, in load_superbills_births\n    sb = pd.read_excel(SUPERBILLS_EXCEL, sheet_name=&quot;Births&quot;, parse_dates=[&quot;DOS&quot;, &quot;DOB&quot;])\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/util\/_decorators.py&quot;, line 211, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/util\/_decorators.py&quot;, line 331, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/io\/excel\/_base.py&quot;, line 482, in read_excel\n    io = ExcelFile(io, storage_options=storage_options, engine=engine)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/io\/excel\/_base.py&quot;, line 1695, in __init__\n    self._reader = self._engines[engine](self._io, storage_options=storage_options)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/io\/excel\/_openpyxl.py&quot;, line 557, in __init__\n    super().__init__(filepath_or_buffer, storage_options=storage_options)\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/io\/excel\/_base.py&quot;, line 545, in __init__\n    self.book = self.load_workbook(self.handles.handle)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/pandas\/io\/excel\/_openpyxl.py&quot;, line 568, in load_workbook\n    return load_workbook(\n           ^^^^^^^^^^^^^^\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/openpyxl\/reader\/excel.py&quot;, line 346, in load_workbook\n    reader.read()\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/openpyxl\/reader\/excel.py&quot;, line 303, in read\n    self.parser.assign_names()\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.11\/lib\/python3.11\/site-packages\/openpyxl\/reader\/workbook.py&quot;, line 109, in assign_names\n    sheet.defined_names[name] = defn\n    ^^^^^^^^^^^^^^^^^^^\nAttributeError: 'ReadOnlyWorksheet' object has no attribute 'defined_names'\n<\/code><\/pre>\n"}
{"0":"Title: Error while iterating over dataframe column&#39;s entries: &quot;AttributeError: &#39;Series&#39; object has no attribute &#39;iteritems&#39;&quot;.\nBody: <p>Using pandas version 2, I get an error when calling <code>iteritems<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for event_id, region in column.iteritems():\n    pass\n<\/code><\/pre>\n<p>The following error message appears:<\/p>\n<pre><code>Traceback (most recent call last):\n     File &quot;\/home\/analyst\/anaconda3\/envs\/outrigger_env\/lib\/python3.10\/site- \n     packages\/outrigger\/io\/gtf.py&quot;, line 185, in exon_bedfiles\n          for event_id, region in column.iteritems())\nAttributeError: 'Series' object has no attribute 'iteritems'\n<\/code><\/pre>\n"}
{"0":"Title: AttributeError: &#39;Connection&#39; object has no attribute &#39;connect&#39; when use df.to_sql().\nBody: <p>I am trying to store data retrieved from a website into MySQL database via a pandas data frame. However, when I make the function call <code>df.to_sql()<\/code>, the compiler give me an error message saying: <code>AttributeError: 'Connection' object has no attribute 'connect'<\/code>. I tested it couple times and I am sure that there is neither connection issue nor table existence issue involved. Is there anything wrong with the code itself? The code I am using is the following:<\/p>\n<pre><code>    from sqlalchemy import create_engine, text\n    import pandas as pd\n    import mysql.connector\n\n    \n    config = configparser.ConfigParser()\n    config.read('db_init.INI')\n    password = config.get(&quot;section_a&quot;, &quot;Password&quot;)\n    host = config.get(&quot;section_a&quot;, &quot;Port&quot;)\n    database = config.get(&quot;section_a&quot;, &quot;Database&quot;)\n\n    engine = create_engine('mysql+mysqlconnector:\/\/root:{0}@{1}\/{2}'.\n                           format(password, host, database),\n                           pool_recycle=1, pool_timeout=57600, future=True)\n    \n    conn = engine.connect()\n    df.to_sql(&quot;tableName&quot;, conn, if_exists='append', index = False)\n<\/code><\/pre>\n<p>The full stack trace looks like this:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/Users\/chent\/Desktop\/PFSDataParser\/src\/FetchPFS.py&quot;, line 304, in &lt;module&gt;\n    main()\n  File &quot;\/Users\/chent\/Desktop\/PFSDataParser\/src\/FetchPFS.py&quot;, line 287, in main\n    insert_to_db(experimentDataSet, expName)\n  File &quot;\/Users\/chent\/Desktop\/PFSDataParser\/src\/FetchPFS.py&quot;, line 89, in insert_to_db\n    df.to_sql(tableName, conn, if_exists='append', index = False)\n  File &quot;\/Users\/chent\/opt\/anaconda3\/lib\/python3.9\/site-packages\/pandas\/core\/generic.py&quot;, line 2951, in to_sql\n    return sql.to_sql(\n  File &quot;\/Users\/chent\/opt\/anaconda3\/lib\/python3.9\/site-packages\/pandas\/io\/sql.py&quot;, line 698, in to_sql\n    return pandas_sql.to_sql(\n  File &quot;\/Users\/chent\/opt\/anaconda3\/lib\/python3.9\/site-packages\/pandas\/io\/sql.py&quot;, line 1754, in to_sql\n    self.check_case_sensitive(name=name, schema=schema)\n  File &quot;\/Users\/chent\/opt\/anaconda3\/lib\/python3.9\/site-packages\/pandas\/io\/sql.py&quot;, line 1647, in check_case_sensitive\n    with self.connectable.connect() as conn:\n\nAttributeError: 'Connection' object has no attribute 'connect'\n<\/code><\/pre>\n<p>The version of pandas I am using is 1.4.4, sqlalchemy is 2.0<\/p>\n<p>I tried to make a several execution of sql query, for example, <code>CREATE TABLE xxx IF NOT EXISTS<\/code> or <code>SELECT * FROM<\/code>, all of which have given me the result I wish to see.<\/p>\n"}
{"0":"Title: Alternative to .concat() of empty dataframe, now that it is being deprecated?.\nBody: <p>I have two dataframes that can both be empty, and I want to concat them.<\/p>\n<p>Before I could just do :<\/p>\n<pre><code>output_df= pd.concat([df1, df2])\n<\/code><\/pre>\n<p>But now I run into<\/p>\n<blockquote>\n<p>FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.<\/p>\n<\/blockquote>\n<p>An easy fix would be:<\/p>\n<pre><code>if not df1.empty and not df2.empty:\n    result_df = pd.concat([df1, df2], axis=0)\nelif not df1.empty:\n    result_df = df1.copy()\nelif not df2.empty:\n    result_df = df2.copy()\nelse:\n    result_df = pd.DataFrame()\n<\/code><\/pre>\n<p>But that seems pretty ugly. Does anyone have a better solution ?<\/p>\n<p>FYI: this appeared after pandas released <a href=\"https:\/\/pandas.pydata.org\/docs\/whatsnew\/v2.1.0.html#deprecations\" rel=\"noreferrer\">v2.1.0<\/a><\/p>\n"}
{"0":"Title: Spyder Console Throws &quot;[SpyderKernelApp] ERROR | Exception in message handler&quot; error.\nBody: <p>I am new to Python and use Spyder as my IDE, and I mainly use it for data analysis. A few days ago I reinstalled Spyder for some reasons. Now when I want to directly enter pandas-related commands such as <code>df.info()<\/code> or <code>df.describe()<\/code> in the iPython console, I see the error message after the output (I do get the right output though). It shows:<\/p>\n<pre><code>[SpyderKernelApp] ERROR | Exception in message handler:\nTraceback (most recent call last):\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/ipykernel\/kernelbase.py&quot;, line 409, in dispatch_shell\n    await result\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/ipykernel\/kernelbase.py&quot;, line 798, in inspect_request\n    reply_content = self.do_inspect(\n                    ^^^^^^^^^^^^^^^^\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/ipykernel\/ipkernel.py&quot;, line 555, in do_inspect\n    bundle = self.shell.object_inspect_mime(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/IPython\/core\/interactiveshell.py&quot;, line 1838, in object_inspect_mime\n    return self.inspector._get_info(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/IPython\/core\/oinspect.py&quot;, line 738, in _get_info\n    info_dict = self.info(obj, oname=oname, info=info, detail_level=detail_level)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/IPython\/core\/oinspect.py&quot;, line 838, in info\n    if info and info.parent and hasattr(info.parent, HOOK_NAME):\n  File &quot;\/opt\/homebrew\/lib\/python3.11\/site-packages\/pandas\/core\/generic.py&quot;, line 1466, in __nonzero__\n    raise ValueError(\nValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n<\/code><\/pre>\n<p>Weirdly, this only shows up when I attempt to type the commands manually, and only when I use pandas-related commands. When I run the commands from scripts, or even simply use the up arrow key to select commands in the console, the error message won't show; It only shows when I manually type the commands.<\/p>\n<p>I've looked the error up on the internet but found no discussion. How do I deal with this error?<\/p>\n<p>I reinstalled Spyder, Python, iPython, ipykernel, spyder-kernels, but nothing seemed to help.<\/p>\n"}
{"0":"Title: Pandas plot, vars() argument must have __dict__ attribute?.\nBody: <p>It was working perfectly earlier but for some reason now I am getting strange errors.<\/p>\n<p>pandas version: <code>1.2.3<\/code><\/p>\n<p>matplotlib version: <code>3.7.0<\/code><\/p>\n<p>sample dataframe:<\/p>\n<pre><code>df\n    cap       Date\n0    1     2022-01-04\n1    2     2022-01-06\n2    3     2022-01-07\n3    4     2022-01-08\n<\/code><\/pre>\n<pre><code>df.plot(x='cap', y='Date')\nplt.show()\n<\/code><\/pre>\n<pre><code>df.dtypes\ncap              int64\nDate    datetime64[ns]\ndtype: object\n<\/code><\/pre>\n<p>I get a traceback:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>Traceback (most recent call last):\n  File &quot;\/Library\/Developer\/CommandLineTools\/Library\/Frameworks\/Python3.framework\/Versions\/3.8\/lib\/python3.8\/code.py&quot;, line 90, in runcode\n    exec(code, self.locals)\n  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/pandas\/plotting\/_core.py&quot;, line 955, in __call__\n    return plot_backend.plot(data, kind=kind, **kwargs)\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/pandas\/plotting\/_matplotlib\/__init__.py&quot;, line 61, in plot\n    plot_obj.generate()\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/pandas\/plotting\/_matplotlib\/core.py&quot;, line 279, in generate\n    self._setup_subplots()\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/pandas\/plotting\/_matplotlib\/core.py&quot;, line 337, in _setup_subplots\n    fig = self.plt.figure(figsize=self.figsize)\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/_api\/deprecation.py&quot;, line 454, in wrapper\n    return func(*args, **kwargs)\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/pyplot.py&quot;, line 813, in figure\n    manager = new_figure_manager(\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/pyplot.py&quot;, line 382, in new_figure_manager\n    _warn_if_gui_out_of_main_thread()\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/pyplot.py&quot;, line 360, in _warn_if_gui_out_of_main_thread\n    if _get_required_interactive_framework(_get_backend_mod()):\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/pyplot.py&quot;, line 208, in _get_backend_mod\n    switch_backend(rcParams._get(&quot;backend&quot;))\n  File &quot;\/Volumes\/coding\/venv\/lib\/python3.8\/site-packages\/matplotlib\/pyplot.py&quot;, line 331, in switch_backend\n    manager_pyplot_show = vars(manager_class).get(&quot;pyplot_show&quot;)\nTypeError: vars() argument must have __dict__ attribute\n<\/code><\/pre>\n"}
{"0":"Title: Pandas 2.1.0 FutureWarning: Series.__getitem__ treating keys as positions is deprecated.\nBody: <p>I'm having an issue with Pandas v2.1.0+ that I can't figure out.<\/p>\n<p>I have a list of columns in my pandas data frame that I need to convert using a custom function.  The new values depend on multiple columns in the data, so I'm using apply to convert the column in-place:<\/p>\n<pre><code>my_columns_to_convert = ['col1','col2','col3']\n\nfor k in my_columns_to_convert:\n  df[k] = df[[k,colx]].apply(lambda x: convert_my_data(value_1_in=x[0],value_2_in=x[1]),axis=1)\n<\/code><\/pre>\n<p>This has worked just fine in previous versions of pandas. But now I get:<\/p>\n<pre><code>FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n<\/code><\/pre>\n<p>But I'm not using loc or iloc, and everything I've reviewed thus far seems to point at that being the issue.  How can i write this code so that I'm doing it the 'correct' way in the future?<\/p>\n<p>Using previous methods in Pandas that did work.<\/p>\n"}
{"0":"Title: Repeat rows in DataFrame with respect to column.\nBody: <p>I have a Pandas DataFrame that looks like this:<\/p>\n<pre><code>df = pd.DataFrame({'col1': [1, 2, 3],\n                   'col2': [4, 5, 6],\n                   'col3': [7, 8, 9]})\n\ndf\n    col1    col2    col3\n0      1       4       7\n1      2       5       8\n2      3       6       9\n<\/code><\/pre>\n<p>I would like to create a Pandas DataFrame like this:<\/p>\n<pre><code>df_new\n    col1    col2    col3\n0      1       4       7\n1      1       5       8\n2      1       6       9\n3      2       4       7\n4      2       5       8\n5      2       6       9\n6      3       4       7\n7      3       5       8\n8      3       6       9\n<\/code><\/pre>\n<p>Is there built-in or combination of built-in Pandas methods that can achieve this?<\/p>\n<p>Even if there are duplicates in <code>df<\/code>, I would like the output to be the same format. In other words:<\/p>\n<pre><code>df\n    col1    col2    col3\n0      1       4       7\n1      2       5       8\n2      2       6       8\n\ndf_new\n    col1    col2    col3\n0      1       4       7\n1      1       5       8\n2      1       6       8\n3      2       4       7\n4      2       5       8\n5      2       6       8\n6      2       4       7\n7      2       5       8\n8      2       6       8\n<\/code><\/pre>\n"}
{"0":"Title: .corr results in ValueError: could not convert string to float.\nBody: <p>I'm getting this very strange error when trying to follow the following exercise on using the corr() method in Python<\/p>\n<p><a href=\"https:\/\/www.geeksforgeeks.org\/python-pandas-dataframe-corr\/\" rel=\"nofollow noreferrer\">https:\/\/www.geeksforgeeks.org\/python-pandas-dataframe-corr\/<\/a><\/p>\n<p>Specifically, when I try to run the following code: <code>df.corr(method ='pearson')<\/code><\/p>\n<p>The error message offers no clue. I thought the corr() method was supposed to automatically ignore strings and empty values etc.<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;&lt;pyshell#6&gt;&quot;, line 1, in &lt;module&gt;\n    df.corr(method='pearson')\n  File &quot;C:\\Users\\d.o\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py&quot;, line 10059, in corr\n    mat = data.to_numpy(dtype=float, na_value=np.nan, copy=False)\n  File &quot;C:\\Users\\d.o\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py&quot;, line 1838, in to_numpy\n    result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)\n  File &quot;C:\\Users\\d.o\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py&quot;, line 1732, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n  File &quot;C:\\Users\\d.o\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py&quot;, line 1794, in _interleave\n    result[rl.indexer] = arr\nValueError: could not convert string to float: 'Avery Bradley'\n<\/code><\/pre>\n"}
{"0":"Title: What datatype is considered &#39;list-like&#39; in Python?.\nBody: <p>In the Pandas documentation <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.isin.html\" rel=\"noreferrer\">here<\/a> for <code>Series.isin(values)<\/code>, they state:<\/p>\n<blockquote>\n<p>values : set or list-like<\/p>\n<\/blockquote>\n<p>What is considered list-like? For a Python dictionary <code>temp_dict<\/code>, would <code>temp_dict.keys()<\/code> and <code>temp_dict.values()<\/code> be considered list-like?<\/p>\n"}
{"0":"Title: Is there a possibility when calling .ToUpper() that the new string requires more memory?.\nBody: <p>I want to use the the following function in the MemoryExtensions namespace<\/p>\n<pre><code>public static int ToUpper(this ReadOnlySpan&lt;char&gt; source, Span&lt;char&gt; destination, CultureInfo? culture)\n<\/code><\/pre>\n<p>My question now is: am I always safe when destination Span has the length of the source span? e.g.<\/p>\n<pre><code>destination = stackalloc char[source.Length];\n<\/code><\/pre>\n<p>If no, can someone provide an example which string converts to a larger string when calling ToUpper on in (including which culture)?<\/p>\n"}
{"0":"Title: C\/C++ warn or prohibit literal string concatenation.\nBody: <p>Is there a way to warn or prohibit literal string concatenations such as:<\/p>\n<pre><code>const char *a = &quot;foo&quot; &quot; bar&quot;;\n<\/code><\/pre>\n<p>I spent hours finding a bug in a big static array that had<\/p>\n<pre><code>const char * a[] = {&quot;foo&quot; &quot;bar&quot;};\n<\/code><\/pre>\n<p>instead of<\/p>\n<pre><code>const char * a[] = {&quot;foo&quot;, &quot;bar&quot;};\n<\/code><\/pre>\n"}
{"0":"Title: Is constructing an object in an argument list and passing a pointer to internal data of the object to the function safe?.\nBody: <p>Is the C++ code below well-formed? Will the <code>std::string<\/code> get destroyed before or after the function finishes executing?<\/p>\n<pre class=\"lang-cpp prettyprint-override\"><code>void my_function(const char*);\n\n...\n\nmy_function(std::string(&quot;Something&quot;).c_str());\n<\/code><\/pre>\n<p>I know I could do <code>my_function(&quot;Something&quot;)<\/code>, but I am using <code>std::string<\/code> this way to illustrate my point.<\/p>\n"}
{"0":"Title: How do I split a string by a character without ignoring trailing split-characters?.\nBody: <p>I have a string similar to the following<\/p>\n<pre><code>my_string &lt;- &quot;apple,banana,orange,&quot;\n<\/code><\/pre>\n<p>And I want to split by <code>,<\/code> to produce the output:<\/p>\n<pre><code>list(c('apple', 'banana', 'orange', &quot;&quot;))\n<\/code><\/pre>\n<p>I thought strsplit would accomplish this but it treats the trailing ',' like it doesn't exist<\/p>\n<pre class=\"lang-r prettyprint-override\"><code>my_string &lt;- &quot;apple,banana,orange,&quot;\n\nstrsplit(my_string, split = ',')\n#&gt; [[1]]\n#&gt; [1] &quot;apple&quot;  &quot;banana&quot; &quot;orange&quot;\n<\/code><\/pre>\n<p><sup>Created on 2023-11-15 by the <a href=\"https:\/\/reprex.tidyverse.org\" rel=\"noreferrer\">reprex package<\/a> (v2.0.1)<\/sup><\/p>\n<p>What is the simplest approach to achieve the desired output?<\/p>\n<p>Some more test cases with example strings and desired outputs<\/p>\n<pre><code>string1 = &quot;apple,banana,orange,&quot;\noutput1 = list(c('apple', 'banana', 'orange', ''))\n\nstring2 =  &quot;apple,banana,orange,pear&quot;\noutput2 = list(c('apple', 'banana', 'orange', 'pear'))\n\nstring3 =  &quot;,apple,banana,orange&quot;\noutput3 = list(c('', 'apple', 'banana', 'orange'))\n\n## Examples of non-comma separated strings\n# '|' separator\nstring4 =  &quot;|apple|banana|orange|&quot;\noutput4 = list(c('', 'apple', 'banana', 'orange', ''))\n\n# 'x' separator\nstring5 =  &quot;xapplexbananaxorangex&quot;\noutput5 = list(c('', 'apple', 'banana', 'orange', ''))\n\n<\/code><\/pre>\n<p>EDIT:<\/p>\n<p>Ideally solution should generalize to any splitting character<\/p>\n<p>Would also prefer a base-R solution (although do still link any packages which supply this functionality since their source code might be useful to look through!)<\/p>\n"}
{"0":"Title: C# triple double quotes (three double quotes).\nBody: <p>What is the purpose of triple douple quotes <code>&quot;&quot;&quot;<\/code> in C#? It seems it is used for multiline text. But why not use single double quotes with <code>@&quot;...&quot;<\/code>?<\/p>\n<pre><code>string text = &quot;&quot;&quot;\n  some text\n  some text\n  some text\n  &quot;&quot;&quot;;\n<\/code><\/pre>\n"}
{"0":"Title: How to replace characters in a string one at a time generating new string for each replacement?.\nBody: <p>I have a vector of strings<\/p>\n<pre><code>c(&quot;YSAHEEHHYDK&quot;, &quot;HEHISSDYAGK&quot;, &quot;TFAHTESHISK&quot;, &quot;ISLGEHEGGGK&quot;, \n&quot;LSSGYDGTSYK&quot;, &quot;FGTGTYAGGEK&quot;, &quot;VGASTGYSGLK&quot;, &quot;TASGVGGFSTK&quot;, &quot;SYASDFGSSAK&quot;, \n&quot;LYSYYSSTESK&quot;)\n<\/code><\/pre>\n<p>for each string I would like to replace &quot;Y&quot;, &quot;S&quot; or &quot;T&quot; with &quot;pY&quot;, &quot;pS&quot; or &quot;pT&quot;. But I dont want all the replacements to be in the same final string, I want each replacement to generate a new string, e.g.<\/p>\n<p>&quot;YSAHEEHHYDK&quot; turns into<\/p>\n<pre><code>c(&quot;pYSAHEEHHYDK&quot;,\n&quot;YpSAHEEHHYDK&quot;,\n&quot;YSAHEEHHpYDK&quot;)\n<\/code><\/pre>\n"}
{"0":"Title: How to find the max and min values of string rows of a dataframe in R?.\nBody: <p>For each row of my data, I want to get the <em>min<\/em> and <em>max<\/em> values and\nthe <em>number of years<\/em> which are originally stored as a character. For example, consider the following data:<\/p>\n<pre><code>df &lt;- data.frame(id = 1:4,\n                 yr = c(&quot;1543,860,2023&quot;,\n                        &quot;2019,2018,2006,2007&quot;,\n                        &quot;1998,2012,2000,2020&quot;,\n                        &quot;2000&quot;))\n<\/code><\/pre>\n<p>Output needed:<\/p>\n<pre><code>id                   yr  min_yr  max_yr  nYears\n 1        1543,860,2023     860    2023       3\n 2  2019,2018,2006,2007    2006    2019       4\n 3  1998,2012,2000,2020    1998    2020       4\n 4                 2000    2000    2000       1\n<\/code><\/pre>\n"}
{"0":"Title: Problem of Java String intern method when using StringBuilder with append method creating a String.\nBody: <pre><code>    public static void main(String[] args) {\n        String a = new StringBuilder(&quot;Jav&quot;).toString();\n        a.intern();\n        String c = &quot;Jav&quot;;\n        System.out.println(a == c);  \/\/false\n    }\n<\/code><\/pre>\n<pre><code>    public static void main(String[] args) {\n        String a = new StringBuilder(&quot;Ja&quot;).append(&quot;v&quot;).toString();\n        a.intern();\n        String c = &quot;Jav&quot;;\n        System.out.println(a == c);  \/\/true\n    }\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/g6pD2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/g6pD2.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I do not understand why first one would print out false, but the second one print out true. I think those should print out true because after calling the intern method, the reference of a would be written into the string pool and c will point to the reference of a. Can someone explain the difference? Thanks!<\/p>\n<p>My JDK Version: OpenJDK 17.0.7<\/p>\n<p>Btw I also get the same result when using StringBuffer.<\/p>\n"}
{"0":"Title: How do I create a multiline string in Raku?.\nBody: <p>In JavaScript (ES6), you can use template literals (``) to create multiline strings as shown in the following example:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>const html = `\n  &lt;div&gt;\n    &lt;p&gt;Raku is &lt;b&gt;ofun&lt;\/b&gt;.&lt;\/p&gt;\n  &lt;\/div&gt;\n`\n<\/code><\/pre>\n<p>What's the Raku equivalent of this?<\/p>\n"}
{"0":"Title: Special case when += for string concatenation is more efficient than =.\nBody: <p>I have this code using python 3.11:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import timeit\n\ncode_1 = &quot;&quot;&quot;\ninitial_string = ''\nfor i in range(10000):\n    initial_string = initial_string + 'x' + 'y'\n&quot;&quot;&quot;\n\ncode_2 = &quot;&quot;&quot;\ninitial_string = ''\nfor i in range(10000):\n    initial_string += 'x' + 'y'\n&quot;&quot;&quot;\n\ntime_1 = timeit.timeit(code_1, number=100)\ntime_2 = timeit.timeit(code_2, number=100)\n\nprint(time_1)\n# 0.5770808999950532\nprint(time_2)\n# 0.08363639999879524\n<\/code><\/pre>\n<p>Why <code>+=<\/code> is more efficient <strong>in this case<\/strong>?\nAs far as I know, there is the same number of concatenation, and the order of execution doesn't change the result.<\/p>\n<p>Since strings are immutable, it's not because of inplace shinanigans, and the only thing I found about string concat is about <code>.join<\/code> efficiency, but I don't want the most efficient, just understand why <code>+=<\/code> seems more efficient than <code>=<\/code>.<\/p>\n<p>With this code, performances between forms almost equals:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import timeit\n\ncode_1 = &quot;&quot;&quot;\ninitial_string = ''\nfor i in range(10000):\n    initial_string = initial_string + 'x'\n&quot;&quot;&quot;\n\ncode_2 = &quot;&quot;&quot;\ninitial_string = ''\nfor i in range(10000):\n    initial_string += 'x'\n&quot;&quot;&quot;\n\ntime_1 = timeit.timeit(code_1, number=100)\ntime_2 = timeit.timeit(code_2, number=100)\n\nprint(time_1)\n# 0.07953230000566691\nprint(time_2)\n# 0.08027460001176223\n<\/code><\/pre>\n<hr \/>\n<p>I noticed a difference using different Python version (<code>'x' + 'y'<\/code> form):<\/p>\n<p>Python 3.7 to 3.9:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print(time_1)\n# ~0.6\nprint(time_2)\n# ~0.3\n<\/code><\/pre>\n<p>Python 3.10:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print(time_1)\n# ~1.7\nprint(time_2)\n# ~0.8\n<\/code><\/pre>\n<p>Python 3.11 for comparison:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print(time_1)\n# ~0.6\nprint(time_2)\n# ~0.1\n<\/code><\/pre>\n<hr \/>\n<p>Similar but not answering the question: <a href=\"https:\/\/stackoverflow.com\/questions\/69079181\/how-is-the-s-sc-string-concat-optimization-decided\">How is the s=s+c string concat optimization decided?<\/a><\/p>\n<blockquote>\n<p>If s is a string, then s = s + 'c' might modify the string in place, while t = s + 'c' can't. But how does the operation s + 'c' know which scenario it's in?<\/p>\n<\/blockquote>\n<p>In a nutshell: Optimization occur when <code>s = s + 'c'<\/code>, not when <code>t = s + 'c'<\/code> because python need to keep a ref to the first string and can't concatenate in-place.<\/p>\n<p>Here, we are always assigning using simple assignment or augmented assignment to the original string, so in-place concatenation should apply in both cases.<\/p>\n"}
{"0":"Title: Removing second and subsequent occurrences of decimal point in string.\nBody: <p>I want to remove second and subsequent occurrences of decimal point in string. My attempt is below:<\/p>\n<pre><code>library(stringr)\nstr_remove(string = &quot;3.99-0.13&quot;, pattern = &quot;\\\\.&quot;)\n[1] &quot;399-0.13&quot;\nsub(&quot;\\\\.&quot;, &quot;&quot;, &quot;3.99-0.13&quot;)\n[1] &quot;399-0.13&quot;\n<\/code><\/pre>\n<p>However, I want the output like <code>3.99-013<\/code>. Any hint, please.<\/p>\n"}
{"0":"Title: Why some character can&#39;t be edited in C++?.\nBody: <p>I'm trying to write my own <code>strcat<\/code> function in C++, but it has some problems.<br \/>\nMy input is two chars <code>c<\/code> and <code>a<\/code>, and my function will return a char pointer to a char which <code>c<\/code> is concatenated with <code>a<\/code>.<\/p>\n<p>For example,<br \/>\nInput: <code>'abc'<\/code> <code>'xyz'<\/code><br \/>\nExpected Output: <code>'xyzabc'<\/code><br \/>\nMy function's Ouput: <code>'xyza@\u25b2\u2229'<\/code><\/p>\n<p>My function returns some special character different to my input.<\/p>\n<p>I debugged my function and found that:<\/p>\n<ul>\n<li>When <code>i=0<\/code>, <code>destination[3]<\/code> = <code>source[0]<\/code> = <code>'a'<\/code><\/li>\n<li>But when <code>i=1<\/code>, <code>destination[8]<\/code> = <code>source[1]<\/code> = <code>'b'<\/code><\/li>\n<li>And when <code>i=2<\/code>, <code>destination[9]<\/code> = <code>source[2]<\/code> = <code>'c'<\/code><\/li>\n<li>Finally, <code>destination[10]<\/code> = <code>'\\0'<\/code><\/li>\n<\/ul>\n<pre class=\"lang-c prettyprint-override\"><code>#include&lt;iostream&gt;\n#include&lt;string.h&gt;\nusing namespace std;\n\nchar* mystrcat ( char * destination, const char *source){\n    for (int i=0; i&lt;strlen(source); i++) {\n        destination[strlen(destination)+i] = source[i];\n    }\n    destination[strlen(destination)+strlen(source)]='\\0';\n    return destination;\n}\n\nint main() {\n    char c[100];\n    cin.getline(c, 99);\n    char a[100];\n    cin.getline(a,99);\n\n    mystrcat(a,c);\n    cout&lt;&lt;a;\n    return 0;\n}\n<\/code><\/pre>\n"}
{"0":"Title: How to prevent a function from accidentally becoming recursive?.\nBody: <p>Consider the following C++ code:<\/p>\n<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;iostream&gt;\n\nvoid get_val_from_db(const char* key, signed char&amp; value)\n{\n    std::cout &lt;&lt; &quot;Getting value from db with signed char!\\n&quot;;\n}\n\nvoid get_val_from_db(const char* key, unsigned char&amp; value)\n{\n    std::cout &lt;&lt; &quot;Getting value from db with unsigned char!\\n&quot;;\n}\n\n\/\/ overload to convert first argument from std::string to const char*\ntemplate &lt;typename T&gt;\nvoid get_val_from_db(const std::string&amp; key, T&amp; value)\n{\n    get_val_from_db(key.c_str(), value);\n}\n\n\nint main()\n{\n    unsigned char my_value_unsigned = 0; \/\/ OK!\n    get_val_from_db(&quot;my key&quot;, my_value_unsigned);\n\n    signed char my_value_signed = 0; \/\/ OK!\n    get_val_from_db(&quot;my key&quot;, my_value_signed);\n    \n    char my_value_char = 0; \/\/ NOK! Can't convert! Becomes recursive!\n    get_val_from_db(&quot;my key&quot;, my_value_char);\n\n    \/\/ Can't remove the std::string conversion altogether because these needs to keep working\n    std::string key = &quot;my key&quot;;\n    get_val_from_db(key, my_value_signed);\n    get_val_from_db(key, my_value_unsigned);\n\n}\n<\/code><\/pre>\n<p>I have a function <code>get_val_from_db<\/code> that receives a key name and a key type, with many specializations for each type, including a catch-all template version that merely converts keys names from <code>std::string<\/code> to <code>const char*<\/code>, since those can't be done automatically.<\/p>\n<p><a href=\"https:\/\/godbolt.org\/z\/ETjGzE88q\" rel=\"nofollow noreferrer\">Check a live example of this code on compiler explorer<\/a>, notice that the program crashes when calling the function passing <code>char<\/code> as a type. This happens because <code>char<\/code> is not convertible to <code>signed char&amp;<\/code> (<a href=\"https:\/\/godbolt.org\/z\/eYE9hz4Mr\" rel=\"nofollow noreferrer\">see another compiler explorer example<\/a>), so when passing <code>char<\/code>, the best available function to be called is <code>void get_val_from_db(const std::string&amp; key, T&amp; value)<\/code> which then calls <em>itself<\/em>, since <code>const char*<\/code> <em>can<\/em> be converted to <code>std::string<\/code> directly. So the call becomes recursive and causes a stack overflow.<\/p>\n<p>I could of course add a new specialization for <code>char<\/code>, but I want to make the code safer for future developers. I want new parameter types not to be captured by <code>void get_val_from_db(const std::string&amp; key, T&amp; value)<\/code> and instead get a nice and juicy compilation error. I don't want to remove the function altogether because we need the <code>std::string<\/code> to <code>const char*<\/code> conversion to keep the current code working. In summary, how to prevent this implicit conversion from <code>const char*<\/code> to <code>std::string<\/code> from happenning?<\/p>\n<pre class=\"lang-cpp prettyprint-override\"><code>template &lt;typename T&gt;\nvoid get_val_from_db(const std::string&amp; key, T&amp; value)\n{\n    \/\/ how to prevent key.c_str() from being converted to std::string?\n    get_val_from_db(key.c_str(), value);\n}\n<\/code><\/pre>\n<p>I have a C++ 17 compiler at my disposal.<\/p>\n"}
{"0":"Title: How to find longest continuous contiguous set of characters in a string based on a given vector.\nBody: <p>I have the following string in R code.<\/p>\n<pre><code>aas &lt;- &quot;QAWDIIKRIDKK&quot;\n<\/code><\/pre>\n<p>And  I want to check the longest continuous fragment of that string that contains the character in following vector:<\/p>\n<pre><code>hydrophobic_res &lt;- c(&quot;W&quot;, &quot;F&quot;, &quot;I&quot;, &quot;L&quot;, &quot;V&quot;, &quot;M&quot;, &quot;C&quot;, &quot;A&quot;, &quot;G&quot;)\n<\/code><\/pre>\n<p>The answer is:<\/p>\n<pre><code>AW, II\n<\/code><\/pre>\n<p>Other example:<\/p>\n<pre><code>QFILVMD -&gt; FILVM\n<\/code><\/pre>\n<p>How can I do that in R?<\/p>\n"}
{"0":"Title: Obtain palindromic array by performing these operations.\nBody: <p>An array is called palindromic if it remains the same after reversing the order of its elements.<\/p>\n<p>You have an array of strings arr. For each i, <code>arr[i]<\/code> consists of at least two characters. For each pair of consecutive elements <code>arr[i]<\/code> and <code>arr[i + 1]<\/code>, you can:<\/p>\n<ol>\n<li>Move the rightmost character of <code>arr[i]<\/code> to the leftmost position in <code>arr[i + 1]<\/code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;ab&quot; and &quot;cdef&quot;. This operation can be applied only once to any pair of consecutive elements.<\/li>\n<li>Move the leftmost character of <code>arr[i + 1]<\/code> to the rightmost position in <code>arr[i]<\/code>. For instance, &quot;abc&quot; and &quot;def&quot; will become &quot;abcd&quot; and &quot;ef&quot;. Again, this operation can be applied only once to any pair of consecutive elements.<\/li>\n<li>Do nothing to the pair of consecutive elements.<\/li>\n<\/ol>\n<p>Is it possible to obtain a palindromic array from arr by performing these operations?<\/p>\n<p>Consider the case when arr = <code>{&quot;aa&quot;, &quot;bab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}<\/code>. Here the output should be true and here is why:<\/p>\n<p>Move first char from 1st index to the last position of 0th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;aba&quot;, &quot;ab&quot;}<\/code>\nMove last char from 3rd index to the first position of 4th index, arr = <code>{&quot;aab&quot;, &quot;ab&quot;, &quot;cde&quot;, &quot;ab&quot;, &quot;aab&quot;}<\/code>, which is a palindromic array.<\/p>\n<p>I tried solutions such as two pointer, etc. but doesn't seem to work.<\/p>\n"}
{"0":"Title: Prepend leading zeros to each line of a file.\nBody: <p>I have a file that looks like this:<\/p>\n<pre><code>1:line1\n14:line2\n135:line3\n15:line4\n<\/code><\/pre>\n<p>I need to prepend leading zeros to each line to make it look like this:<\/p>\n<pre><code>00001:line1\n00014:line2\n00135:line3\n00015:line4\n<\/code><\/pre>\n<p>Is there an easy way to do this in Linux?<\/p>\n<p>I have tried using<\/p>\n<pre><code>awk '{printf &quot;%05d:%s\\n&quot;, FNR, $0}' file\n<\/code><\/pre>\n<p>but this outputted:<\/p>\n<pre><code>00001:1:line1\n00002:14:line2\n00003:135:line3\n00004:15:line4\n<\/code><\/pre>\n<p>I should note I did not write this command, I got it from Google and don't really understand how it works<\/p>\n"}
{"0":"Title: Capture the last word on each line.\nBody: <p>I have a file that doesn't have the correct spacing and I would like to add a space between the dollar amount and the word right beside it, i.e., <code>2342.20Hello<\/code>.<\/p>\n<p>I tried using <code>sed<\/code> to resolve this issue but it didn't seem to work.<\/p>\n<p>I tried this command but it doesn't seem to work.<\/p>\n<pre><code>sed -r 's\/([0-9].*)\\.([a-zA-Z].*) \/\\1 \\2\/g' \/tmp\/testfile2.txt\n<\/code><\/pre>\n<p>I was expecting the file that has:<\/p>\n<pre><code>2234.3Hello\n8938.3HeyYou\n1239.0New\n<\/code><\/pre>\n<p>To look like this:<\/p>\n<pre><code>2234.3 Hello\n8938.3 HeyYou\n1239.0 New\n<\/code><\/pre>\n<p>I'm okay with <code>Perl<\/code> or <code>sed<\/code> commands to accomplish the above.<\/p>\n"}
{"0":"Title: Fast and efficient substring extraction and comparison in R.\nBody: <p>I have a problem concerning very fast and efficient comparison between the substrings of two strings in my dataset, which won't run fast enough despite pretty powerful machinery.\nI have a <code>data.table<\/code> with 2 columns and about 1.5 billion rows, which has this structure:<\/p>\n<pre><code>library(data.table)\nlibrary(stringr)\nlibrary(stringi)\nlibrary(stringdist)\n\ndt &lt;- data.frame(c(&quot;002134&quot;, &quot;024345&quot;, &quot;176234&quot;), c(&quot;002003&quot;, &quot;024234&quot;, &quot;002004&quot;))\ncolnames(dt) &lt;- c(&quot;class1&quot;, &quot;class2&quot;)\nsetDT(dt)\n<\/code><\/pre>\n<p>What I want is a function that (1) extracts the first 3 digits from each string by row for both vectors, (2) compares the substrings between the two vectors, and (3) create a new boolean variable that reports whether the two substrings are equal or not.<\/p>\n<p>So the desired result is as follows:<\/p>\n<pre><code>dt$sameclass &lt;- c(TRUE, TRUE, FALSE)\nprint(dt)\n   class1 class2 sameclass\n1: 002134 002003      TRUE\n2: 024345 024234      TRUE\n3: 176234 002004     FALSE\n<\/code><\/pre>\n<p>I have tried versions of <code>stringr<\/code> and <code>stringi<\/code> both within <code>data.table<\/code> functionality and without. For comparing the substrings I use <code>stringdist<\/code>, since to my understanding can be parallelized which would be very beneficial on my server. However, the bottleneck still seems to be the substring extraction.<\/p>\n<pre><code>\n#stringi + stringdist without data.table: \ndt$redclass1 &lt;- stri_sub(dt$class1, to = 3)\ndt$redclass2 &lt;- stri_sub(dt$class2, to = 3)\ndt[, classdist := stringdist(a = redclass1, b = redclass2, method = &quot;hamming&quot;)] \ndt[, sameclass := (classdist == 0)] \n\n#stringi + stringdist within data.table: \ndt[, classdist := stringdist(a = stri_sub(dt$class1, to = 3), b = stri_sub(dt$class2, to = 3), method = &quot;hamming&quot;)] \ndt[, sameclass := (classdist == 0)] \n\n#stringr with separate function: \nsameclass &lt;- function(subclass1, subclass2, classdepth){\n  truthvalue &lt;- (str_sub(subclass1, end = classdepth) == str_sub(subclass2, end = classdepth))\n  return(truthvalue)\n} \ndt[, sameclass := sameclass(subclass1 = class1, subclass2 = class2, classdepth = 3), by = seq_len(nrow(dt))]\n<\/code><\/pre>\n<p>All versions either run into memory problems or take several hours to a day to run. Since I need to do this repeatedly this does not work for me, and I wanted to ask if you can come up with something faster\/ more efficient. Any help would be greatly appreciated!<\/p>\n<p><strong>EDIT<\/strong><\/p>\n<p>I have benchmarked some of the methods suggested here, which indeed show a substantial speedup:<\/p>\n<pre><code>dt &lt;- data.frame(rep(c(&quot;002134&quot;, &quot;024345&quot;, &quot;176234&quot;), 1000), rep(c(&quot;002003&quot;, &quot;024234&quot;, &quot;002004&quot;), 1000))\ncolnames(dt) &lt;- c(&quot;class1&quot;, &quot;class2&quot;)\nsetDT(dt)\n\ntimes &lt;- microbenchmark(\n\nstartswithtest = dt[, startsWith(class2, substring(class1, 1, 3))],\nlapplytest = dt[, do.call(`==`, lapply(.SD, substring, 1, 3)), .SDcols = c(&quot;class1&quot;, &quot;class2&quot;)],\nnumerictest = dt[, as.numeric(class1)%\/%1000 == as.numeric(class2)%\/%1000],\nfunctiontest = dt[, sameclass(subclass1 = class1, subclass2 = class2, classdepth = 3), by = seq_len(nrow(dt))],\nstringitest = dt[, stringdist(a = stri_sub(dt$class1, to = 3), b = stri_sub(dt$class2, to = 3), method = &quot;hamming&quot;)], \ntimes = 50\n)\ntimes\n           expr       min        lq       mean     median         uq        max neval\n startswithtest   312.501   356.901   593.4530   444.8515    737.301   1692.602    50\n     lapplytest   383.602   439.201   736.3512   522.7010    966.901   2259.601    50\n    numerictest  1763.100  1932.600  3229.6651  2399.7510   4153.201   8396.301    50\n   functiontest 45677.700 61124.002 81567.9409 77844.5510 100084.901 133921.502    50\n    stringitest   794.201  1028.200  1423.5289  1259.6005   1739.400   3640.701    50\n<\/code><\/pre>\n<p>I will go with the startsWith for now, since it seems to offer the highest speed (unfortunately I was not able to use the C-function due to restrictions on my server). Thank you for the help!<\/p>\n"}
{"0":"Title: Sorting words from argv by length.\nBody: <p>I'm attempting to read words from the command line using <code>argv<\/code> in C and then sort them in descending order based on their lengths. However, my sorting algorithm is producing unexpected output.<\/p>\n<p>The code I'm using is as follows:<\/p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nint main(int argc, char *argv[]) {\n\n    for (int i = 1; i &lt; argc - 1; i++) {\n        for (int j = 1; j &lt; argc - i - 1; j++) {\n            if (strlen(argv[j]) &lt; strlen(argv[j + 1])) {\n                char temp_word[20];\n                strcpy(temp_word, argv[j]);\n                strcpy(argv[j], argv[j + 1]);\n                strcpy(argv[j + 1], temp_word);\n            }\n        }\n    }\n\n    puts(&quot;\\n&quot;);\n    for (int i = 1; i &lt; argc; i++) {\n        printf(&quot;%s &quot;, argv[i]);\n    }\n\n    return 0;\n}\n<\/code><\/pre>\n<pre><code>gcc test.c -o test\n.\/test I put this words\n\n\npuwordI wordI I  % \n<\/code><\/pre>\n<p>Unfortunately, the output is corrupted. I suspect there might be an issue with my sorting logic or how I'm handling the command line arguments. Could someone please review my code and provide guidance on how to correctly sort the words by length?<\/p>\n"}
{"0":"Title: how do I concatenate and join an array of strings with a delimiter in powershell?.\nBody: <p>PS C:\\Users\\User\\ps-modules&gt; more .\\MyStrings.Tests.ps1<\/p>\n<pre><code>function slist { &quot;1&quot;, &quot;2&quot;, &quot;3&quot; }\n\nDescribe 'StringTests' {\n\n  It 'literal -join' {\n    &quot;1&quot;, &quot;2&quot;, &quot;3&quot; -join &quot;,&quot; | Should -Be &quot;1,2,3&quot;\n  }\n\n  It 'literal -join' {\n    @(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;) -join &quot;,&quot; | Should -Be &quot;1,2,3&quot;\n  }\n\n  It 'slist returns a list of string' {\n    slist | Should -Be @(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)\n  }\n\n  It 'slist -join' {\n    slist -join &quot;,&quot; | Should -Be &quot;1,2,3&quot;\n  }\n\n}\n<\/code><\/pre>\n<p>PS C:\\Users\\User\\ps-modules&gt; pwsh .\\MyStrings.Tests.ps1<\/p>\n<pre><code>Starting discovery in 1 files.\nDiscovery found 4 tests in 169ms.\nRunning tests.\n[-] StringTests.slist -join 55ms (53ms|2ms)\n Expected '1,2,3', but got @('1', '2', '3').\n at slist -join &quot;,&quot; | Should -Be &quot;1,2,3&quot;, C:\\Users\\User\\ps-modules\\MyStrings.Tests.ps1:17\n at &lt;ScriptBlock&gt;, C:\\Users\\User\\ps-modules\\MyStrings.Tests.ps1:17\nTests completed in 731ms\nTests Passed: 3, Failed: 1, Skipped: 0 NotRun: 0\n<\/code><\/pre>\n<p>Why is the array treated differently when it comes from a function return vs when it's literally declared?<\/p>\n"}
